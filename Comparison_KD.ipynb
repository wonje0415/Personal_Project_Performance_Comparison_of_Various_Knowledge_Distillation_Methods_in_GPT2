{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RSTnhfWhUS0e",
        "CzbwkaeYUs7X",
        "2LaYeOP6Zdjc",
        "NDEZDPlwcBeE",
        "VnACQiaShQqs",
        "vqpgiWEJw6Ni",
        "NJP4A3mcyaJ1",
        "MaswKG2vzhf5",
        "NiOR-50T1Zd1",
        "Bzi3qHrg2V5u",
        "Tyx-mz5A3Y9g",
        "FfeX_Vy94i3n",
        "xNueMXAw5shC",
        "76pDVPks7Ig2",
        "ltspXAkf7yoU",
        "phzEaN_H8ZI9",
        "xhbL1yOb9Z3o"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## KD with customized-TinyGPT\n",
        "\n",
        "- customized-TinyGPT : about 51M parameters, 194MB"
      ],
      "metadata": {
        "id": "RSTnhfWhUS0e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OTbzm1uNrlK",
        "outputId": "63ed6711-ee1c-45bc-88ca-650485c78077"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Aug 18 23:29:48 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             45W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Check GPU -> It should be A100.\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 1\n",
        "Model Making & Data Preprocessing"
      ],
      "metadata": {
        "id": "CzbwkaeYUs7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# random seed fixing\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.cuda.manual_seed_all(42)  # multi-GPU\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "wBJz0cvoh7Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciafe_9TqPaF"
      },
      "outputs": [],
      "source": [
        "# customized-TinyGPT realization\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "@dataclass\n",
        "class TinyGPTConfig:\n",
        "  # Hyperparameters for TinyGPT\n",
        "  vocab_size: int = 50257\n",
        "  n_layers: int = 8 # transformer blocks\n",
        "  n_head: int = 8 # head_dim\n",
        "  d_model: int = 512 # hidden_size\n",
        "  d_ff: int = 2048 # Feed-Forward hidden size\n",
        "  max_position_embeddings: int = 256 # context length\n",
        "  dropout = 0.2\n",
        "  rotary_pct: float = 0.0\n",
        "  tie_embeddings: bool = True\n",
        "  device: str = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "  def __init__(self, d_model : int, max_len : int):\n",
        "    super().__init__()\n",
        "    pe = torch.zeros(max_len, d_model) # shape : (max_len, d_model)\n",
        "    positions = torch.arange(0, max_len).unsqueeze(1) # shape : (max_len, 1)\n",
        "    div_terms = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000) / d_model))\n",
        "    pe[:,0::2] = torch.sin(positions * div_terms)\n",
        "    pe[:,1::2] = torch.cos(positions * div_terms)\n",
        "    self.register_buffer('pe', pe.unsqueeze(0), persistent=False) # (1, max_len, d_model)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor: # (batch_size, T, C)\n",
        "    return x + self.pe[:,:x.size(1),:]\n",
        "\n",
        "class MHSA(nn.Module):\n",
        "  def __init__(self,config=TinyGPTConfig):\n",
        "    super().__init__()\n",
        "    assert config.d_model % config.n_head == 0, \"d_model must be divisible by n_head\"\n",
        "    self.d_model = config.d_model\n",
        "    self.n_head = config.n_head\n",
        "    self.head_dim = config.d_model // config.n_head\n",
        "    self.qkv_linear = nn.Linear(config.d_model, 3 * config.d_model)\n",
        "    self.linear = nn.Linear(config.d_model, config.d_model)\n",
        "    self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "  def forward(self, x: torch.Tensor, return_attentions: bool, casual_mask:bool = True) -> torch.Tensor: # (batch_size, T, C)\n",
        "    batch_size, T, C = x.shape # C == self.d_model\n",
        "    qkv = self.qkv_linear(x) # (batch_size, T, 3C)\n",
        "    q,k,v = qkv.chunk(3, dim=-1) # each shape : (batch_size, T, C)\n",
        "\n",
        "    # reshape for multi-head. shape : (batch_size, n_head, T, head_dim)\n",
        "    q = q.view(batch_size, T, self.n_head, self.head_dim).transpose(1,2)\n",
        "    k = k.view(batch_size, T, self.n_head, self.head_dim).transpose(1,2)\n",
        "    v = v.view(batch_size, T, self.n_head, self.head_dim).transpose(1,2)\n",
        "\n",
        "    attn = torch.matmul(q, k.transpose(-1,-2)) / math.sqrt(self.head_dim) # (batch_size, n_head, T, T)\n",
        "    if casual_mask:\n",
        "      mask = torch.triu(torch.ones(T, T, device=x.device, dtype=torch.bool), diagonal=1) # up-triangle\n",
        "      attn = attn.masked_fill(mask, float('-1e9')) # 1 -> -1e9\n",
        "    attn = F.softmax(attn, dim=-1)\n",
        "    attn = self.dropout(attn)\n",
        "\n",
        "    attn_res = torch.matmul(attn, v) # shape : (batch_size, n_head, T, head_dim)\n",
        "    attn_res = attn_res.transpose(1,2).contiguous().view(batch_size, T, C) # shape : (batch_size, T, C)\n",
        "    attn_res = self.linear(attn_res)\n",
        "    if return_attentions:\n",
        "      return attn_res, attn\n",
        "    else:\n",
        "      return attn_res\n",
        "\n",
        "class FFNN(nn.Module):\n",
        "  def __init__(self, config=TinyGPTConfig):\n",
        "    super().__init__()\n",
        "    self.FFNN_net = nn.Sequential(\n",
        "        nn.Linear(config.d_model, config.d_ff),\n",
        "        nn.GELU(),\n",
        "        nn.Linear(config.d_ff, config.d_model),\n",
        "        nn.Dropout(config.dropout)\n",
        "    )\n",
        "  def forward(self, x:torch.Tensor) -> torch.Tensor: # (batch_size, T, C)\n",
        "    ffnn_res = self.FFNN_net(x)\n",
        "    return ffnn_res\n",
        "\n",
        "class TinyGPTBlock(nn.Module):\n",
        "  def __init__(self, config=TinyGPTConfig):\n",
        "    super().__init__()\n",
        "    self.ln1 = nn.LayerNorm(config.d_model)\n",
        "    self.attn = MHSA(config)\n",
        "    self.ln2 = nn.LayerNorm(config.d_model)\n",
        "    self.ff = FFNN(config)\n",
        "\n",
        "  def forward(self, x:torch.Tensor, return_attentions: bool, casual_mask:bool = True) -> torch.Tensor:\n",
        "    if return_attentions == True:\n",
        "      attn_w, org_attn = self.attn(self.ln1(x), return_attentions, casual_mask=casual_mask)\n",
        "      x = x + attn_w\n",
        "      x = x + self.ff(self.ln2(x))\n",
        "      return x, org_attn\n",
        "    else:\n",
        "      x = x + self.attn(self.ln1(x), return_attentions, casual_mask=casual_mask)\n",
        "      x = x + self.ff(self.ln2(x))\n",
        "      return x\n",
        "\n",
        "class TinyGPT(nn.Module):\n",
        "  def __init__(self, config: TinyGPTConfig):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.token_emb = nn.Embedding(config.vocab_size, config.d_model)\n",
        "    self.pos_emb = PositionalEmbedding(config.d_model, config.max_position_embeddings)\n",
        "    self.drop = nn.Dropout(config.dropout)\n",
        "\n",
        "    self.blocks = nn.ModuleList([TinyGPTBlock(config) for _ in range(config.n_layers)])\n",
        "    self.ln_f = nn.LayerNorm(config.d_model)\n",
        "    self.Linear_f = nn.Linear(config.d_model, config.vocab_size, bias=False)\n",
        "\n",
        "    if config.tie_embeddings:\n",
        "      self.Linear_f.weight = self.token_emb.weight # weight tying\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "    self.to(config.device)\n",
        "\n",
        "  @staticmethod # can use directly without calling out\n",
        "  def _init_weights(module):\n",
        "    if isinstance(module, nn.Linear): # initialization mathod in linear\n",
        "      nn.init.normal_(module.weight, mean=0.0, std=0.02) # it is usually used in GPT-type models\n",
        "      if module.bias is not None: # if bias exist,\n",
        "        nn.init.zeros_(module.bias)\n",
        "    elif isinstance(module, nn.Embedding):\n",
        "      nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "  def forward(self,\n",
        "              input_ids: torch.Tensor,\n",
        "              return_attentions: bool,\n",
        "              labels: Optional[torch.Tensor]=None) -> tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
        "    B, T = input_ids.shape\n",
        "    if T > self.config.max_position_embeddings: # if seq_len > max_position_embeddings\n",
        "      raise ValueError(f'Sequence length {T} must not be larger than limit : {self.config.max_position_embeddings}')\n",
        "\n",
        "    x = self.token_emb(input_ids) # (B, T, C)\n",
        "    x = self.pos_emb(x)\n",
        "    x = self.drop(x)\n",
        "    if return_attentions == True:\n",
        "      all_attns = [] # list to save all attn\n",
        "      for block in self.blocks:\n",
        "        x, org_attn = block(x, return_attentions=True, casual_mask=True)\n",
        "        all_attns.append(org_attn)\n",
        "      x = self.ln_f(x)\n",
        "      logits = self.Linear_f(x) # (B, T, vocab_size)\n",
        "\n",
        "      return logits, all_attns\n",
        "    else:\n",
        "      for block in self.blocks:\n",
        "        x = block(x, return_attentions=False, casual_mask=True)\n",
        "\n",
        "      x = self.ln_f(x)\n",
        "      logits = self.Linear_f(x) # (B, T, vocab_size)\n",
        "\n",
        "      return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znMfChM76Sye",
        "outputId": "6b89bb61-5432-45a2-9271-4436e95afbe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.34.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (2025.3.0)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.19.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.1.7)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# For using Dataset from huggingface\n",
        "pip install -U datasets huggingface_hub fsspec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "0984a36ab3904c2d8c8e226580e3124f",
            "399d95d6854a4d579dc362cc5b24f840",
            "d8b3a01db86b4ea4b092695e541aed99",
            "a5931b83e79f437988d2c1b3cec5266c",
            "e29c7750e292423ab7424f952cab1e4b",
            "5317f5fb2a1045ca89e60a71f16c2eaa",
            "055041f95fa547dea1c7bb0b0c2237c2",
            "3a17e70d8fe14df3b8e756d3b6077520",
            "66f18b6237df42ae8bdea54eab4498cb",
            "6f5a499c1ae04333a256da17f41ad354",
            "79c4490ff6ef496698c577c2235397df",
            "2c5e81a1fe73411cbb7212ea3f072d6b",
            "7c56df4d31f94c9d9a36f8a95778c72f",
            "8a0f96f584c64d3caf738730ee6a63b7",
            "8e9ca8412a5b40919d94bd2873f81a99",
            "077f09e319cd42e89990875f0fd2e527",
            "258b7e1868d64f929970f6dd3c7416a8",
            "e9791ac1598546cea2efb35bc2106463",
            "cfe1118480fa4a0281f782e95b82332a",
            "f053bc70b30846d497b2e5d8f0180527",
            "ad06498cc8c74492beffae5106a15d3e",
            "09268c72b1a943d2863378821da5689c",
            "c8df38500d724994a7599fa2580591b0",
            "9f0b04d4925641c0b5344225b909336d",
            "51932c101c8d4bc287d8f7857b543df8",
            "2207902d04b747ff91a1fce0bdee0c59",
            "a2ff4b551a454a28a60c8c08d2e9c7c2",
            "bdf4ba407d734fb0851884f9aed58a1f",
            "a82fc7bd9ee04989a6ba2fd0528f466c",
            "e787dec4fec34ed283cb29de213ab439",
            "7697657389c74106beca03d0e0358dfc",
            "54af26af18c54fceadbb200ca07e1128",
            "793143eff0ae430d990f17dda18953d8",
            "c297bd857eb448d3822b79e288480b9b",
            "b035cdeccc354b3ca8f7b70ece9a9c68",
            "b65bf1df503a40fda727277e0cd6ceb1",
            "04a237a726074867addb6fe8215ae47a",
            "740099b3ceb44dc29225a1cd88b880ea",
            "4963ebc8d2b446a1a933b859a2acc9d3",
            "f5f8ee6161e94c10921fa26531e9c1e6",
            "8c7986c7b2cf4c1dafeceb5da8c64080",
            "97b11735e3104a20aa4c74da4311677a",
            "125f4c8cf35a421da04e733cace902e9",
            "d5bddc6fb20c4bd9bf7fbd1e94746d56",
            "95d4c133488d4b9eb2facef6e92ace9d",
            "272884d711de4481997dad5a292c533b",
            "c6454425eccd4eae86849810f4e63756",
            "877a9601af85454b99efc48db8920167",
            "89ae65050ae143a0bccef5ff4039e619",
            "5ef86ae30de44dd5a602fcb61883df05",
            "e717ee53e2c440ffbce5eb8d85f2f862",
            "4d4ba53ad7e74551a2c1d5fbd85861e3",
            "0b0e328825fe4e6e88c669aea835c8f3",
            "951310fc02cf45d5b669a8443b242067",
            "602991de300c4afdafae041f87655d60",
            "36ea380563554470af608d596c8cccd8",
            "4dec9d475f954c65bb23a2dea1919d50",
            "5f13edbd22a249ba9b02ab54cbdefeb2",
            "4d1c5671c3c841fca2623315b60a3221",
            "0cfe70a4bd3849a784cb60facfc78dca",
            "85523cf98e4f44b49f214121962165c0",
            "e955689402754bfd8d94bf48028dd224",
            "e6feccc5973741f78b1c836c918a985f",
            "6625dc64b3484918bdb86523d7ae3933",
            "95e76a5024bd4844b0580e83ae361feb",
            "e4d05829ebd84a14b296adceadbd6d4c",
            "17e5ff10fb684bc6a13158c1abc42810",
            "d0756d85595b4456b549161e8b1a757d",
            "442461e3263f444ebcb79ae80e9cb232",
            "3bf3626c20b54dd2ae570d9b633935f4",
            "82580824d39b48129893e5a8af9eb5d9",
            "660d9cc6a0234a819fbd0ce5be270e3d",
            "91c1c38b42f249a7bbc712d375aea7e1",
            "a0933c3bbae04622a896b737d12047ee",
            "52af12bd8e7b4b618b01cf131792ca11",
            "e7ba5bf4d48242cda78cda90265c170e",
            "be2fa5bcb86841d6af402577a97a8de6",
            "5f3d187b520048698a64c4edc5f36f6b",
            "aa9cf33d670d4bb5b87cfff30c3de429",
            "39080204a3cd4f72894b1ea0c304334c",
            "0a8bf57078a94558a0113175cb0957c4",
            "f51064c842c843eab2485fe832ec4c2b",
            "e9f9da2c316d434aa79eb43e479732d7",
            "ea9ec1fe90104d7c96ec5c9b16d2b9ad",
            "e7dcddb0fe5144aca286f2aa4aaac3b2",
            "fe649cf9fe9e4b6aaf216de960bcfc33",
            "5a099512f8914054ac32601fb57d5ee1",
            "a530413055dd480784c02656ad59dd18"
          ]
        },
        "id": "F1vvjj_Dohd5",
        "outputId": "7792aedf-8501-4d71-a6eb-a98f56125825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0984a36ab3904c2d8c8e226580e3124f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/733k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c5e81a1fe73411cbb7212ea3f072d6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00002.parquet:   0%|          | 0.00/157M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8df38500d724994a7599fa2580591b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00001-of-00002.parquet:   0%|          | 0.00/157M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c297bd857eb448d3822b79e288480b9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "validation-00000-of-00001.parquet:   0%|          | 0.00/657k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95d4c133488d4b9eb2facef6e92ace9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36ea380563554470af608d596c8cccd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17e5ff10fb684bc6a13158c1abc42810"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f3d187b520048698a64c4edc5f36f6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 4358\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 1801350\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 3760\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "# call WikiText-103\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "ec299e4e49fc40c589a36af2edf03fe1",
            "f317a62bdaec4cfc93aa4fd777590cc1",
            "4ad4d5ae797e482c85daeb1890a78617",
            "6e31b01bd6c141da88343bb95f3d5fb7",
            "ac8b70252df24741aa1a4c5972d18f6b",
            "853aee1abbc14525b9460a754c4c1043",
            "2edcd9afabc74654b4f543c4b117566c",
            "e8b37ec0226343a082bb37f30c2dc068",
            "af00bf9ec8324259a4e382c5e8f3c323",
            "7988c130f7154cd3bcab4ddd331d0516",
            "d11f64e3dc3f4f6e9332a023be961221",
            "f55c3d83ade345288e1de9019789a9fa",
            "abcaddb0d41d4e68820e92559b03f06e",
            "38948422d0414660a16b51b06daa4698",
            "eeb1a66c51724477b58bd249e32a6cb2",
            "9726dff556f24b7ca8c994699940392f",
            "f6b0495a9bd34242ac7ad94fd702f989",
            "0ca670c0539f449bba81ae8d82bf4bdf",
            "0159682d5d1e40fd983016c114b2b4f5",
            "d544919dd44544ddb9407cee38402f39",
            "68ff3d98087541098be3f059b2a76eb0",
            "25e7e7cbff5a4a4c9f44812b6cdd98cf",
            "a1a8238c5689453ca00cf8d77726131a",
            "a025cbd99afe429786e668de71761ad3",
            "030eb2863dad411198908c45189ecb02",
            "173a0d3a62ae494b96d48dd6c3dcc25e",
            "50fc8609ad3a43589342bfc42b7cd7f1",
            "9877b9e6fa814b58a1de9dd002c9a515",
            "b7a05a456dfc48389b2ed3784592460e",
            "10aea1e727da446dbcc183253fc7bfc0",
            "b43aa085b6b24f2eadf1696b015052ab",
            "7f4a6f7f7cb24b819c30f7963d0d0bfc",
            "5b95748d1db844a8bd86e1c249251a13",
            "af2a3f44238c4a94bb383c202b3faad3",
            "7a43160006f3490bb278b46373fa19b4",
            "e9e07cb9805449c892c3426d692e9546",
            "94a5327708954bd4a826199e7a24751b",
            "1c64efde1e1f435fbca7cc7b58ebbc7d",
            "d16c16d5599149a28ac33960e33e159e",
            "3156b1574dfc4c80af1bf7c87812c6c9",
            "b9b89c2e960448d1ad5d933a3f5f233b",
            "a1d2e57bb6024c34860eae308ee5cedb",
            "d8d275d67b1742aa9b0fb21ee6e26e3f",
            "c48b289b4e7c4f3fab79963c7e0a90a9",
            "8801bbf1a4c4479098f9f4eafa3e2063",
            "3cc9c549993442bf863a13a74d48ec99",
            "d8e2e268e2294e86b8c83cdf487c132d",
            "c75094611ab6487c8c752c3d172a344d",
            "5702f0af7a60482085afa93002c1781c",
            "e7c8f893b46043ec9e62bb999932a8c6",
            "61f1a6e3347b4b5fb30a1b353484f840",
            "46b6c3d9d37e492b86ef378c6d79b35e",
            "317be2a31c124899a8962e4613395e06",
            "1f5d1e779532430983bbbc23ff0cb9b9",
            "2378dfd30cc546f49c2077a0b7f07813",
            "4a582ddb0d3e4b52aadbad7bd1b39816",
            "3f683c70380f4a048780622949f34a75",
            "a05759ed67994de6a9b2d7754b8916e7",
            "de2594694ffc4aae980a50227c4ffa5e",
            "9241bdb303ac490fa7e72c0e7ea99263",
            "ddab8f86cbae42508c85478b83ad36c4",
            "8133e8c864814442baa7ac0a7f8ef45b",
            "daeba92bde0e4ce397e26d41a5ce2a5c",
            "b7ef264ada384742ade89e46faa9d9cc",
            "ef50d6a70bf74464bd85788f38beaa81",
            "8f210f2fbfd14beab13af32b84184b6e",
            "683022628aa841fdbf344f5938529813",
            "19b7efd241cc4428a6763904231cc430",
            "3dbb66ec3c0f428986979eaddf8b08ca",
            "780072c7e1b64a958c16d3ae5ee26468",
            "c8d910a5b433491d9f2f9b42f0318a70",
            "a417368915a04cb6bfe0099228f2ff44",
            "2f4c27a42a2747c29ef762efd08589cb",
            "da3948fca01741a5b980afe729b457a7",
            "e95f4c1172554470a706735c4c900fae",
            "b05de5ffcef34cafb41c8ed397f59194",
            "fa2d24dcb35c4604a7354d1c219ed5e6",
            "4c3502076c8043a491d295a8826b258a",
            "9254a254b5e84e4283a0877838f9dd86",
            "a5a075223d83420dbc06019eea4e9ed3",
            "083677110df74c47ace2b3041e7e8ea8",
            "a504fc2304ce47679519321f37faebf7",
            "a5d54726881c4836a17bdfd43b1f20fb",
            "6c32661257c74c60b94e9c13878178e2",
            "2181b4d2d6934ccb8e8e44021dd7927c",
            "d28564f334c34498b2be6bbe4d0315a7",
            "57a2cbd2ffe14722a9f1bddb48e2955c",
            "f7b3c786cb83491aa1c31cedcc9e5a6c",
            "af490c2e4f9b4ef1a26415460381973d",
            "d586a80aabd34ea58fe3494f705c2e06",
            "e5bee6718a444697a1e8740996b8a6c4",
            "be09b5f17c084e2abdfaad2c6cd9ae9f",
            "5a32b64a665b4263a5cc4a7391a099f4",
            "fc6ca4bd539142e29fd10f898f72d303",
            "bbfe389076564fe380bc8206e050068c",
            "c177c201e083418490eabcd742555697",
            "d4b8eeec27164a75a84d4dc163dd4552",
            "9dacb82720a74a2abfcd2187560ad341",
            "ec0f525616e3485bbbd8cbee5e6af24c",
            "54fbefea24104183a400d73d0f824f70",
            "3e70a2ac26c744afb4073fdcc5da9248",
            "01e0ca01ea7d4036ac6c1f642e68a36a",
            "42bae254d2f3492889977894bffe16dd",
            "bc118b6c43114966a7c569ef29dbcf35",
            "a75b7303e00a49a0b7e16f472cc6d561",
            "7aefff65b03f45a6b8b216936f0c3383",
            "c23323dbaa964a7f8c2b14b894385c33",
            "8e7e28ebc2b144aca6feb6bf3736e6e4",
            "d6b4b9ac8d534841995a6c408e48b487",
            "fd776a91627f4819a184922e0159a4d7",
            "a02eb9c0443d4de890e72225103e656a",
            "4ce6930f4e824adc9b77505a82c4c89a",
            "c8dc43709cf343fca132ea9267d99af0",
            "38dab802fbc14782927dcd00fc7457be",
            "588bbf9e6f3b4764818fd180069960e3",
            "fc5e709522cd4e489f16ef59cfebd855",
            "53b28a04d86740a2967b4e9329536934",
            "00e636782c3140cd924c6093041541ca",
            "7f775cdb43da48d5a560666c7993f3cf",
            "34363b4752704c4b8dd76217e4e5c453",
            "06c2d54b87964d6b8d4faef2f9da1263"
          ]
        },
        "id": "wn7_0X2b8b-i",
        "outputId": "95235ec2-c031-48ef-f839-28ee959a2625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-791519425.py:16: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  sent = re.sub('\\s+', ' ', sent)  # 다중 공백을 단일 공백으로\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec299e4e49fc40c589a36af2edf03fe1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f55c3d83ade345288e1de9019789a9fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1a8238c5689453ca00cf8d77726131a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af2a3f44238c4a94bb383c202b3faad3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8801bbf1a4c4479098f9f4eafa3e2063"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab_size should be 50257\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a582ddb0d3e4b52aadbad7bd1b39816"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "683022628aa841fdbf344f5938529813"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c3502076c8043a491d295a8826b258a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5120 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af490c2e4f9b4ef1a26415460381973d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1845248 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54fbefea24104183a400d73d0f824f70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/4096 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a02eb9c0443d4de890e72225103e656a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from itertools import chain\n",
        "import re\n",
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "# GPT2 Tokenizer setting\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
        "print(f'vocab_size should be {len(tokenizer)}')\n",
        "\n",
        "# GPT2 doesn't have padding token -> replace it with EOS token\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# preprocess function\n",
        "def preprocess(sentence):\n",
        "  # blank without alphabet, numbers and some special letters\n",
        "  sent = re.sub('[^a-zA-Z0-9\\'\\\".,!? ]+', ' ', sentence.strip())\n",
        "  sent = re.sub('\\s+', ' ', sent)  # multiple blank -> single blank\n",
        "  return sent\n",
        "\n",
        "# text tokenizeing\n",
        "def tokenizing(example):\n",
        "  # After preprocessing, combine to one str\n",
        "  text = \" \".join([preprocess(t) for t in example['text']])\n",
        "  # tokeizer includes <eos> token processing\n",
        "  return tokenizer(text, return_attention_mask=False, truncation=True, padding=False)\n",
        "\n",
        "# Applying tokenizer to all datasets\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenizing,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]  # Delete the original text column\n",
        ")\n",
        "\n",
        "# Function to split text into blocks for GPT training\n",
        "block_size = 128  # hyper-parameters\n",
        "\n",
        "def group_texts(examples):\n",
        "  # Check if input_ids is list in the list\n",
        "  input_ids = examples[\"input_ids\"]\n",
        "\n",
        "  # Make a long token sequences\n",
        "  if isinstance(input_ids[0], list):  # if several sentences(batch)\n",
        "    joined = list(chain(*input_ids))\n",
        "  else:  # one sentence (not batch)\n",
        "    joined = input_ids\n",
        "\n",
        "  total_len = (len(joined) // block_size) * block_size\n",
        "  joined = joined[:total_len]\n",
        "\n",
        "  # Making blocks to input datasets to models\n",
        "  input_blocks = [joined[i:i+block_size] for i in range(0, total_len, block_size)]\n",
        "\n",
        "  return {\n",
        "      \"input_ids\": input_blocks,\n",
        "      \"labels\": [\n",
        "          [-100 if token == tokenizer.pad_token_id else token for token in block]\n",
        "          for block in input_blocks\n",
        "          ]\n",
        "    }\n",
        "\n",
        "# Datset making\n",
        "lm_dataset = tokenized_dataset.map(\n",
        "    group_texts,\n",
        "    batched=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQQr4P_d40zW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a95589-b01e-4a92-b40f-147c1519263f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lm_dataset : DatasetDict({\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 35\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 12916\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 28\n",
            "    })\n",
            "})\n",
            "['', ' = Valkyria Chronicles III = \\n', '', ' Senjō no Valkyria 3 : Unrecorded Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" . \\n', \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\"]\n",
            "['', ' Valkyria Chronicles III ', '', 'Senj no Valkyria 3 Unrecorded Chronicles Japanese 3 , lit . Valkyria of the Battlefield 3 , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" Calamaty Raven \" .', \"The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n .\"]\n",
            "[[220, 569, 18354, 7496, 17740, 6711, 220, 220, 2311, 73, 645, 569, 18354, 7496, 513, 791, 47398, 17740, 4960, 513, 837, 6578, 764, 569, 18354, 7496, 286, 262, 30193, 513, 837, 8811, 6412, 284, 355, 569, 18354, 7496, 17740, 6711, 2354, 2869, 837, 318, 257, 16106, 2597, 2712, 2008, 983, 4166, 416, 29490, 290, 6343, 13, 44206, 329, 262, 14047, 44685, 764, 28728, 287, 3269, 2813, 287, 2869, 837, 340, 318, 262, 2368, 983, 287, 262, 569, 18354, 7496, 2168, 764, 12645, 278, 262, 976, 21748, 286, 16106, 290, 1103, 640, 11327, 355, 663, 27677, 837, 262, 1621, 4539, 10730, 284, 262, 717, 983, 290, 5679, 262, 366, 17871, 5321, 366, 837, 257, 23634, 2422, 4326, 7351, 262, 3277, 286, 7096, 544, 1141, 262, 5498, 1898, 6839, 1810], [508, 1620, 3200, 2042, 4560, 290, 389, 46852, 1028, 262, 11773, 4326, 366, 2199, 321, 265, 88, 12552, 366, 764, 383, 983, 2540, 2478, 287, 3050, 837, 6872, 625, 257, 1588, 6903, 286, 262, 670, 1760, 319, 569, 18354, 7496, 17740, 2873, 764, 2893, 340, 17383, 262, 3210, 3033, 286, 262, 2168, 837, 340, 635, 25289, 3294, 16895, 837, 884, 355, 1642, 262, 983, 517, 43486, 329, 2168, 29661, 764, 15684, 11915, 371, 4548, 64, 8835, 73, 280, 290, 26777, 7286, 13704, 13231, 43354, 1111, 4504, 422, 2180, 12784, 837, 1863, 351, 569, 18354, 7496, 17740, 2873, 3437, 33687, 5303, 18024, 6909, 764, 317, 1588, 1074, 286, 8786, 12118, 262, 4226, 764, 383, 983, 705, 82, 4756, 7505, 373, 23568, 416, 1737, 705, 77, 764, 632, 1138, 351], [3967, 4200, 287, 2869, 837, 290, 373, 15342, 416, 1111, 4960, 290, 8830, 9188, 764, 2293, 2650, 837, 340, 2722, 41496, 2695, 837, 1863, 351, 281, 9902, 8313, 287, 3389, 286, 326, 614, 764, 632, 373, 635, 16573, 656, 15911, 290, 281, 2656, 2008, 11034, 2168, 764, 14444, 284, 1877, 4200, 286, 569, 18354, 7496, 17740, 2873, 837, 569, 18354, 7496, 17740, 6711, 373, 407, 36618, 837, 475, 257, 4336, 11059, 11670, 351, 262, 983, 705, 82, 9902, 8313, 373, 2716, 287, 1946, 764, 6343, 13, 44206, 561, 1441, 284, 262, 8663, 351, 262, 2478, 286, 569, 18354, 7496, 22134, 9303, 329, 262, 14047, 604, 764, 220, 220, 3776, 1759, 220, 220, 1081, 351, 2180, 569, 18354, 8704, 17740, 1830, 837, 569, 18354, 7496, 17740, 6711, 318, 257], [16106, 2597, 2712, 983, 810, 1938, 1011, 1630, 286, 257, 2422, 4326, 290, 1011, 636, 287, 10566, 1028, 4472, 3386, 764, 18152, 389, 1297, 832, 9048, 1492, 588, 13043, 351, 15108, 2095, 31725, 837, 351, 3435, 5486, 12387, 832, 21346, 4046, 25037, 290, 12387, 832, 555, 13038, 3711, 2420, 764, 383, 2137, 33226, 832, 257, 2168, 286, 14174, 10566, 837, 11835, 14838, 355, 8739, 326, 460, 307, 12748, 28660, 832, 290, 302, 21542, 355, 484, 389, 14838, 764, 383, 6339, 284, 1123, 1621, 4067, 319, 262, 3975, 17806, 6906, 319, 281, 1981, 2137, 705, 82, 3164, 618, 530, 3038, 318, 6163, 837, 262, 584, 318, 15283, 572, 284, 262, 2137, 764, 22151, 10566, 837, 262, 2137, 3435, 1334, 287, 257, 1413, 837, 810, 4991, 460, 307, 27658, 290], [2095, 3349, 8833, 764, 17159, 1589, 262, 1388, 1621, 10566, 389, 2095, 2176, 850, 10566, 11270, 284, 1180, 8244, 1866, 764, 2293, 262, 983, 705, 82, 11939, 837, 3224, 8640, 389, 14838, 837, 617, 286, 606, 1719, 257, 2440, 8722, 621, 883, 1043, 287, 262, 1334, 286, 262, 983, 764, 1318, 389, 635, 1842, 18640, 4847, 3519, 284, 262, 983, 705, 82, 734, 1388, 4293, 1127, 837, 3584, 484, 1011, 257, 845, 4159, 2597, 764, 383, 983, 705, 82, 3344, 1080, 837, 262, 1086, 72, 51, 57, 1080, 837, 318, 5281, 625, 3264, 422, 569, 18354, 8704, 17740, 764, 5856, 10566, 837, 1938, 2922, 1123, 4326, 1262, 257, 1353, 866, 6650, 286, 262, 13480, 3975, 1752, 257, 2095, 318, 6163, 837, 262, 2137, 6100, 262, 2095, 1088, 262]]\n",
            "[220, 569, 18354, 7496, 17740, 6711, 220, 220, 2311, 73, 645, 569, 18354, 7496, 513, 791, 47398, 17740, 4960, 513, 837, 6578, 764, 569, 18354, 7496, 286, 262, 30193, 513, 837, 8811, 6412, 284, 355, 569, 18354, 7496, 17740, 6711, 2354, 2869, 837, 318, 257, 16106, 2597, 2712, 2008, 983, 4166, 416, 29490, 290, 6343, 13, 44206, 329, 262, 14047, 44685, 764, 28728, 287, 3269, 2813, 287, 2869, 837, 340, 318, 262, 2368, 983, 287, 262, 569, 18354, 7496, 2168, 764, 12645, 278, 262, 976, 21748, 286, 16106, 290, 1103, 640, 11327, 355, 663, 27677, 837, 262, 1621, 4539, 10730, 284, 262, 717, 983, 290, 5679, 262, 366, 17871, 5321, 366, 837, 257, 23634, 2422, 4326, 7351, 262, 3277, 286, 7096, 544, 1141, 262, 5498, 1898, 6839, 1810]\n",
            "128\n",
            "\n",
            "['', ' = Homarus gammarus = \\n', '', ' Homarus gammarus , known as the European lobster or common lobster , is a species of clawed lobster from the eastern Atlantic Ocean , Mediterranean Sea and parts of the Black Sea . It is closely related to the American lobster , H. americanus . It may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . In life , the lobsters are blue , only becoming \" lobster red \" on cooking . Mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into planktonic larvae . Homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the British Isles . \\n', '']\n",
            "['', ' Homarus gammarus ', '', 'Homarus gammarus , known as the European lobster or common lobster , is a species of clawed lobster from the eastern Atlantic Ocean , Mediterranean Sea and parts of the Black Sea . It is closely related to the American lobster , H. americanus . It may grow to a length of 60 cm 24 in and a mass of 6 kilograms 13 lb , and bears a conspicuous pair of claws . In life , the lobsters are blue , only becoming \" lobster red \" on cooking . Mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into planktonic larvae . Homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the British Isles .', '']\n",
            "[[220, 8074, 20272, 9106, 3876, 385, 220, 220, 8074, 20272, 9106, 3876, 385, 837, 1900, 355, 262, 3427, 43657, 393, 2219, 43657, 837, 318, 257, 4693, 286, 26573, 276, 43657, 422, 262, 10183, 10596, 10692, 837, 19517, 6896, 290, 3354, 286, 262, 2619, 6896, 764, 632, 318, 7173, 3519, 284, 262, 1605, 43657, 837, 367, 13, 45630, 41141, 764, 632, 743, 1663, 284, 257, 4129, 286, 3126, 12067, 1987, 287, 290, 257, 2347, 286, 718, 37075, 1511, 18360, 837, 290, 13062, 257, 39089, 5166, 286, 28421, 764, 554, 1204, 837, 262, 6804, 5937, 389, 4171, 837, 691, 5033, 366, 43657, 2266, 366, 319, 10801, 764, 337, 803, 8833, 287, 262, 3931, 837, 9194, 9653, 543, 389, 5281, 416, 262, 12366, 329, 510, 284, 257, 614, 878, 289, 19775], [656, 39599, 1122, 291, 37346, 764, 8074, 20272, 9106, 3876, 385, 318, 257, 4047, 48243, 2057, 837, 290, 318, 6768, 4978, 1262, 43657, 32195, 837, 4632, 1088, 262, 3517, 36217, 764, 220, 220, 12489, 220, 220, 8074, 20272, 9106, 3876, 385, 318, 257, 1588, 20048, 558, 272, 837, 351, 257, 1767, 4129, 510, 284, 3126, 1247, 38813, 411, 1987, 287, 290, 21990, 510, 284, 642, 718, 37075, 1367, 1511, 18360, 837, 3584, 262, 6804, 5937, 4978, 287, 43657, 32195, 389, 3221, 2242, 4353, 12067, 860, 1315, 287, 890, 290, 10164, 657, 764, 767, 362, 764, 362, 14211, 352, 764, 642, 604, 764, 860, 18360, 764, 4525, 584, 20048, 558, 504, 837, 6804, 5937, 423, 257, 1327, 409, 418, 38800, 543, 484, 1276, 14999, 287, 1502, 284, 1663, 837], [287, 257, 1429, 1444, 9940, 67, 3097, 285, 2852, 889, 764, 770, 743, 3051, 1811, 1661, 257, 614, 329, 1862, 6804, 5937, 837, 475, 20638, 284, 1752, 790, 352, 362, 812, 329, 4025, 4695, 764, 383, 717, 5166, 286, 279, 567, 14922, 12978, 318, 6936, 351, 257, 1588, 837, 30372, 34546, 5166, 286, 28421, 764, 383, 4025, 530, 318, 262, 366, 25164, 372, 366, 837, 290, 468, 19273, 18666, 5028, 973, 329, 24949, 15974, 262, 584, 318, 262, 366, 38121, 366, 837, 543, 468, 7786, 8434, 13015, 837, 290, 318, 973, 329, 4769, 393, 24447, 262, 15974, 764, 19672, 837, 262, 1364, 26573, 318, 262, 25164, 372, 837, 290, 262, 826, 318, 262, 38121, 764, 383, 409, 418, 38800, 318, 4143, 4171, 2029, 837, 351, 10222, 326, 46064], [344, 837, 290, 7872, 2174, 764, 383, 2266, 9568, 3917, 351, 6804, 5937, 691, 3568, 706, 10801, 764, 770, 8833, 780, 837, 287, 1204, 837, 262, 2266, 43385, 6468, 897, 29313, 259, 318, 5421, 284, 257, 7532, 3716, 837, 475, 262, 3716, 318, 5445, 510, 416, 262, 4894, 286, 10801, 837, 13011, 262, 2266, 43385, 764, 383, 11706, 3585, 286, 367, 13, 9106, 3876, 385, 318, 262, 1605, 43657, 837, 8074, 20272, 45630, 41141, 764, 383, 734, 4693, 389, 845, 2092, 837, 290, 460, 307, 12606, 32455, 837, 3584, 45456, 389, 7485, 284, 3051, 287, 262, 4295, 1201, 511, 16069, 466, 407, 21721, 764, 383, 734, 4693, 460, 307, 18876, 416, 257, 1271, 286, 9695, 220, 383, 686, 2536, 388, 286, 367, 13, 45630, 41141, 13062, 530, 393], [517, 599, 1127, 319, 262, 44929, 837, 543, 389, 14394, 287, 367, 13, 9106, 3876, 385, 764, 383, 599, 1127, 319, 262, 28421, 286, 367, 13, 45630, 41141, 389, 2266, 393, 2266, 28395, 837, 981, 883, 286, 367, 13, 9106, 3876, 385, 389, 2330, 393, 2330, 28395, 764, 383, 44929, 286, 262, 26573, 286, 367, 13, 45630, 41141, 318, 10912, 393, 2266, 837, 981, 326, 286, 367, 13, 9106, 3876, 385, 318, 27892, 2330, 393, 845, 14005, 2266, 764, 220, 220, 5155, 6772, 220, 220, 15396, 367, 13, 9106, 3876, 385, 3151, 3206, 24841, 618, 484, 423, 7334, 284, 257, 1097, 499, 558, 4129, 286, 4019, 7600, 3939, 38813, 411, 513, 764, 352, 513, 764, 513, 287, 837, 9472, 10835, 15345, 379, 257, 4622, 4833, 2546, 764, 337]]\n",
            "[220, 8074, 20272, 9106, 3876, 385, 220, 220, 8074, 20272, 9106, 3876, 385, 837, 1900, 355, 262, 3427, 43657, 393, 2219, 43657, 837, 318, 257, 4693, 286, 26573, 276, 43657, 422, 262, 10183, 10596, 10692, 837, 19517, 6896, 290, 3354, 286, 262, 2619, 6896, 764, 632, 318, 7173, 3519, 284, 262, 1605, 43657, 837, 367, 13, 45630, 41141, 764, 632, 743, 1663, 284, 257, 4129, 286, 3126, 12067, 1987, 287, 290, 257, 2347, 286, 718, 37075, 1511, 18360, 837, 290, 13062, 257, 39089, 5166, 286, 28421, 764, 554, 1204, 837, 262, 6804, 5937, 389, 4171, 837, 691, 5033, 366, 43657, 2266, 366, 319, 10801, 764, 337, 803, 8833, 287, 262, 3931, 837, 9194, 9653, 543, 389, 5281, 416, 262, 12366, 329, 510, 284, 257, 614, 878, 289, 19775]\n",
            "128\n",
            "\n",
            "['', ' = Robert Boulter = \\n', '', ' Robert Boulter is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy \\'s Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the Menier Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall . \\n', ' In 2006 , Boulter starred alongside Whishaw in the play Citizenship written by Mark Ravenhill . He appeared on a 2006 episode of the television series , Doctors , followed by a role in the 2007 theatre production of How to Curse directed by Josie Rourke . How to Curse was performed at Bush Theatre in the London Borough of Hammersmith and Fulham . Boulter starred in two films in 2008 , Daylight Robbery by filmmaker Paris Leonti , and Donkey Punch directed by Olly Blackburn . In May 2008 , Boulter made a guest appearance on a two @-@ part episode arc of the television series Waking the Dead , followed by an appearance on the television series Survivors in November 2008 . He had a recurring role in ten episodes of the television series Casualty in 2010 , as \" Kieron Fletcher \" . Boulter starred in the 2011 film Mercenaries directed by Paris Leonti . \\n']\n",
            "['', ' Robert Boulter ', '', 'Robert Boulter is an English film , television and theatre actor . He had a guest starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John Deed in 2002 . In 2004 Boulter landed a role as \" Craig \" in the episode \" Teddy \\'s Story \" of the television series The Long Firm he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the Menier Chocolate Factory in London . He was directed by John Tiffany and starred alongside Ben Whishaw , Shane Zaza , Harry Kent , Fraser Ayres , Sophie Stanton and Dominic Hall .', 'In 2006 , Boulter starred alongside Whishaw in the play Citizenship written by Mark Ravenhill . He appeared on a 2006 episode of the television series , Doctors , followed by a role in the 2007 theatre production of How to Curse directed by Josie Rourke . How to Curse was performed at Bush Theatre in the London Borough of Hammersmith and Fulham . Boulter starred in two films in 2008 , Daylight Robbery by filmmaker Paris Leonti , and Donkey Punch directed by Olly Blackburn . In May 2008 , Boulter made a guest appearance on a two part episode arc of the television series Waking the Dead , followed by an appearance on the television series Survivors in November 2008 . He had a recurring role in ten episodes of the television series Casualty in 2010 , as \" Kieron Fletcher \" . Boulter starred in the 2011 film Mercenaries directed by Paris Leonti .']\n",
            "[[220, 5199, 347, 2852, 353, 220, 220, 5199, 347, 2852, 353, 318, 281, 3594, 2646, 837, 5581, 290, 21421, 8674, 764, 679, 550, 257, 8319, 20495, 2597, 319, 262, 5581, 2168, 383, 3941, 287, 4751, 764, 770, 373, 3940, 416, 257, 20495, 2597, 287, 262, 711, 2332, 684, 3194, 416, 11288, 37072, 837, 543, 373, 6157, 287, 5878, 379, 262, 8111, 3078, 15752, 764, 679, 550, 257, 8319, 2597, 287, 262, 5581, 2168, 8974, 1757, 1024, 276, 287, 6244, 764, 554, 5472, 347, 2852, 353, 11406, 257, 2597, 355, 366, 13854, 366, 287, 262, 4471, 366, 29345, 705, 82, 8362, 366, 286, 262, 5581, 2168, 383, 5882, 31623, 339, 31636, 7848, 10544, 2940, 13535, 290, 20893, 12806, 72, 764, 679, 373, 3350, 287, 262, 5075, 21421, 32260, 286], [262, 14576, 39616, 711, 21673, 22384, 837, 543, 373, 6157, 379, 262, 25331, 15752, 287, 42125, 290, 262, 6065, 959, 24777, 19239, 287, 3576, 764, 679, 373, 7924, 416, 1757, 40928, 290, 31636, 7848, 3932, 854, 680, 707, 837, 24379, 1168, 7056, 837, 5850, 8758, 837, 28059, 13709, 411, 837, 35331, 36442, 290, 36401, 4789, 764, 554, 4793, 837, 347, 2852, 353, 31636, 7848, 854, 680, 707, 287, 262, 711, 47002, 3194, 416, 2940, 12552, 12639, 764, 679, 4120, 319, 257, 4793, 4471, 286, 262, 5581, 2168, 837, 28274, 837, 3940, 416, 257, 2597, 287, 262, 4343, 21421, 3227, 286, 1374, 284, 19739, 7924, 416, 22568, 494, 371, 49003, 764, 1374, 284, 19739, 373, 6157, 379, 5511, 15752, 287, 262, 3576, 48114, 286, 4345, 11056, 22947, 290, 28040], [2763, 764, 347, 2852, 353, 31636, 287, 734, 7328, 287, 3648, 837, 47743, 3851, 13001, 416, 26479, 6342, 1004, 756, 72, 837, 290, 43823, 24265, 7924, 416, 440, 12810, 42603, 764, 554, 1737, 3648, 837, 347, 2852, 353, 925, 257, 8319, 5585, 319, 257, 734, 636, 4471, 10389, 286, 262, 5581, 2168, 370, 868, 262, 5542, 837, 3940, 416, 281, 5585, 319, 262, 5581, 2168, 45998, 287, 3389, 3648, 764, 679, 550, 257, 24824, 2597, 287, 3478, 8640, 286, 262, 5581, 2168, 43508, 774, 287, 3050, 837, 355, 366, 39717, 261, 31942, 366, 764, 347, 2852, 353, 31636, 287, 262, 2813, 2646, 12185, 30216, 7924, 416, 6342, 1004, 756, 72, 764, 220, 220, 32619, 220, 220, 220, 220, 4751, 5075, 220, 220, 554, 4751, 347, 2852, 353, 550], [257, 8319, 20495, 2597, 319, 262, 5581, 2168, 383, 3941, 339, 19152, 366, 4746, 2547, 563, 366, 287, 262, 4471, 837, 366, 554, 19978, 22237, 366, 764, 347, 2852, 353, 31636, 355, 366, 4746, 366, 287, 262, 711, 2332, 684, 3194, 416, 11288, 37072, 837, 543, 373, 6157, 287, 5878, 379, 262, 8111, 3078, 15752, 764, 317, 2423, 286, 347, 2852, 353, 705, 82, 2854, 287, 383, 13362, 319, 3502, 3417, 683, 355, 366, 33437, 39579, 366, 287, 262, 2597, 837, 290, 339, 2722, 4688, 8088, 287, 383, 18277, 837, 290, 31867, 8997, 764, 679, 4120, 287, 262, 5581, 2168, 8974, 1757, 1024, 276, 287, 6244, 355, 366, 3060, 368, 943, 2781, 496, 366, 287, 262, 4471, 366, 14611, 5518, 276, 6160, 366, 837, 290, 550, 257, 2597], [355, 257, 1180, 2095, 366, 37578, 28549, 366, 319, 383, 3941, 764, 679, 550, 257, 24824, 2597, 287, 5816, 319, 734, 8640, 286, 383, 3941, 837, 355, 2095, 366, 27599, 7886, 366, 764, 554, 5472, 347, 2852, 353, 11406, 257, 2597, 355, 366, 13854, 366, 287, 262, 4471, 366, 29345, 705, 82, 8362, 366, 286, 262, 5581, 2168, 383, 5882, 31623, 339, 31636, 7848, 10544, 2940, 13535, 290, 20893, 12806, 72, 764, 347, 2852, 353, 31636, 355, 366, 26203, 366, 837, 287, 262, 5075, 21421, 32260, 286, 262, 14576, 39616, 711, 21673, 22384, 764, 632, 373, 6157, 379, 262, 25331, 15752, 287, 42125, 837, 290, 262, 6065, 959, 24777, 19239, 287, 3576, 764, 679, 373, 7924, 416, 1757, 40928, 290, 31636, 7848, 3932, 854, 680, 707, 837, 24379]]\n",
            "[220, 5199, 347, 2852, 353, 220, 220, 5199, 347, 2852, 353, 318, 281, 3594, 2646, 837, 5581, 290, 21421, 8674, 764, 679, 550, 257, 8319, 20495, 2597, 319, 262, 5581, 2168, 383, 3941, 287, 4751, 764, 770, 373, 3940, 416, 257, 20495, 2597, 287, 262, 711, 2332, 684, 3194, 416, 11288, 37072, 837, 543, 373, 6157, 287, 5878, 379, 262, 8111, 3078, 15752, 764, 679, 550, 257, 8319, 2597, 287, 262, 5581, 2168, 8974, 1757, 1024, 276, 287, 6244, 764, 554, 5472, 347, 2852, 353, 11406, 257, 2597, 355, 366, 13854, 366, 287, 262, 4471, 366, 29345, 705, 82, 8362, 366, 286, 262, 5581, 2168, 383, 5882, 31623, 339, 31636, 7848, 10544, 2940, 13535, 290, 20893, 12806, 72, 764, 679, 373, 3350, 287, 262, 5075, 21421, 32260, 286]\n",
            "128\n"
          ]
        }
      ],
      "source": [
        "# Check dataset\n",
        "print(f'lm_dataset : {lm_dataset}')\n",
        "print(dataset['train']['text'][:5])\n",
        "print([preprocess(sent) for sent in dataset['train']['text'][:5]])\n",
        "\n",
        "print(lm_dataset['train']['input_ids'][:5])\n",
        "print(lm_dataset['train']['labels'][0])\n",
        "print(len(lm_dataset['train']['input_ids'][1])) # each length of train\n",
        "print()\n",
        "\n",
        "print(dataset['validation']['text'][:5])\n",
        "print([preprocess(sent) for sent in dataset['validation']['text'][:5]])\n",
        "\n",
        "print(lm_dataset['validation']['input_ids'][:5])\n",
        "print(lm_dataset['validation']['labels'][0])\n",
        "print(len(lm_dataset['validation']['input_ids'][1])) # each length of validation\n",
        "print()\n",
        "\n",
        "print(dataset['test']['text'][:5])\n",
        "print([preprocess(sent) for sent in dataset['test']['text'][:5]])\n",
        "\n",
        "print(lm_dataset['test']['input_ids'][:5])\n",
        "print(lm_dataset['test']['labels'][0])\n",
        "print(len(lm_dataset['test']['input_ids'][1])) # each length of test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0E-tFPLbnEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f159782-1d25-466f-cdfd-7f37c70c1df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12916\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Make datasets to dataloaders\n",
        "1. raw datasets -> tensor\n",
        "2. tensor -> TensorDataset\n",
        "3  TensorDataset -> DataLoader\n",
        "'''\n",
        "batch_size = 64 # Hyper-parameters. if OOM occured, batch_size should be 32, else 64\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_input_tensor = torch.tensor(lm_dataset['train']['input_ids'], dtype=torch.long)\n",
        "train_label_tensor = torch.tensor(lm_dataset['train']['labels'], dtype=torch.long)\n",
        "\n",
        "valid_input_tensor = torch.tensor(lm_dataset['validation']['input_ids'], dtype=torch.long)\n",
        "valid_label_tensor = torch.tensor(lm_dataset['validation']['labels'], dtype=torch.long)\n",
        "\n",
        "test_input_tensor = torch.tensor(lm_dataset['test']['input_ids'], dtype=torch.long)\n",
        "test_label_tensor = torch.tensor(lm_dataset['test']['labels'], dtype=torch.long)\n",
        "\n",
        "# Setting datasets and dataloaders\n",
        "train_dataset = TensorDataset(train_input_tensor, train_label_tensor)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "valid_dataset = TensorDataset(valid_input_tensor, valid_label_tensor)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle = True)\n",
        "print(len(train_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 2\n",
        "\n",
        "No KD\n",
        "\n",
        "PPL : 367.0832\n",
        "\n",
        "Best Epoch : 21"
      ],
      "metadata": {
        "id": "2LaYeOP6Zdjc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJiqUjR8ygjM",
        "outputId": "942361ac-b838-425d-85dd-0c084ca26182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "model = TinyGPT(TinyGPTConfig)\n",
        "print(TinyGPTConfig.device) # Check device is GPU or CPU\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klvSiCngNm_G",
        "outputId": "1b45db51-d0b0-45fc-c670-a4e7047d80be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "202\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hd6Nka8YOO1z"
      },
      "outputs": [],
      "source": [
        "num_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRpdEUuIstwK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "# betas:\n",
        "# 1. weight for the moving average of gradients\n",
        "# 2. weight for the moving average of squared gradients\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  '''\n",
        "  For my experiments, scheduler was customized\n",
        "  warmup steps = 100\n",
        "  total steps = 10000\n",
        "  '''\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXZahkE3bnG6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(model, dataloader, loss_function, return_attentions, device):\n",
        "  model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100  # Last token should be ignored\n",
        "\n",
        "      outputs = model(input_ids, return_attentions=return_attentions)\n",
        "      loss = loss_function(outputs.reshape(-1, outputs.size(-1)), labels.reshape(-1))\n",
        "      ce_loss = F.cross_entropy(outputs.reshape(-1, outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  # return loss, acc, and ppl\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "978K-ktTrked",
        "outputId": "e896b450-ee1d-4699-e4df-83d70832357e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 7.5475 | Train_Accuracy : 0.0509 | Train Perplexity : 1895.9428\n",
            "Valid Loss : 7.5213 | Valid_Accuracy : 0.0402 | Valid Perplexity : 1846.9351\n",
            "Valid Loss improved from inf to 7.5213\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [01:11<58:08, 71.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 7.4909 | Train_Accuracy : 0.0731 | Train Perplexity : 1791.5800\n",
            "Valid Loss : 7.5006 | Valid_Accuracy : 0.0694 | Valid Perplexity : 1809.1408\n",
            "Valid Loss improved from 7.5213 to 7.5006\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [02:07<49:44, 62.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 7.2116 | Train_Accuracy : 0.0924 | Train Perplexity : 1355.1553\n",
            "Valid Loss : 7.2646 | Valid_Accuracy : 0.0836 | Valid Perplexity : 1428.8737\n",
            "Valid Loss improved from 7.5006 to 7.2646\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [03:02<46:28, 59.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 6.8625 | Train_Accuracy : 0.1181 | Train Perplexity : 955.7839\n",
            "Valid Loss : 6.9475 | Valid_Accuracy : 0.1097 | Valid Perplexity : 1040.5593\n",
            "Valid Loss improved from 7.2646 to 6.9475\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [03:59<44:29, 58.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 6.7888 | Train_Accuracy : 0.1184 | Train Perplexity : 887.7756\n",
            "Valid Loss : 6.8875 | Valid_Accuracy : 0.1117 | Valid Perplexity : 979.9760\n",
            "Valid Loss improved from 6.9475 to 6.8875\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [04:54<42:57, 57.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 6.5889 | Train_Accuracy : 0.1301 | Train Perplexity : 726.9883\n",
            "Valid Loss : 6.7323 | Valid_Accuracy : 0.1207 | Valid Perplexity : 839.0429\n",
            "Valid Loss improved from 6.8875 to 6.7323\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [05:50<41:39, 56.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 6.4328 | Train_Accuracy : 0.1380 | Train Perplexity : 621.9152\n",
            "Valid Loss : 6.5994 | Valid_Accuracy : 0.1239 | Valid Perplexity : 734.6417\n",
            "Valid Loss improved from 6.7323 to 6.5994\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [06:46<40:31, 56.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 6.2593 | Train_Accuracy : 0.1461 | Train Perplexity : 522.8465\n",
            "Valid Loss : 6.4769 | Valid_Accuracy : 0.1312 | Valid Perplexity : 649.9261\n",
            "Valid Loss improved from 6.5994 to 6.4769\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [07:42<39:26, 56.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 6.0755 | Train_Accuracy : 0.1547 | Train Perplexity : 435.0677\n",
            "Valid Loss : 6.3107 | Valid_Accuracy : 0.1474 | Valid Perplexity : 550.4330\n",
            "Valid Loss improved from 6.4769 to 6.3107\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [08:38<38:25, 56.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 5.9975 | Train_Accuracy : 0.1583 | Train Perplexity : 402.3921\n",
            "Valid Loss : 6.2812 | Valid_Accuracy : 0.1482 | Valid Perplexity : 534.4170\n",
            "Valid Loss improved from 6.3107 to 6.2812\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [09:34<37:26, 56.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 5.8241 | Train_Accuracy : 0.1656 | Train Perplexity : 338.3362\n",
            "Valid Loss : 6.1682 | Valid_Accuracy : 0.1539 | Valid Perplexity : 477.3394\n",
            "Valid Loss improved from 6.2812 to 6.1682\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [10:30<36:28, 56.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [11:26<35:24, 55.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 12 / 50\n",
            "Train Loss : 5.7450 | Train_Accuracy : 0.1697 | Train Perplexity : 312.6181\n",
            "Valid Loss : 6.1703 | Valid_Accuracy : 0.1542 | Valid Perplexity : 478.3222\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 5.6323 | Train_Accuracy : 0.1725 | Train Perplexity : 279.3138\n",
            "Valid Loss : 6.1253 | Valid_Accuracy : 0.1565 | Valid Perplexity : 457.3042\n",
            "Valid Loss improved from 6.1682 to 6.1253\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [12:22<34:28, 55.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 5.5117 | Train_Accuracy : 0.1779 | Train Perplexity : 247.5526\n",
            "Valid Loss : 6.0739 | Valid_Accuracy : 0.1650 | Valid Perplexity : 434.3887\n",
            "Valid Loss improved from 6.1253 to 6.0739\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [13:18<33:33, 55.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 15 / 50\n",
            "Train Loss : 5.3827 | Train_Accuracy : 0.1838 | Train Perplexity : 217.6372\n",
            "Valid Loss : 6.0377 | Valid_Accuracy : 0.1664 | Valid Perplexity : 418.9305\n",
            "Valid Loss improved from 6.0739 to 6.0377\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [14:14<32:37, 55.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 5.3394 | Train_Accuracy : 0.1871 | Train Perplexity : 208.3932\n",
            "Valid Loss : 6.0315 | Valid_Accuracy : 0.1689 | Valid Perplexity : 416.3426\n",
            "Valid Loss improved from 6.0377 to 6.0315\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [15:09<31:41, 55.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 17 / 50\n",
            "Train Loss : 5.1842 | Train_Accuracy : 0.1935 | Train Perplexity : 178.4277\n",
            "Valid Loss : 5.9809 | Valid_Accuracy : 0.1721 | Valid Perplexity : 395.8133\n",
            "Valid Loss improved from 6.0315 to 5.9809\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [16:05<30:45, 55.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 5.0416 | Train_Accuracy : 0.2013 | Train Perplexity : 154.7438\n",
            "Valid Loss : 5.9325 | Valid_Accuracy : 0.1763 | Valid Perplexity : 377.0810\n",
            "Valid Loss improved from 5.9809 to 5.9325\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [17:01<29:49, 55.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 19 / 50\n",
            "Train Loss : 4.9282 | Train_Accuracy : 0.2055 | Train Perplexity : 138.1243\n",
            "Valid Loss : 5.9312 | Valid_Accuracy : 0.1808 | Valid Perplexity : 376.5928\n",
            "Valid Loss improved from 5.9325 to 5.9312\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [17:57<28:53, 55.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 4.8709 | Train_Accuracy : 0.2098 | Train Perplexity : 130.4348\n",
            "Valid Loss : 5.9301 | Valid_Accuracy : 0.1817 | Valid Perplexity : 376.1736\n",
            "Valid Loss improved from 5.9312 to 5.9301\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [18:53<27:58, 55.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 4.7217 | Train_Accuracy : 0.2180 | Train Perplexity : 112.3518\n",
            "Valid Loss : 5.9056 | Valid_Accuracy : 0.1837 | Valid Perplexity : 367.0832\n",
            "Valid Loss improved from 5.9301 to 5.9056\n",
            "Save the Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [19:49<27:02, 55.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [20:45<26:01, 55.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 22 / 50\n",
            "Train Loss : 4.6452 | Train_Accuracy : 0.2230 | Train Perplexity : 104.0874\n",
            "Valid Loss : 5.9080 | Valid_Accuracy : 0.1842 | Valid Perplexity : 367.9825\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [21:40<25:03, 55.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 23 / 50\n",
            "Train Loss : 4.5625 | Train_Accuracy : 0.2271 | Train Perplexity : 95.8311\n",
            "Valid Loss : 5.9108 | Valid_Accuracy : 0.1828 | Valid Perplexity : 368.9868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [22:35<24:05, 55.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 24 / 50\n",
            "Train Loss : 4.4967 | Train_Accuracy : 0.2320 | Train Perplexity : 89.7276\n",
            "Valid Loss : 5.9560 | Valid_Accuracy : 0.1800 | Valid Perplexity : 386.0777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [23:31<23:08, 55.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 25 / 50\n",
            "Train Loss : 4.4115 | Train_Accuracy : 0.2378 | Train Perplexity : 82.3883\n",
            "Valid Loss : 5.9623 | Valid_Accuracy : 0.1820 | Valid Perplexity : 388.5007\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [24:26<22:12, 55.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 26 / 50\n",
            "Train Loss : 4.2855 | Train_Accuracy : 0.2480 | Train Perplexity : 72.6310\n",
            "Valid Loss : 5.9256 | Valid_Accuracy : 0.1831 | Valid Perplexity : 374.5141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [25:22<23:25, 58.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 4.1934 | Train_Accuracy : 0.2559 | Train Perplexity : 66.2398\n",
            "Valid Loss : 5.9320 | Valid_Accuracy : 0.1834 | Valid Perplexity : 376.8965\n",
            "best_epoch : 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Model training\n",
        "'''\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  model.train()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100  # Last token should be ignored\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(input_ids, return_attentions=False)\n",
        "\n",
        "    loss = loss_function(outputs.reshape(-1, outputs.size(-1)), labels.reshape(-1))\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    '''\n",
        "    In GPT type models, clip_grad_norm_ is used to avoid gradient divergence\n",
        "    Upper boundary is 1.0.\n",
        "    If gradient is over than upper boundary, scaling is applied.\n",
        "    '''\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(model, train_dataloader, loss_function, False, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(model, valid_dataloader, loss_function, False, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  '''\n",
        "  If valid loss and valid perplexity both don't reduce for six peochs,\n",
        "  early-stopping is applied.\n",
        "  '''\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_TinyGPT_checkpoint.pth')\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  else:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_epoch : {best_epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 3\n",
        "KL - logits\n",
        "\n",
        "PPL : 197.1689\n",
        "\n",
        "Best Epoch : 50"
      ],
      "metadata": {
        "id": "NDEZDPlwcBeE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwOnJE7IlhRm"
      },
      "outputs": [],
      "source": [
        "# Loss Function\n",
        "def KL_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  student_log_probs = F.log_softmax(student_logits / T, dim=-1)\n",
        "  teacher_probs = F.softmax(teacher_logits / T, dim=-1)\n",
        "  eps = 1e-8\n",
        "  KL = (teacher_probs * (torch.log(teacher_probs + eps) - student_log_probs)).sum(dim=-1)\n",
        "\n",
        "  if mask is not None:\n",
        "    KL = KL * mask\n",
        "    return (KL.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return KL.mean() * (T**2)\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.A = alpha\n",
        "    self.ignore_index = ignore_index\n",
        "    self.label_smoothing = label_smoothing\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "\n",
        "    KL_Loss = KL_divergence(student_logits, teacher_logits, self.T, mask)\n",
        "    CE_Loss = F.cross_entropy(\n",
        "        student_logits.view(-1, student_logits.size(-1)),\n",
        "        labels.view(-1),\n",
        "        ignore_index=self.ignore_index,\n",
        "        label_smoothing=self.label_smoothing\n",
        "    )\n",
        "\n",
        "    total_Loss = self.A * KL_Loss + (1 - self.A) * CE_Loss\n",
        "    return total_Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c97b113bb52d40d09d4c29e1bd392f88",
            "2a977319a5f04dff953116db5f4db07a",
            "2a7a3dd792b64a52ab86693b814f9a09",
            "d5907394166a4c739b6b6fd52556c901",
            "056e0655019343db8eca1c2068bdc513",
            "afb0724ac5ff455380ade8b6608d112c",
            "909edfef541440e0b4ce29e45e4304c2",
            "2f7782fea312438f8d69a39bcb0db2ab",
            "c38943d4a4614daeb1b50744e70d33f9",
            "cb5e3204b3944de1a218141cd82d235f",
            "e629aebb178d496996261b234efc453f",
            "0f9f207b99ce487685eb3479d37ce6f0",
            "65f5b8c5f30f40949d42bb61892a1960",
            "36cfd943b06c4cf893847e2cd16b4a5f",
            "54bc2431dda3475386ef0f889e2298f8",
            "44375289f8aa47d298f0c3abcf2b45da",
            "aed5c8449a964fc6b7baa451ff46e7ca",
            "a354829708f14e31bb4a3745f6b6197d",
            "7532071511cd463199955141ef91e578",
            "001dc42cc4d24e2a85d41f8e28432129",
            "7ad2b41c2e58441d9aae24ad42ef30ed",
            "0446b1adab0a4870a7b346c7498ca2fc"
          ]
        },
        "id": "dZxs7r09oUsW",
        "outputId": "f874b601-7309-4978-83d5-81cc18ed74e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c97b113bb52d40d09d4c29e1bd392f88"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f9f207b99ce487685eb3479d37ce6f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "# Load model and tokenizer\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=False)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model): # Functions for counting omdel's parameters\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "# Student model has about 42% parameters of teacher models\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1F6pmOcftjdM"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100  # Last token should be ignored\n",
        "\n",
        "      s_outputs = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids).logits\n",
        "      loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_outputs.reshape(-1, t_outputs.size(-1))) # 이건 나중에 shape 확인해봐야 할 듯.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  # return loss, acc, and ppl\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M743e8bv7tOK"
      },
      "outputs": [],
      "source": [
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "loss_function = TotalLoss(temperature=2.0, alpha=0.5)\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  '''\n",
        "  For my experiments, scheduler was customized\n",
        "  warmup steps = 100\n",
        "  total steps = 10000\n",
        "  '''\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8QipWQWIxqP",
        "outputId": "e9dfb6e2-0d35-4f07-b9b0-cf0482583aa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 6.2442 | Train_Accuracy : 0.0501 | Train Perplexity : 2063.3424\n",
            "Valid Loss : 6.2477 | Valid_Accuracy : 0.0428 | Valid Perplexity : 1926.4015\n",
            "Valid Loss improved from inf to 6.2477\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1926.4015\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [03:44<3:03:29, 224.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 6.2373 | Train_Accuracy : 0.0602 | Train Perplexity : 2030.3419\n",
            "Valid Loss : 6.2466 | Valid_Accuracy : 0.0488 | Valid Perplexity : 1908.4210\n",
            "Valid Loss improved from 6.2477 to 6.2466\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1926.4015 to 1908.4210\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [07:01<2:46:45, 208.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 5.8113 | Train_Accuracy : 0.0951 | Train Perplexity : 1307.4162\n",
            "Valid Loss : 5.8380 | Valid_Accuracy : 0.0873 | Valid Perplexity : 1270.0845\n",
            "Valid Loss improved from 6.2466 to 5.8380\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1908.4210 to 1270.0845\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [10:18<2:39:13, 203.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 5.6757 | Train_Accuracy : 0.1045 | Train Perplexity : 1148.3576\n",
            "Valid Loss : 5.7227 | Valid_Accuracy : 0.0972 | Valid Perplexity : 1139.3703\n",
            "Valid Loss improved from 5.8380 to 5.7227\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1270.0845 to 1139.3703\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [13:36<2:33:59, 200.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 5.5983 | Train_Accuracy : 0.1072 | Train Perplexity : 1086.0774\n",
            "Valid Loss : 5.6495 | Valid_Accuracy : 0.0967 | Valid Perplexity : 1092.7038\n",
            "Valid Loss improved from 5.7227 to 5.6495\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1139.3703 to 1092.7038\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [16:53<2:29:39, 199.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 5.2911 | Train_Accuracy : 0.1234 | Train Perplexity : 762.9445\n",
            "Valid Loss : 5.3271 | Valid_Accuracy : 0.1128 | Valid Perplexity : 764.6118\n",
            "Valid Loss improved from 5.6495 to 5.3271\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1092.7038 to 764.6118\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [20:10<2:25:39, 198.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 5.1727 | Train_Accuracy : 0.1319 | Train Perplexity : 652.5269\n",
            "Valid Loss : 5.2224 | Valid_Accuracy : 0.1156 | Valid Perplexity : 675.0579\n",
            "Valid Loss improved from 5.3271 to 5.2224\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 764.6118 to 675.0579\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [23:27<2:21:59, 198.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 5.0386 | Train_Accuracy : 0.1369 | Train Perplexity : 562.7912\n",
            "Valid Loss : 5.1043 | Valid_Accuracy : 0.1222 | Valid Perplexity : 597.8781\n",
            "Valid Loss improved from 5.2224 to 5.1043\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 675.0579 to 597.8781\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [26:44<2:18:27, 197.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 4.9628 | Train_Accuracy : 0.1413 | Train Perplexity : 508.2776\n",
            "Valid Loss : 5.0046 | Valid_Accuracy : 0.1259 | Valid Perplexity : 530.9361\n",
            "Valid Loss improved from 5.1043 to 5.0046\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 597.8781 to 530.9361\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [30:01<2:15:05, 197.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 4.9147 | Train_Accuracy : 0.1428 | Train Perplexity : 478.7672\n",
            "Valid Loss : 4.9704 | Valid_Accuracy : 0.1307 | Valid Perplexity : 509.9682\n",
            "Valid Loss improved from 5.0046 to 4.9704\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 530.9361 to 509.9682\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [33:18<2:11:39, 197.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 4.7895 | Train_Accuracy : 0.1545 | Train Perplexity : 408.7457\n",
            "Valid Loss : 4.8613 | Valid_Accuracy : 0.1468 | Valid Perplexity : 446.5117\n",
            "Valid Loss improved from 4.9704 to 4.8613\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 509.9682 to 446.5117\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [36:35<2:08:16, 197.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 4.7085 | Train_Accuracy : 0.1586 | Train Perplexity : 371.9416\n",
            "Valid Loss : 4.8157 | Valid_Accuracy : 0.1494 | Valid Perplexity : 427.2878\n",
            "Valid Loss improved from 4.8613 to 4.8157\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 446.5117 to 427.2878\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [39:52<2:04:53, 197.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 4.6334 | Train_Accuracy : 0.1639 | Train Perplexity : 336.6635\n",
            "Valid Loss : 4.7510 | Valid_Accuracy : 0.1590 | Valid Perplexity : 395.0213\n",
            "Valid Loss improved from 4.8157 to 4.7510\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 427.2878 to 395.0213\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [43:10<2:01:41, 197.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 4.5419 | Train_Accuracy : 0.1682 | Train Perplexity : 302.3479\n",
            "Valid Loss : 4.6994 | Valid_Accuracy : 0.1553 | Valid Perplexity : 376.4525\n",
            "Valid Loss improved from 4.7510 to 4.6994\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 395.0213 to 376.4525\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [46:27<1:58:22, 197.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 15 / 50\n",
            "Train Loss : 4.5062 | Train_Accuracy : 0.1730 | Train Perplexity : 284.3926\n",
            "Valid Loss : 4.6775 | Valid_Accuracy : 0.1576 | Valid Perplexity : 361.0871\n",
            "Valid Loss improved from 4.6994 to 4.6775\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 376.4525 to 361.0871\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [49:44<1:55:04, 197.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 4.4578 | Train_Accuracy : 0.1768 | Train Perplexity : 266.7207\n",
            "Valid Loss : 4.6287 | Valid_Accuracy : 0.1630 | Valid Perplexity : 341.5499\n",
            "Valid Loss improved from 4.6775 to 4.6287\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 361.0871 to 341.5499\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [53:01<1:51:44, 197.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 17 / 50\n",
            "Train Loss : 4.3501 | Train_Accuracy : 0.1820 | Train Perplexity : 234.1337\n",
            "Valid Loss : 4.5600 | Valid_Accuracy : 0.1670 | Valid Perplexity : 315.6868\n",
            "Valid Loss improved from 4.6287 to 4.5600\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 341.5499 to 315.6868\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [56:18<1:48:26, 197.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 4.3187 | Train_Accuracy : 0.1852 | Train Perplexity : 222.5420\n",
            "Valid Loss : 4.5405 | Valid_Accuracy : 0.1721 | Valid Perplexity : 307.3681\n",
            "Valid Loss improved from 4.5600 to 4.5405\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 315.6868 to 307.3681\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [59:36<1:45:09, 197.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [1:02:51<1:41:38, 196.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 19 / 50\n",
            "Train Loss : 4.2894 | Train_Accuracy : 0.1870 | Train Perplexity : 212.9915\n",
            "Valid Loss : 4.5449 | Valid_Accuracy : 0.1712 | Valid Perplexity : 310.7553\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 4.2319 | Train_Accuracy : 0.1915 | Train Perplexity : 196.8945\n",
            "Valid Loss : 4.4971 | Valid_Accuracy : 0.1797 | Valid Perplexity : 292.0945\n",
            "Valid Loss improved from 4.5405 to 4.4971\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 307.3681 to 292.0945\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:06:08<1:38:22, 196.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 4.1549 | Train_Accuracy : 0.1984 | Train Perplexity : 177.4406\n",
            "Valid Loss : 4.4482 | Valid_Accuracy : 0.1842 | Valid Perplexity : 275.6696\n",
            "Valid Loss improved from 4.4971 to 4.4482\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 292.0945 to 275.6696\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:09:25<1:35:10, 196.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:12:41<1:31:46, 196.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 22 / 50\n",
            "Train Loss : 4.1391 | Train_Accuracy : 0.2001 | Train Perplexity : 171.4342\n",
            "Valid Loss : 4.4491 | Valid_Accuracy : 0.1780 | Valid Perplexity : 275.8296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:15:57<1:28:21, 196.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 23 / 50\n",
            "Train Loss : 4.0966 | Train_Accuracy : 0.2027 | Train Perplexity : 161.9411\n",
            "Valid Loss : 4.4509 | Valid_Accuracy : 0.1811 | Valid Perplexity : 275.9520\n",
            "Epoch : 24 / 50\n",
            "Train Loss : 4.0185 | Train_Accuracy : 0.2104 | Train Perplexity : 145.4919\n",
            "Valid Loss : 4.3760 | Valid_Accuracy : 0.1913 | Valid Perplexity : 252.6243\n",
            "Valid Loss improved from 4.4482 to 4.3760\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 275.6696 to 252.6243\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:19:14<1:25:10, 196.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:22:30<1:21:48, 196.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 25 / 50\n",
            "Train Loss : 4.0356 | Train_Accuracy : 0.2083 | Train Perplexity : 147.8098\n",
            "Valid Loss : 4.4395 | Valid_Accuracy : 0.1828 | Valid Perplexity : 272.6068\n",
            "Epoch : 26 / 50\n",
            "Train Loss : 3.9318 | Train_Accuracy : 0.2191 | Train Perplexity : 128.3525\n",
            "Valid Loss : 4.3317 | Valid_Accuracy : 0.1947 | Valid Perplexity : 241.6565\n",
            "Valid Loss improved from 4.3760 to 4.3317\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 252.6243 to 241.6565\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:25:47<1:18:37, 196.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:29:03<1:15:17, 196.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 3.9338 | Train_Accuracy : 0.2200 | Train Perplexity : 126.8443\n",
            "Valid Loss : 4.3476 | Valid_Accuracy : 0.1976 | Valid Perplexity : 245.4407\n",
            "Epoch : 28 / 50\n",
            "Train Loss : 3.8930 | Train_Accuracy : 0.2238 | Train Perplexity : 120.0645\n",
            "Valid Loss : 4.3271 | Valid_Accuracy : 0.1930 | Valid Perplexity : 240.4312\n",
            "Valid Loss improved from 4.3317 to 4.3271\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 241.6565 to 240.4312\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:32:21<1:12:09, 196.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:35:37<1:08:46, 196.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 29 / 50\n",
            "Train Loss : 3.8721 | Train_Accuracy : 0.2273 | Train Perplexity : 115.5975\n",
            "Valid Loss : 4.3357 | Valid_Accuracy : 0.1944 | Valid Perplexity : 240.8302\n",
            "Epoch : 30 / 50\n",
            "Train Loss : 3.7985 | Train_Accuracy : 0.2347 | Train Perplexity : 104.6445\n",
            "Valid Loss : 4.2869 | Valid_Accuracy : 0.1916 | Valid Perplexity : 229.7992\n",
            "Valid Loss improved from 4.3271 to 4.2869\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 240.4312 to 229.7992\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:38:53<1:05:31, 196.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 31 / 50\n",
            "Train Loss : 3.7943 | Train_Accuracy : 0.2358 | Train Perplexity : 102.9419\n",
            "Valid Loss : 4.2724 | Valid_Accuracy : 0.1973 | Valid Perplexity : 223.8889\n",
            "Valid Loss improved from 4.2869 to 4.2724\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 229.7992 to 223.8889\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:42:10<1:02:17, 196.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 32 / 50\n",
            "Train Loss : 3.7528 | Train_Accuracy : 0.2411 | Train Perplexity : 97.1360\n",
            "Valid Loss : 4.2576 | Valid_Accuracy : 0.1998 | Valid Perplexity : 220.3744\n",
            "Valid Loss improved from 4.2724 to 4.2576\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 223.8889 to 220.3744\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:45:27<59:01, 196.73s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:48:43<55:40, 196.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 33 / 50\n",
            "Train Loss : 3.7279 | Train_Accuracy : 0.2441 | Train Perplexity : 93.4969\n",
            "Valid Loss : 4.2617 | Valid_Accuracy : 0.1976 | Valid Perplexity : 221.4886\n",
            "Epoch : 34 / 50\n",
            "Train Loss : 3.7100 | Train_Accuracy : 0.2469 | Train Perplexity : 90.7627\n",
            "Valid Loss : 4.2356 | Valid_Accuracy : 0.2021 | Valid Perplexity : 214.8608\n",
            "Valid Loss improved from 4.2576 to 4.2356\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 220.3744 to 214.8608\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [1:52:00<52:26, 196.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 35 / 50\n",
            "Train Loss : 3.6765 | Train_Accuracy : 0.2511 | Train Perplexity : 86.6065\n",
            "Valid Loss : 4.2349 | Valid_Accuracy : 0.1987 | Valid Perplexity : 214.6524\n",
            "Valid Loss improved from 4.2356 to 4.2349\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 214.8608 to 214.6524\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [1:55:18<49:14, 197.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 36 / 50\n",
            "Train Loss : 3.6671 | Train_Accuracy : 0.2530 | Train Perplexity : 84.8984\n",
            "Valid Loss : 4.2273 | Valid_Accuracy : 0.2027 | Valid Perplexity : 212.1157\n",
            "Valid Loss improved from 4.2349 to 4.2273\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 214.6524 to 212.1157\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [1:58:35<45:59, 197.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 37 / 50\n",
            "Train Loss : 3.6453 | Train_Accuracy : 0.2556 | Train Perplexity : 82.2292\n",
            "Valid Loss : 4.2155 | Valid_Accuracy : 0.2018 | Valid Perplexity : 209.7125\n",
            "Valid Loss improved from 4.2273 to 4.2155\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 212.1157 to 209.7125\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [2:01:52<42:42, 197.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 38 / 50\n",
            "Train Loss : 3.6182 | Train_Accuracy : 0.2592 | Train Perplexity : 79.1338\n",
            "Valid Loss : 4.1992 | Valid_Accuracy : 0.2049 | Valid Perplexity : 205.6901\n",
            "Valid Loss improved from 4.2155 to 4.1992\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 209.7125 to 205.6901\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [2:05:10<39:25, 197.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [2:08:25<36:03, 196.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 39 / 50\n",
            "Train Loss : 3.6162 | Train_Accuracy : 0.2598 | Train Perplexity : 78.6800\n",
            "Valid Loss : 4.2123 | Valid_Accuracy : 0.2069 | Valid Perplexity : 208.6089\n",
            "Epoch : 40 / 50\n",
            "Train Loss : 3.5956 | Train_Accuracy : 0.2626 | Train Perplexity : 76.2630\n",
            "Valid Loss : 4.1911 | Valid_Accuracy : 0.2089 | Valid Perplexity : 203.2323\n",
            "Valid Loss improved from 4.1992 to 4.1911\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 205.6901 to 203.2323\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [2:11:42<32:47, 196.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 41 / 50\n",
            "Train Loss : 3.5864 | Train_Accuracy : 0.2640 | Train Perplexity : 75.1793\n",
            "Valid Loss : 4.1895 | Valid_Accuracy : 0.2095 | Valid Perplexity : 203.0633\n",
            "Valid Loss improved from 4.1911 to 4.1895\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 203.2323 to 203.0633\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [2:14:59<29:32, 196.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 42 / 50\n",
            "Train Loss : 3.5790 | Train_Accuracy : 0.2653 | Train Perplexity : 74.1352\n",
            "Valid Loss : 4.1828 | Valid_Accuracy : 0.2083 | Valid Perplexity : 201.2229\n",
            "Valid Loss improved from 4.1895 to 4.1828\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 203.0633 to 201.2229\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [2:18:17<26:15, 196.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [2:21:32<22:56, 196.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 43 / 50\n",
            "Train Loss : 3.5806 | Train_Accuracy : 0.2657 | Train Perplexity : 74.0266\n",
            "Valid Loss : 4.1904 | Valid_Accuracy : 0.2058 | Valid Perplexity : 203.1634\n",
            "Epoch : 44 / 50\n",
            "Train Loss : 3.5642 | Train_Accuracy : 0.2678 | Train Perplexity : 72.3286\n",
            "Valid Loss : 4.1721 | Valid_Accuracy : 0.2038 | Valid Perplexity : 198.5810\n",
            "Valid Loss improved from 4.1828 to 4.1721\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 201.2229 to 198.5810\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [2:24:50<19:40, 196.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [2:28:05<16:22, 196.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 45 / 50\n",
            "Train Loss : 3.5624 | Train_Accuracy : 0.2679 | Train Perplexity : 71.9185\n",
            "Valid Loss : 4.1797 | Valid_Accuracy : 0.2072 | Valid Perplexity : 200.8778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [2:31:21<13:05, 196.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 46 / 50\n",
            "Train Loss : 3.5519 | Train_Accuracy : 0.2694 | Train Perplexity : 70.8803\n",
            "Valid Loss : 4.1746 | Valid_Accuracy : 0.2072 | Valid Perplexity : 199.7862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [2:34:37<09:48, 196.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 47 / 50\n",
            "Train Loss : 3.5452 | Train_Accuracy : 0.2705 | Train Perplexity : 70.2037\n",
            "Valid Loss : 4.1778 | Valid_Accuracy : 0.2080 | Valid Perplexity : 200.5692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [2:37:53<06:32, 196.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 48 / 50\n",
            "Train Loss : 3.5401 | Train_Accuracy : 0.2714 | Train Perplexity : 69.3918\n",
            "Valid Loss : 4.1741 | Valid_Accuracy : 0.2078 | Valid Perplexity : 199.7538\n",
            "Epoch : 49 / 50\n",
            "Train Loss : 3.5332 | Train_Accuracy : 0.2722 | Train Perplexity : 68.6715\n",
            "Valid Loss : 4.1696 | Valid_Accuracy : 0.2069 | Valid Perplexity : 198.2910\n",
            "Valid Loss improved from 4.1721 to 4.1696\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 198.5810 to 198.2910\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [2:41:10<03:16, 196.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "Epoch : 50 / 50\n",
            "Train Loss : 3.5242 | Train_Accuracy : 0.2739 | Train Perplexity : 67.7393\n",
            "Valid Loss : 4.1641 | Valid_Accuracy : 0.2069 | Valid Perplexity : 197.1689\n",
            "Valid Loss improved from 4.1696 to 4.1641\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 198.2910 to 197.1689\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [2:44:27<00:00, 197.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_TinyGPT_checkpoint.pth\n",
            "best_loss_epoch : 50\n",
            "best_ppl_epoch : 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Training\n",
        "'''\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_loss_epoch = 0\n",
        "best_valid_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "best_ppl = float('inf')\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100  # Last token should be ignored\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs = student_model(input_ids, return_attentions=False)\n",
        "    t_outputs = teacher_model(input_ids).logits\n",
        "\n",
        "    loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_outputs.reshape(-1, t_outputs.size(-1)))\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, False, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, False, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_KD_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_ppl_KD_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 4\n",
        "MSE - layerwise & KL - Logits\n",
        "\n",
        "PPL: 203.9260\n",
        "\n",
        "Best Epoch: 50"
      ],
      "metadata": {
        "id": "VnACQiaShQqs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOa39tyWhnGi"
      },
      "outputs": [],
      "source": [
        "# Loss Function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def KL_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  student_log_probs = F.log_softmax(student_logits / T, dim=-1)\n",
        "  teacher_probs = F.softmax(teacher_logits / T, dim=-1)\n",
        "  eps = 1e-8\n",
        "  KL = (teacher_probs * (torch.log(teacher_probs + eps) - student_log_probs)).sum(dim=-1)\n",
        "\n",
        "  if mask is not None:\n",
        "    KL = KL * mask\n",
        "    return (KL.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return KL.mean() * (T**2)\n",
        "\n",
        "class KD_Loss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.A = alpha\n",
        "    self.ignore_index = ignore_index\n",
        "    self.label_smoothing = label_smoothing\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    KL_Loss = KL_divergence(student_logits, teacher_logits, self.T, mask)\n",
        "    CE_Loss = F.cross_entropy(student_logits, labels, ignore_index=self.ignore_index, label_smoothing=self.label_smoothing)\n",
        "    total_Loss = self.A * KL_Loss + (1 - self.A) * CE_Loss\n",
        "    return total_Loss\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "  return attn.mean(dim=1)\n",
        "\n",
        "def MSE(s_attn, t_attn):\n",
        "  '''\n",
        "  s_attn : student attention list\n",
        "  t_attn : teacher_attention list\n",
        "  Each len means the number of layer of each model.\n",
        "  '''\n",
        "  assert len(t_attn) % 2 == 0, 'Len of teacher attention layers must be divisible by 2.'\n",
        "  loss = 0.0\n",
        "  num_s_layer = len(s_attn)\n",
        "  num_t_layer = len(t_attn)\n",
        "  idx_list = []\n",
        "  t_attn_list = []\n",
        "\n",
        "  if 2 * num_s_layer == num_t_layer:\n",
        "    for i in range(num_s_layer):\n",
        "      t_attn_list.append(t_attn[2*i+1]) # Save the odd layer of teacher\n",
        "  elif 2 * num_s_layer > num_t_layer:\n",
        "    for i in range(num_s_layer):\n",
        "      if 2*i + 1 >= num_t_layer:\n",
        "        break\n",
        "      idx_list.append(2*i+1) # First, save the odd layer of teacher\n",
        "    while len(idx_list) < num_s_layer: # Until saved index == the number of student layer\n",
        "      for i in range(num_t_layer - 2, -1, -2): # From the last, which should not be saved before\n",
        "        if i not in idx_list:\n",
        "          idx_list.append(i)\n",
        "        if len(idx_list) == num_s_layer:\n",
        "          break\n",
        "    idx_list.sort() # Sort the order\n",
        "    for idx in idx_list: # Saved indexes saved to pick the teacher's layers\n",
        "      t_attn_list.append(t_attn[idx])\n",
        "  elif 2 * num_s_layer < num_t_layer:\n",
        "    for i in range(num_t_layer-1, -1, -2): # From the last, layers are saved. interval = 2\n",
        "      if len(idx_list) == 2 * num_s_layer:\n",
        "        break\n",
        "      idx_list.append(i)\n",
        "    idx_list.sort() # Sort the order\n",
        "    for idx in idx_list:\n",
        "      t_attn_list.append(t_attn[idx])\n",
        "  assert num_s_layer == len(t_attn_list), f'Len of t_attn_list ({len(t_attn_list)}) do no match len of s_attn ({num_s_layer})'\n",
        "  for i in range(num_s_layer): # Applying MSE Loss\n",
        "    loss += torch.mean((average_head(s_attn[i]) - average_head(t_attn_list[i])) ** 2)\n",
        "  loss /= num_s_layer\n",
        "  return loss\n",
        "\n",
        "class MSE_Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, s_attn, t_attn):\n",
        "    loss = MSE(s_attn, t_attn)\n",
        "    return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, beta, label_smoothing=0.1 ,ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.B = beta\n",
        "    self.ignore_index = ignore_index\n",
        "    self.kd_loss = KD_Loss(temperature, alpha, label_smoothing, ignore_index=ignore_index)\n",
        "    self.mse = MSE_Loss()\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits, s_attn, t_attn):\n",
        "    kd_l = self.kd_loss(student_logits, labels, teacher_logits)\n",
        "    mse_l = self.mse(s_attn, t_attn)\n",
        "    total_loss = kd_l + self.B * mse_l\n",
        "    return total_loss, kd_l, mse_l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b8307eaef7be4b7186acc604eb5b614b",
            "2e48a7c9258c42bab5a29315a28e6427",
            "d6f254716b5a4adfbd6b45a06dcfc50c",
            "023574f845cb49a89a170b26d3933096",
            "bbcf1c46132440059997eebdce4461ed",
            "2c4da9dbaa7d4807b0319cd3c954e190",
            "5dbc733cdd034cb9bb59fa4c77c1d57f",
            "f3a221aa60184e5a9287c8aef78d5b25",
            "9b2df2fd96d64948a2758c49b8b3b5aa",
            "f15df1a0f49f42538da75535abab3593",
            "8b4a255ec4214f8da122027897987cc7",
            "fb0c5cab42be48478abd9df57bfbd3b2",
            "6cbe91108c4b4d7e92ad569728bf99f5",
            "222a8eb46e7141f0bafad41af6ec0883",
            "8e61f17685454160ae19a2ebcb85872c",
            "ca6f4011afc34afc9a34498644d54ada",
            "78409485160044599c4b5dd53345cbce",
            "d1ad56ada0c24f5ab8f2df6a2c8c0852",
            "71bfc2a93c5d4a9ea5eb9953c4fc1443",
            "376cfbc96ae6474ba6ee7243eb93f670",
            "12a7912b098d434da6327d6fb02cf42f",
            "8d302843288942c18ecd447b2b2a9d4f"
          ]
        },
        "id": "4u_emsrdhnJP",
        "outputId": "666af538-4829-47eb-ef7d-c1a175219f5a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8307eaef7be4b7186acc604eb5b614b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb0c5cab42be48478abd9df57bfbd3b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Load model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtR0H4GoxerC"
      },
      "outputs": [],
      "source": [
        "# Setting epochs, loss function, optimizer, and scheduler\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# alpha : KL-Divergence & CE Loss(1-alpha), beta : MSE\n",
        "loss_function = TotalLoss(temperature=2.0, alpha=0.5, beta=0.05)\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4uq4oP0hnLa"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss, _, _ = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-Ix5Cpr0QUH",
        "outputId": "8418854c-d10b-42e3-db58-ff509e8bf615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 6.2444 | Train_Accuracy : 0.0501 | Train Perplexity : 2063.3408\n",
            "Valid Loss : 6.2478 | Valid_Accuracy : 0.0428 | Valid Perplexity : 1926.4015\n",
            "Valid Loss improved from inf to 6.2478\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1926.4015\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [03:49<3:07:30, 229.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 6.2376 | Train_Accuracy : 0.0601 | Train Perplexity : 2030.5028\n",
            "Valid Loss : 6.2470 | Valid_Accuracy : 0.0482 | Valid Perplexity : 1908.6492\n",
            "Valid Loss improved from 6.2478 to 6.2470\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1926.4015 to 1908.6492\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [07:13<2:51:26, 214.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 5.8931 | Train_Accuracy : 0.0929 | Train Perplexity : 1377.7104\n",
            "Valid Loss : 5.9275 | Valid_Accuracy : 0.0870 | Valid Perplexity : 1362.2171\n",
            "Valid Loss improved from 6.2470 to 5.9275\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1908.6492 to 1362.2171\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [10:36<2:44:03, 209.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 5.6042 | Train_Accuracy : 0.1068 | Train Perplexity : 1088.8152\n",
            "Valid Loss : 5.6521 | Valid_Accuracy : 0.0981 | Valid Perplexity : 1081.6924\n",
            "Valid Loss improved from 5.9275 to 5.6521\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1362.2171 to 1081.6924\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [14:00<2:38:54, 207.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 5.5111 | Train_Accuracy : 0.1089 | Train Perplexity : 993.4773\n",
            "Valid Loss : 5.5580 | Valid_Accuracy : 0.0944 | Valid Perplexity : 1000.9227\n",
            "Valid Loss improved from 5.6521 to 5.5580\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1081.6924 to 1000.9227\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [17:24<2:34:28, 205.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 5.3931 | Train_Accuracy : 0.1217 | Train Perplexity : 829.5533\n",
            "Valid Loss : 5.4299 | Valid_Accuracy : 0.1128 | Valid Perplexity : 832.1236\n",
            "Valid Loss improved from 5.5580 to 5.4299\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1000.9227 to 832.1236\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [20:48<2:30:28, 205.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 5.2010 | Train_Accuracy : 0.1278 | Train Perplexity : 678.5131\n",
            "Valid Loss : 5.2418 | Valid_Accuracy : 0.1120 | Valid Perplexity : 690.3789\n",
            "Valid Loss improved from 5.4299 to 5.2418\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 832.1236 to 690.3789\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [24:11<2:26:40, 204.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 5.0958 | Train_Accuracy : 0.1318 | Train Perplexity : 604.4734\n",
            "Valid Loss : 5.1691 | Valid_Accuracy : 0.1176 | Valid Perplexity : 641.4207\n",
            "Valid Loss improved from 5.2418 to 5.1691\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 690.3789 to 641.4207\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [27:35<2:23:08, 204.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 4.9302 | Train_Accuracy : 0.1446 | Train Perplexity : 492.0752\n",
            "Valid Loss : 4.9747 | Valid_Accuracy : 0.1301 | Valid Perplexity : 508.4660\n",
            "Valid Loss improved from 5.1691 to 4.9747\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 641.4207 to 508.4660\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [30:59<2:19:34, 204.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 4.8807 | Train_Accuracy : 0.1447 | Train Perplexity : 469.1366\n",
            "Valid Loss : 4.9505 | Valid_Accuracy : 0.1344 | Valid Perplexity : 506.8253\n",
            "Valid Loss improved from 4.9747 to 4.9505\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 508.4660 to 506.8253\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [34:22<2:15:57, 203.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 4.7753 | Train_Accuracy : 0.1553 | Train Perplexity : 403.0857\n",
            "Valid Loss : 4.8337 | Valid_Accuracy : 0.1477 | Valid Perplexity : 429.2709\n",
            "Valid Loss improved from 4.9505 to 4.8337\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 506.8253 to 429.2709\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [37:46<2:12:32, 203.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [41:09<2:08:52, 203.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 12 / 50\n",
            "Train Loss : 4.7319 | Train_Accuracy : 0.1559 | Train Perplexity : 385.2796\n",
            "Valid Loss : 4.8346 | Valid_Accuracy : 0.1468 | Valid Perplexity : 434.2401\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 4.6232 | Train_Accuracy : 0.1629 | Train Perplexity : 336.4041\n",
            "Valid Loss : 4.7315 | Valid_Accuracy : 0.1582 | Valid Perplexity : 388.6100\n",
            "Valid Loss improved from 4.8337 to 4.7315\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 429.2709 to 388.6100\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [44:32<2:05:30, 203.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [47:55<2:01:56, 203.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 14 / 50\n",
            "Train Loss : 4.5981 | Train_Accuracy : 0.1641 | Train Perplexity : 323.9133\n",
            "Valid Loss : 4.7430 | Valid_Accuracy : 0.1474 | Valid Perplexity : 391.7067\n",
            "Epoch : 15 / 50\n",
            "Train Loss : 4.5931 | Train_Accuracy : 0.1682 | Train Perplexity : 313.9097\n",
            "Valid Loss : 4.7411 | Valid_Accuracy : 0.1610 | Valid Perplexity : 384.1965\n",
            "Valid Perplexity improved from 388.6100 to 384.1965\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [51:18<1:58:30, 203.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 4.4134 | Train_Accuracy : 0.1778 | Train Perplexity : 255.8550\n",
            "Valid Loss : 4.5970 | Valid_Accuracy : 0.1641 | Valid Perplexity : 331.3598\n",
            "Valid Loss improved from 4.7315 to 4.5970\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 384.1965 to 331.3598\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [54:41<1:55:10, 203.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [58:04<1:51:40, 203.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 17 / 50\n",
            "Train Loss : 4.4668 | Train_Accuracy : 0.1777 | Train Perplexity : 266.0713\n",
            "Valid Loss : 4.6292 | Valid_Accuracy : 0.1701 | Valid Perplexity : 338.6330\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 4.3269 | Train_Accuracy : 0.1850 | Train Perplexity : 225.5039\n",
            "Valid Loss : 4.5555 | Valid_Accuracy : 0.1740 | Valid Perplexity : 311.2886\n",
            "Valid Loss improved from 4.5970 to 4.5555\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 331.3598 to 311.2886\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [1:01:28<1:48:24, 203.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [1:04:50<1:44:55, 203.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 19 / 50\n",
            "Train Loss : 4.3086 | Train_Accuracy : 0.1831 | Train Perplexity : 219.4175\n",
            "Valid Loss : 4.5858 | Valid_Accuracy : 0.1672 | Valid Perplexity : 326.9259\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 4.2597 | Train_Accuracy : 0.1900 | Train Perplexity : 203.4699\n",
            "Valid Loss : 4.5086 | Valid_Accuracy : 0.1752 | Valid Perplexity : 296.2925\n",
            "Valid Loss improved from 4.5555 to 4.5086\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 311.2886 to 296.2925\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:08:14<1:41:37, 203.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 4.1812 | Train_Accuracy : 0.1962 | Train Perplexity : 183.4688\n",
            "Valid Loss : 4.4729 | Valid_Accuracy : 0.1777 | Valid Perplexity : 282.3140\n",
            "Valid Loss improved from 4.5086 to 4.4729\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 296.2925 to 282.3140\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:11:38<1:38:21, 203.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 22 / 50\n",
            "Train Loss : 4.1329 | Train_Accuracy : 0.2003 | Train Perplexity : 171.4249\n",
            "Valid Loss : 4.4418 | Valid_Accuracy : 0.1857 | Valid Perplexity : 275.1564\n",
            "Valid Loss improved from 4.4729 to 4.4418\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 282.3140 to 275.1564\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:15:02<1:35:01, 203.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 23 / 50\n",
            "Train Loss : 4.1148 | Train_Accuracy : 0.2014 | Train Perplexity : 166.1341\n",
            "Valid Loss : 4.4387 | Valid_Accuracy : 0.1803 | Valid Perplexity : 272.5435\n",
            "Valid Loss improved from 4.4418 to 4.4387\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 275.1564 to 272.5435\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:18:26<1:31:41, 203.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 24 / 50\n",
            "Train Loss : 4.0521 | Train_Accuracy : 0.2071 | Train Perplexity : 152.8594\n",
            "Valid Loss : 4.4108 | Valid_Accuracy : 0.1868 | Valid Perplexity : 264.7332\n",
            "Valid Loss improved from 4.4387 to 4.4108\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 272.5435 to 264.7332\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:21:50<1:28:17, 203.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:25:12<1:24:46, 203.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 25 / 50\n",
            "Train Loss : 4.0370 | Train_Accuracy : 0.2081 | Train Perplexity : 148.3781\n",
            "Valid Loss : 4.4204 | Valid_Accuracy : 0.1851 | Valid Perplexity : 265.9631\n",
            "Epoch : 26 / 50\n",
            "Train Loss : 3.9557 | Train_Accuracy : 0.2168 | Train Perplexity : 132.9019\n",
            "Valid Loss : 4.3551 | Valid_Accuracy : 0.1922 | Valid Perplexity : 247.7954\n",
            "Valid Loss improved from 4.4108 to 4.3551\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 264.7332 to 247.7954\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:28:36<1:21:26, 203.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:31:59<1:17:58, 203.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 3.9572 | Train_Accuracy : 0.2171 | Train Perplexity : 131.8020\n",
            "Valid Loss : 4.3634 | Valid_Accuracy : 0.1936 | Valid Perplexity : 250.5443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:35:22<1:14:29, 203.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 28 / 50\n",
            "Train Loss : 3.9540 | Train_Accuracy : 0.2177 | Train Perplexity : 130.3412\n",
            "Valid Loss : 4.3699 | Valid_Accuracy : 0.1950 | Valid Perplexity : 251.8607\n",
            "Epoch : 29 / 50\n",
            "Train Loss : 3.8755 | Train_Accuracy : 0.2264 | Train Perplexity : 116.8544\n",
            "Valid Loss : 4.3265 | Valid_Accuracy : 0.1978 | Valid Perplexity : 239.3243\n",
            "Valid Loss improved from 4.3551 to 4.3265\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 247.7954 to 239.3243\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:38:46<1:11:11, 203.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 30 / 50\n",
            "Train Loss : 3.8311 | Train_Accuracy : 0.2313 | Train Perplexity : 109.8680\n",
            "Valid Loss : 4.3057 | Valid_Accuracy : 0.1973 | Valid Perplexity : 234.5951\n",
            "Valid Loss improved from 4.3265 to 4.3057\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 239.3243 to 234.5951\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:42:10<1:07:50, 203.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 31 / 50\n",
            "Train Loss : 3.8055 | Train_Accuracy : 0.2340 | Train Perplexity : 105.3471\n",
            "Valid Loss : 4.2849 | Valid_Accuracy : 0.2041 | Valid Perplexity : 228.2604\n",
            "Valid Loss improved from 4.3057 to 4.2849\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 234.5951 to 228.2604\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:45:34<1:04:28, 203.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 32 / 50\n",
            "Train Loss : 3.7674 | Train_Accuracy : 0.2391 | Train Perplexity : 99.8745\n",
            "Valid Loss : 4.2678 | Valid_Accuracy : 0.2044 | Valid Perplexity : 223.4226\n",
            "Valid Loss improved from 4.2849 to 4.2678\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 228.2604 to 223.4226\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:48:58<1:01:07, 203.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:52:20<57:39, 203.48s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 33 / 50\n",
            "Train Loss : 3.7541 | Train_Accuracy : 0.2415 | Train Perplexity : 97.2859\n",
            "Valid Loss : 4.2781 | Valid_Accuracy : 0.2021 | Valid Perplexity : 226.6707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [1:55:43<54:12, 203.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 34 / 50\n",
            "Train Loss : 3.7386 | Train_Accuracy : 0.2433 | Train Perplexity : 95.0138\n",
            "Valid Loss : 4.2686 | Valid_Accuracy : 0.2058 | Valid Perplexity : 224.7556\n",
            "Epoch : 35 / 50\n",
            "Train Loss : 3.7119 | Train_Accuracy : 0.2470 | Train Perplexity : 91.1020\n",
            "Valid Loss : 4.2558 | Valid_Accuracy : 0.2078 | Valid Perplexity : 220.5823\n",
            "Valid Loss improved from 4.2678 to 4.2558\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 223.4226 to 220.5823\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [1:59:07<50:51, 203.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 36 / 50\n",
            "Train Loss : 3.6841 | Train_Accuracy : 0.2507 | Train Perplexity : 87.3132\n",
            "Valid Loss : 4.2421 | Valid_Accuracy : 0.2086 | Valid Perplexity : 216.8481\n",
            "Valid Loss improved from 4.2558 to 4.2421\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 220.5823 to 216.8481\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [2:02:31<47:30, 203.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 37 / 50\n",
            "Train Loss : 3.6650 | Train_Accuracy : 0.2532 | Train Perplexity : 84.8221\n",
            "Valid Loss : 4.2338 | Valid_Accuracy : 0.2080 | Valid Perplexity : 215.1179\n",
            "Valid Loss improved from 4.2421 to 4.2338\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 216.8481 to 215.1179\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [2:05:55<44:09, 203.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 38 / 50\n",
            "Train Loss : 3.6460 | Train_Accuracy : 0.2557 | Train Perplexity : 82.3976\n",
            "Valid Loss : 4.2196 | Valid_Accuracy : 0.2063 | Valid Perplexity : 210.9752\n",
            "Valid Loss improved from 4.2338 to 4.2196\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 215.1179 to 210.9752\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [2:09:19<40:45, 203.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [2:12:42<37:17, 203.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 39 / 50\n",
            "Train Loss : 3.6357 | Train_Accuracy : 0.2572 | Train Perplexity : 81.1368\n",
            "Valid Loss : 4.2288 | Valid_Accuracy : 0.2089 | Valid Perplexity : 214.0383\n",
            "Epoch : 40 / 50\n",
            "Train Loss : 3.6178 | Train_Accuracy : 0.2599 | Train Perplexity : 79.0497\n",
            "Valid Loss : 4.2132 | Valid_Accuracy : 0.2095 | Valid Perplexity : 209.9312\n",
            "Valid Loss improved from 4.2196 to 4.2132\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 210.9752 to 209.9312\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [2:16:06<33:55, 203.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 41 / 50\n",
            "Train Loss : 3.6094 | Train_Accuracy : 0.2611 | Train Perplexity : 78.0410\n",
            "Valid Loss : 4.2087 | Valid_Accuracy : 0.2112 | Valid Perplexity : 209.3263\n",
            "Valid Loss improved from 4.2132 to 4.2087\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 209.9312 to 209.3263\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [2:19:29<30:32, 203.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 42 / 50\n",
            "Train Loss : 3.6026 | Train_Accuracy : 0.2621 | Train Perplexity : 77.0150\n",
            "Valid Loss : 4.2099 | Valid_Accuracy : 0.2106 | Valid Perplexity : 208.9846\n",
            "Valid Perplexity improved from 209.3263 to 208.9846\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [2:22:53<27:08, 203.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 43 / 50\n",
            "Train Loss : 3.5985 | Train_Accuracy : 0.2628 | Train Perplexity : 76.4504\n",
            "Valid Loss : 4.2075 | Valid_Accuracy : 0.2089 | Valid Perplexity : 208.1813\n",
            "Valid Loss improved from 4.2087 to 4.2075\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 208.9846 to 208.1813\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [2:26:17<23:46, 203.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 44 / 50\n",
            "Train Loss : 3.5906 | Train_Accuracy : 0.2640 | Train Perplexity : 75.4608\n",
            "Valid Loss : 4.2040 | Valid_Accuracy : 0.2103 | Valid Perplexity : 207.2896\n",
            "Valid Loss improved from 4.2075 to 4.2040\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 208.1813 to 207.2896\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [2:29:41<20:23, 203.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [2:33:04<16:58, 203.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 45 / 50\n",
            "Train Loss : 3.5809 | Train_Accuracy : 0.2653 | Train Perplexity : 74.2253\n",
            "Valid Loss : 4.2051 | Valid_Accuracy : 0.2120 | Valid Perplexity : 207.4454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [2:36:27<13:33, 203.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 46 / 50\n",
            "Train Loss : 3.5761 | Train_Accuracy : 0.2660 | Train Perplexity : 73.6458\n",
            "Valid Loss : 4.2071 | Valid_Accuracy : 0.2069 | Valid Perplexity : 207.8969\n",
            "Epoch : 47 / 50\n",
            "Train Loss : 3.5596 | Train_Accuracy : 0.2682 | Train Perplexity : 71.9413\n",
            "Valid Loss : 4.1930 | Valid_Accuracy : 0.2160 | Valid Perplexity : 204.8032\n",
            "Valid Loss improved from 4.2040 to 4.1930\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 207.2896 to 204.8032\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [2:39:51<10:10, 203.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [2:43:13<06:46, 203.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 48 / 50\n",
            "Train Loss : 3.5613 | Train_Accuracy : 0.2685 | Train Perplexity : 71.8224\n",
            "Valid Loss : 4.1988 | Valid_Accuracy : 0.2115 | Valid Perplexity : 206.6954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [2:46:36<03:23, 203.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 49 / 50\n",
            "Train Loss : 3.5523 | Train_Accuracy : 0.2697 | Train Perplexity : 70.9113\n",
            "Valid Loss : 4.1966 | Valid_Accuracy : 0.2117 | Valid Perplexity : 205.9966\n",
            "Epoch : 50 / 50\n",
            "Train Loss : 3.5452 | Train_Accuracy : 0.2710 | Train Perplexity : 70.0591\n",
            "Valid Loss : 4.1913 | Valid_Accuracy : 0.2140 | Valid Perplexity : 203.9260\n",
            "Valid Loss improved from 4.1930 to 4.1913\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 204.8032 to 203.9260\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [2:50:00<00:00, 204.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_attn_TinyGPT_checkpoint.pth\n",
            "best_loss_epoch : 50\n",
            "best_ppl_epoch : 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss, kd_l, mse_l = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0: # To check the log of MSE Loss and CE Loss & KL-Divergence\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_KD_with_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_ppl_KD_with_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 5\n",
        "\n",
        "MSE - layerwise & JS - logits\n",
        "\n",
        "PPL : 293.6137\n",
        "\n",
        "Best Epoch : 28\n",
        "\n",
        "\"In this code, the weight of JS-Divergence is 0.3 due to supplementary experiment.\""
      ],
      "metadata": {
        "id": "vqpgiWEJw6Ni"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlihgVZD1j9D"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def JS_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  eps=1e-9\n",
        "  student_prob = F.softmax(student_logits / temperature, dim=-1)\n",
        "  teacher_prob = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "  M = 0.5 * (student_prob + teacher_prob)\n",
        "  M_log = torch.log(M + eps)\n",
        "  student_log = torch.log(student_prob + eps)\n",
        "  teacher_log = torch.log(teacher_prob + eps)\n",
        "\n",
        "  D_p = (teacher_prob * (teacher_log - M_log)).sum(dim=-1)\n",
        "  D_q = (student_prob * (student_log - M_log)).sum(dim=-1)\n",
        "\n",
        "  JS = 0.5 * (D_p + D_q)\n",
        "  if mask is not None:\n",
        "    JS = JS * mask\n",
        "    return (JS.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return JS.mean() * (T**2)\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def layerwise_MSE(s_attn, t_attn):\n",
        "  assert len(t_attn) % 2 == 0, 'Len of teacher attention layers must be divisible by 2.'\n",
        "  weighted_loss = 0.0\n",
        "  eps = 1e-9\n",
        "  num_s_layer = len(s_attn)\n",
        "  num_t_layer = len(t_attn)\n",
        "\n",
        "  idx_list = []\n",
        "  t_attn_list = []\n",
        "  if 2 * num_s_layer == num_t_layer:\n",
        "    for i in range(num_s_layer):\n",
        "      t_attn_list.append(t_attn[2*i+1])\n",
        "  elif 2 * num_s_layer > num_t_layer:\n",
        "    for i in range(num_s_layer):\n",
        "      if 2*i + 1 >= num_t_layer:\n",
        "        break\n",
        "      idx_list.append(2*i+1)\n",
        "    while len(idx_list) < num_s_layer:\n",
        "      for i in range(num_t_layer - 2, -1, -2):\n",
        "        if i not in idx_list:\n",
        "          idx_list.append(i)\n",
        "        if len(idx_list) == num_s_layer:\n",
        "          break\n",
        "    idx_list.sort()\n",
        "    for idx in idx_list:\n",
        "      t_attn_list.append(t_attn[idx])\n",
        "  elif 2 * num_s_layer < num_t_layer:\n",
        "    for i in range(num_t_layer-1, -1, -2):\n",
        "      if len(idx_list) == 2 * num_s_layer:\n",
        "        break\n",
        "      idx_list.append(i)\n",
        "    idx_list.sort()\n",
        "    for idx in idx_list:\n",
        "      t_attn_list.append(t_attn[idx])\n",
        "\n",
        "  assert num_s_layer == len(t_attn_list), f'Len of t_attn_list ({len(t_attn_list)}) do no match len of s_attn ({num_s_layer})'\n",
        "\n",
        "  per_layer_mse = []\n",
        "  loss = 0.0\n",
        "  for i in range(num_s_layer):\n",
        "    s_avg = average_head(s_attn[i])\n",
        "    t_avg = average_head(t_attn_list[i]).detach()\n",
        "    diff = s_avg - t_avg\n",
        "    mse = torch.mean(diff ** 2)\n",
        "    loss += mse\n",
        "  loss /= num_s_layer\n",
        "  return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, alpha, beta, gamma, temperature=2.0, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "    self.gamma = gamma\n",
        "    self.temperature = temperature\n",
        "    self.label_smoothing = label_smoothing\n",
        "    self.ignore_index = ignore_index\n",
        "\n",
        "  def forward(self, s_attn, t_attn, s_logits, t_logits, labels):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    with torch.no_grad():\n",
        "      t_attn = [a.detach() for a in t_attn]\n",
        "      t_logits = t_logits.detach()\n",
        "\n",
        "    # 1. Attention Loss\n",
        "    attn_loss = layerwise_MSE(s_attn, t_attn)\n",
        "\n",
        "    # 2. JS Divergence\n",
        "    js_loss = JS_divergence(s_logits, t_logits, self.temperature, mask)\n",
        "\n",
        "    # 3. Cross-Entropy Loss\n",
        "    ce_loss = F.cross_entropy(\n",
        "        s_logits.view(-1, s_logits.size(-1)),\n",
        "        labels.view(-1),\n",
        "        ignore_index=self.ignore_index,\n",
        "        label_smoothing=self.label_smoothing\n",
        "    )\n",
        "\n",
        "    # 4. Final loss\n",
        "    total_loss = (\n",
        "        self.alpha * attn_loss +\n",
        "        self.beta * js_loss +\n",
        "        self.gamma * ce_loss\n",
        "    )\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "66951f11894647aa94256ce1f915212d",
            "ae172e8ff03943a784b8413000efc948",
            "2109b8d1b5db40609566091c2679154a",
            "d56e9a515e124979a7a4b8d47f3e5705",
            "22ed36cba35d470fbd47a91712643e87",
            "97cb3eebc9ec44c4bb390c27811bf389",
            "3e037b4bea1d41fb9e5a09bea5030edb",
            "101b63a878d74cd39a1b15334cacbeb4",
            "68ab5cfc95124ca38bb80ed7ea38607a",
            "20d07a52f13a429c94133db0e607e519",
            "6b8d3e51e06e4a72b074c31e861ea025",
            "5d32aebd0f09450a8ed7e62da74cb459",
            "923e92a9ad564bffa7e7a5c6e4563dc2",
            "6009f8e081854b3e9f3d758aca78677e",
            "07b6683b889d4daeb40ca2366d958981",
            "435f7842b09f4b4fa7e333312be866f0",
            "26225cdd7ea24739ae42befa6043dce0",
            "3c462d39f42446879729fdd45e89b8fe",
            "3e22625b9b064cb6a7ab64936389d3d0",
            "211291232fcf4259b60ddf601d0b65a3",
            "e7b18d765f064f74a15d9d7d1702686c",
            "dbce2fce0d244c1eaae6d5c72f23edf4"
          ]
        },
        "id": "kY_i6hvR1kKl",
        "outputId": "4ef383b6-2706-4bb7-ec3a-0e061a69fbf8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66951f11894647aa94256ce1f915212d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d32aebd0f09450a8ed7e62da74cb459"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Load Model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VboeNzTd1k0k"
      },
      "outputs": [],
      "source": [
        "# Setting loss function, optimizer, and scheduler\n",
        "\n",
        "# alpha : attn loss, beta : JS Divergence, gamma : CE Loss\n",
        "loss_function = TotalLoss(alpha = 0.05, beta = 0.4, gamma = 0.5)\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slboaLFv1kub"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_attn, t_attn, s_outputs.reshape(-1, s_outputs.size(-1)), t_logits.reshape(-1, t_logits.size(-1)), labels.reshape(-1)) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffAdnoT11klK",
        "outputId": "880af99a-c904-499b-f4aa-3ba90d63f8fe"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 4.2692 | Train_Accuracy : 0.0507 | Train Perplexity : 1958.2949\n",
            "Valid Loss : 4.2529 | Valid_Accuracy : 0.0400 | Valid Perplexity : 1877.1775\n",
            "Valid Loss improved from inf to 4.2529\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1877.1775\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [03:09<2:34:48, 189.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 4.1170 | Train_Accuracy : 0.0949 | Train Perplexity : 1410.6046\n",
            "Valid Loss : 4.1184 | Valid_Accuracy : 0.0916 | Valid Perplexity : 1405.7845\n",
            "Valid Loss improved from 4.2529 to 4.1184\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1877.1775 to 1405.7845\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [06:02<2:23:36, 179.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 4.0248 | Train_Accuracy : 0.1080 | Train Perplexity : 1138.0254\n",
            "Valid Loss : 4.0282 | Valid_Accuracy : 0.0995 | Valid Perplexity : 1138.8897\n",
            "Valid Loss improved from 4.1184 to 4.0282\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1405.7845 to 1138.8897\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [08:54<2:18:06, 176.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 3.8774 | Train_Accuracy : 0.1255 | Train Perplexity : 840.3674\n",
            "Valid Loss : 3.9092 | Valid_Accuracy : 0.1199 | Valid Perplexity : 894.2421\n",
            "Valid Loss improved from 4.0282 to 3.9092\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1138.8897 to 894.2421\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [11:46<2:13:58, 174.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 3.7932 | Train_Accuracy : 0.1372 | Train Perplexity : 693.2660\n",
            "Valid Loss : 3.8194 | Valid_Accuracy : 0.1224 | Valid Perplexity : 730.1206\n",
            "Valid Loss improved from 3.9092 to 3.8194\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 894.2421 to 730.1206\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [14:39<2:10:22, 173.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 3.6760 | Train_Accuracy : 0.1464 | Train Perplexity : 538.1517\n",
            "Valid Loss : 3.7194 | Valid_Accuracy : 0.1335 | Valid Perplexity : 590.5568\n",
            "Valid Loss improved from 3.8194 to 3.7194\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 730.1206 to 590.5568\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [17:31<2:07:10, 173.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 3.6107 | Train_Accuracy : 0.1563 | Train Perplexity : 468.5680\n",
            "Valid Loss : 3.6665 | Valid_Accuracy : 0.1431 | Valid Perplexity : 529.0205\n",
            "Valid Loss improved from 3.7194 to 3.6665\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 590.5568 to 529.0205\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [20:24<2:04:06, 173.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 3.5681 | Train_Accuracy : 0.1606 | Train Perplexity : 428.1598\n",
            "Valid Loss : 3.6467 | Valid_Accuracy : 0.1474 | Valid Perplexity : 507.6194\n",
            "Valid Loss improved from 3.6665 to 3.6467\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 529.0205 to 507.6194\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [23:17<2:01:08, 173.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 3.4642 | Train_Accuracy : 0.1711 | Train Perplexity : 341.1014\n",
            "Valid Loss : 3.5623 | Valid_Accuracy : 0.1593 | Valid Perplexity : 422.6720\n",
            "Valid Loss improved from 3.6467 to 3.5623\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 507.6194 to 422.6720\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [26:09<1:58:11, 172.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 3.4146 | Train_Accuracy : 0.1760 | Train Perplexity : 302.5473\n",
            "Valid Loss : 3.5423 | Valid_Accuracy : 0.1661 | Valid Perplexity : 399.3853\n",
            "Valid Loss improved from 3.5623 to 3.5423\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 422.6720 to 399.3853\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [29:02<1:55:13, 172.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 3.3714 | Train_Accuracy : 0.1795 | Train Perplexity : 275.2984\n",
            "Valid Loss : 3.5268 | Valid_Accuracy : 0.1635 | Valid Perplexity : 388.0830\n",
            "Valid Loss improved from 3.5423 to 3.5268\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 399.3853 to 388.0830\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [31:54<1:52:14, 172.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 3.3229 | Train_Accuracy : 0.1867 | Train Perplexity : 248.2857\n",
            "Valid Loss : 3.5004 | Valid_Accuracy : 0.1723 | Valid Perplexity : 365.2112\n",
            "Valid Loss improved from 3.5268 to 3.5004\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 388.0830 to 365.2112\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [34:47<1:49:17, 172.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 3.2764 | Train_Accuracy : 0.1922 | Train Perplexity : 223.2286\n",
            "Valid Loss : 3.4858 | Valid_Accuracy : 0.1817 | Valid Perplexity : 352.4262\n",
            "Valid Loss improved from 3.5004 to 3.4858\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 365.2112 to 352.4262\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [37:39<1:46:22, 172.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 3.2108 | Train_Accuracy : 0.1989 | Train Perplexity : 192.1088\n",
            "Valid Loss : 3.4610 | Valid_Accuracy : 0.1837 | Valid Perplexity : 333.7924\n",
            "Valid Loss improved from 3.4858 to 3.4610\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 352.4262 to 333.7924\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [40:32<1:43:33, 172.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [43:23<1:40:27, 172.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 15 / 50\n",
            "Train Loss : 3.1801 | Train_Accuracy : 0.2018 | Train Perplexity : 180.2641\n",
            "Valid Loss : 3.4700 | Valid_Accuracy : 0.1837 | Valid Perplexity : 340.9475\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 3.1232 | Train_Accuracy : 0.2095 | Train Perplexity : 158.8104\n",
            "Valid Loss : 3.4566 | Valid_Accuracy : 0.1854 | Valid Perplexity : 330.5171\n",
            "Valid Loss improved from 3.4610 to 3.4566\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 333.7924 to 330.5171\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [46:15<1:37:35, 172.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 17 / 50\n",
            "Train Loss : 3.0868 | Train_Accuracy : 0.2154 | Train Perplexity : 144.4273\n",
            "Valid Loss : 3.4516 | Valid_Accuracy : 0.1859 | Valid Perplexity : 323.2377\n",
            "Valid Loss improved from 3.4566 to 3.4516\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 330.5171 to 323.2377\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [49:08<1:34:45, 172.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 3.0345 | Train_Accuracy : 0.2225 | Train Perplexity : 129.3656\n",
            "Valid Loss : 3.4465 | Valid_Accuracy : 0.1842 | Valid Perplexity : 320.2157\n",
            "Valid Loss improved from 3.4516 to 3.4465\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 323.2377 to 320.2157\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [52:00<1:31:53, 172.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 19 / 50\n",
            "Train Loss : 2.9834 | Train_Accuracy : 0.2303 | Train Perplexity : 114.6447\n",
            "Valid Loss : 3.4411 | Valid_Accuracy : 0.1916 | Valid Perplexity : 314.7164\n",
            "Valid Loss improved from 3.4465 to 3.4411\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 320.2157 to 314.7164\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [54:52<1:29:00, 172.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 2.9433 | Train_Accuracy : 0.2388 | Train Perplexity : 104.5048\n",
            "Valid Loss : 3.4408 | Valid_Accuracy : 0.1930 | Valid Perplexity : 313.5439\n",
            "Valid Loss improved from 3.4411 to 3.4408\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 314.7164 to 313.5439\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [57:45<1:26:11, 172.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 2.8813 | Train_Accuracy : 0.2497 | Train Perplexity : 90.5671\n",
            "Valid Loss : 3.4340 | Valid_Accuracy : 0.1956 | Valid Perplexity : 307.1036\n",
            "Valid Loss improved from 3.4408 to 3.4340\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 313.5439 to 307.1036\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:00:37<1:23:18, 172.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 22 / 50\n",
            "Train Loss : 2.8339 | Train_Accuracy : 0.2596 | Train Perplexity : 81.2810\n",
            "Valid Loss : 3.4206 | Valid_Accuracy : 0.1993 | Valid Perplexity : 297.1031\n",
            "Valid Loss improved from 3.4340 to 3.4206\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 307.1036 to 297.1031\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:03:30<1:20:26, 172.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:06:21<1:17:27, 172.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 23 / 50\n",
            "Train Loss : 2.7988 | Train_Accuracy : 0.2665 | Train Perplexity : 74.9366\n",
            "Valid Loss : 3.4321 | Valid_Accuracy : 0.1959 | Valid Perplexity : 304.7244\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:09:13<1:14:31, 171.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 24 / 50\n",
            "Train Loss : 2.7535 | Train_Accuracy : 0.2769 | Train Perplexity : 67.7131\n",
            "Valid Loss : 3.4362 | Valid_Accuracy : 0.2012 | Valid Perplexity : 306.3716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:12:04<1:11:33, 171.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 25 / 50\n",
            "Train Loss : 2.7161 | Train_Accuracy : 0.2848 | Train Perplexity : 61.5377\n",
            "Valid Loss : 3.4330 | Valid_Accuracy : 0.2015 | Valid Perplexity : 301.0472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:14:55<1:08:38, 171.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 26 / 50\n",
            "Train Loss : 2.6807 | Train_Accuracy : 0.2935 | Train Perplexity : 56.9698\n",
            "Valid Loss : 3.4541 | Valid_Accuracy : 0.1956 | Valid Perplexity : 316.2877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:17:47<1:05:43, 171.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 2.6358 | Train_Accuracy : 0.3046 | Train Perplexity : 51.1676\n",
            "Valid Loss : 3.4463 | Valid_Accuracy : 0.1961 | Valid Perplexity : 308.7213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:20:38<1:08:41, 179.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 28 / 50\n",
            "Train Loss : 2.5950 | Train_Accuracy : 0.3163 | Train Perplexity : 46.4881\n",
            "Valid Loss : 3.4556 | Valid_Accuracy : 0.1927 | Valid Perplexity : 313.8461\n",
            "best_loss_epoch : 22\n",
            "best_ppl_epoch : 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    with torch.no_grad():\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_attn, t_attn, s_outputs.reshape(-1, s_outputs.size(-1)), t_logits.reshape(-1, t_logits.size(-1)), labels.reshape(-1))\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_my_loss_function_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_my_loss_function_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 6\n",
        "\n",
        "MSE - last layer & KL - logits\n",
        "\n",
        "PPL : 201.0778\n",
        "\n",
        "Best Epoch : 47"
      ],
      "metadata": {
        "id": "NJP4A3mcyaJ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "324fPpmdL4lY"
      },
      "outputs": [],
      "source": [
        "# Loss Function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def KL_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  student_log_probs = F.log_softmax(student_logits / T, dim=-1)\n",
        "  teacher_probs = F.softmax(teacher_logits / T, dim=-1)\n",
        "  eps = 1e-8\n",
        "  KL = (teacher_probs * (torch.log(teacher_probs + eps) - student_log_probs)).sum(dim=-1)\n",
        "\n",
        "  if mask is not None:\n",
        "    KL = KL * mask\n",
        "    return (KL.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return KL.mean() * (T**2)\n",
        "\n",
        "class KD_Loss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.A = alpha\n",
        "    self.ignore_index = ignore_index\n",
        "    self.label_smoothing = label_smoothing\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    KL_Loss = KL_divergence(student_logits, teacher_logits, self.T, mask)\n",
        "    CE_Loss = F.cross_entropy(student_logits, labels, ignore_index=self.ignore_index, label_smoothing=self.label_smoothing)\n",
        "    total_Loss = self.A * KL_Loss + (1 - self.A) * CE_Loss\n",
        "    return total_Loss\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def MSE(s_attn, t_attn):\n",
        "  '''\n",
        "  s_attn: list of student attention tensors (shape: [batch, heads, seq_len, seq_len])\n",
        "  t_attn: list of teacher attention tensors (same shape)\n",
        "  Returns:\n",
        "    MSE Loss from the last layers\n",
        "  '''\n",
        "  last_t_attn = t_attn[-1]\n",
        "  last_s_attn = s_attn[-1]\n",
        "  loss = ((average_head(last_s_attn) - average_head(last_t_attn)) ** 2).mean()\n",
        "  return loss\n",
        "\n",
        "class MSE_Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, s_attn, t_attn):\n",
        "    loss = MSE(s_attn, t_attn)\n",
        "    return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, beta, label_smoothing=0.1 ,ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.B = beta\n",
        "    self.ignore_index = ignore_index\n",
        "    self.kd_loss = KD_Loss(temperature, alpha, label_smoothing, ignore_index=ignore_index)\n",
        "    self.mse = MSE_Loss()\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits, s_attn, t_attn):\n",
        "    kd_l = self.kd_loss(student_logits, labels, teacher_logits)\n",
        "    mse_l = self.mse(s_attn, t_attn)\n",
        "    total_loss = kd_l + self.B * mse_l\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oRx2Y6BL4i3",
        "outputId": "8a07a54d-8484-4320-9364-918ff8917213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Load Model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCIeaIc6L4go"
      },
      "outputs": [],
      "source": [
        "# Setting loss function, optimizer, and scheduler\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# alpha : KL & CE(1-alpha), beta : MSE\n",
        "loss_function = TotalLoss(temperature=2.0, alpha=0.5, beta=0.05)\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbqMnmLfL4ee"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr6z8SVCL4cP",
        "outputId": "f7cad3b2-b0a7-4316-bcad-135364a77282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 6.2443 | Train_Accuracy : 0.0501 | Train Perplexity : 2063.3422\n",
            "Valid Loss : 6.2478 | Valid_Accuracy : 0.0428 | Valid Perplexity : 1926.4025\n",
            "Valid Loss improved from inf to 6.2478\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1926.4025\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [03:50<3:08:18, 230.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 6.2377 | Train_Accuracy : 0.0592 | Train Perplexity : 2031.0795\n",
            "Valid Loss : 6.2472 | Valid_Accuracy : 0.0476 | Valid Perplexity : 1909.6343\n",
            "Valid Loss improved from 6.2478 to 6.2472\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1926.4025 to 1909.6343\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [07:13<2:51:31, 214.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 5.8112 | Train_Accuracy : 0.0955 | Train Perplexity : 1276.3986\n",
            "Valid Loss : 5.8341 | Valid_Accuracy : 0.0884 | Valid Perplexity : 1237.7357\n",
            "Valid Loss improved from 6.2472 to 5.8341\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1909.6343 to 1237.7357\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [10:36<2:43:56, 209.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 5.5885 | Train_Accuracy : 0.0986 | Train Perplexity : 1080.4435\n",
            "Valid Loss : 5.6293 | Valid_Accuracy : 0.0870 | Valid Perplexity : 1068.6466\n",
            "Valid Loss improved from 5.8341 to 5.6293\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1237.7357 to 1068.6466\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [13:59<2:38:32, 206.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 5.5118 | Train_Accuracy : 0.1120 | Train Perplexity : 957.5590\n",
            "Valid Loss : 5.5488 | Valid_Accuracy : 0.1046 | Valid Perplexity : 950.2782\n",
            "Valid Loss improved from 5.6293 to 5.5488\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1068.6466 to 950.2782\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [17:22<2:34:04, 205.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 5.4080 | Train_Accuracy : 0.1225 | Train Perplexity : 829.8945\n",
            "Valid Loss : 5.4441 | Valid_Accuracy : 0.1128 | Valid Perplexity : 828.3974\n",
            "Valid Loss improved from 5.5488 to 5.4441\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 950.2782 to 828.3974\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [20:45<2:30:00, 204.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 5.2288 | Train_Accuracy : 0.1287 | Train Perplexity : 689.4290\n",
            "Valid Loss : 5.2621 | Valid_Accuracy : 0.1182 | Valid Perplexity : 693.6890\n",
            "Valid Loss improved from 5.4441 to 5.2621\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 828.3974 to 693.6890\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [24:08<2:26:09, 203.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 5.0931 | Train_Accuracy : 0.1372 | Train Perplexity : 587.4027\n",
            "Valid Loss : 5.1361 | Valid_Accuracy : 0.1227 | Valid Perplexity : 601.9332\n",
            "Valid Loss improved from 5.2621 to 5.1361\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 693.6890 to 601.9332\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [27:31<2:22:29, 203.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 4.9467 | Train_Accuracy : 0.1431 | Train Perplexity : 505.7544\n",
            "Valid Loss : 4.9845 | Valid_Accuracy : 0.1293 | Valid Perplexity : 524.1274\n",
            "Valid Loss improved from 5.1361 to 4.9845\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 601.9332 to 524.1274\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [30:53<2:18:56, 203.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 4.8928 | Train_Accuracy : 0.1456 | Train Perplexity : 470.3240\n",
            "Valid Loss : 4.9845 | Valid_Accuracy : 0.1284 | Valid Perplexity : 522.9229\n",
            "Valid Loss improved from 4.9845 to 4.9845\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 524.1274 to 522.9229\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [34:17<2:15:33, 203.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 4.8988 | Train_Accuracy : 0.1503 | Train Perplexity : 460.6435\n",
            "Valid Loss : 4.9001 | Valid_Accuracy : 0.1395 | Valid Perplexity : 464.0212\n",
            "Valid Loss improved from 4.9845 to 4.9001\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 522.9229 to 464.0212\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [37:40<2:12:06, 203.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 4.7134 | Train_Accuracy : 0.1549 | Train Perplexity : 375.2152\n",
            "Valid Loss : 4.8176 | Valid_Accuracy : 0.1471 | Valid Perplexity : 430.0720\n",
            "Valid Loss improved from 4.9001 to 4.8176\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 464.0212 to 430.0720\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [41:03<2:08:40, 203.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 4.6268 | Train_Accuracy : 0.1613 | Train Perplexity : 336.7871\n",
            "Valid Loss : 4.7690 | Valid_Accuracy : 0.1525 | Valid Perplexity : 405.5191\n",
            "Valid Loss improved from 4.8176 to 4.7690\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 430.0720 to 405.5191\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [44:27<2:05:24, 203.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 4.5932 | Train_Accuracy : 0.1621 | Train Perplexity : 324.9505\n",
            "Valid Loss : 4.7418 | Valid_Accuracy : 0.1531 | Valid Perplexity : 398.6100\n",
            "Valid Loss improved from 4.7690 to 4.7418\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 405.5191 to 398.6100\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [47:50<2:01:58, 203.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 15 / 50\n",
            "Train Loss : 4.5564 | Train_Accuracy : 0.1678 | Train Perplexity : 301.1095\n",
            "Valid Loss : 4.7277 | Valid_Accuracy : 0.1601 | Valid Perplexity : 382.0399\n",
            "Valid Loss improved from 4.7418 to 4.7277\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 398.6100 to 382.0399\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [51:13<1:58:32, 203.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 4.4214 | Train_Accuracy : 0.1788 | Train Perplexity : 257.5531\n",
            "Valid Loss : 4.6045 | Valid_Accuracy : 0.1667 | Valid Perplexity : 335.0932\n",
            "Valid Loss improved from 4.7277 to 4.6045\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 382.0399 to 335.0932\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [54:36<1:55:09, 203.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 17 / 50\n",
            "Train Loss : 4.3644 | Train_Accuracy : 0.1814 | Train Perplexity : 237.1361\n",
            "Valid Loss : 4.5861 | Valid_Accuracy : 0.1698 | Valid Perplexity : 325.2384\n",
            "Valid Loss improved from 4.6045 to 4.5861\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 335.0932 to 325.2384\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [57:59<1:51:42, 203.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 4.3238 | Train_Accuracy : 0.1843 | Train Perplexity : 224.1920\n",
            "Valid Loss : 4.5458 | Valid_Accuracy : 0.1678 | Valid Perplexity : 311.2183\n",
            "Valid Loss improved from 4.5861 to 4.5458\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 325.2384 to 311.2183\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [1:01:22<1:48:17, 203.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 19 / 50\n",
            "Train Loss : 4.2675 | Train_Accuracy : 0.1891 | Train Perplexity : 207.5269\n",
            "Valid Loss : 4.5388 | Valid_Accuracy : 0.1811 | Valid Perplexity : 308.5512\n",
            "Valid Loss improved from 4.5458 to 4.5388\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 311.2183 to 308.5512\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [1:04:45<1:44:55, 203.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 4.2031 | Train_Accuracy : 0.1945 | Train Perplexity : 190.2152\n",
            "Valid Loss : 4.4979 | Valid_Accuracy : 0.1820 | Valid Perplexity : 294.0489\n",
            "Valid Loss improved from 4.5388 to 4.4979\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 308.5512 to 294.0489\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:08:08<1:41:32, 203.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:11:30<1:38:00, 202.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 21 / 50\n",
            "Train Loss : 4.1934 | Train_Accuracy : 0.1948 | Train Perplexity : 185.3204\n",
            "Valid Loss : 4.5096 | Valid_Accuracy : 0.1789 | Valid Perplexity : 295.5911\n",
            "Epoch : 22 / 50\n",
            "Train Loss : 4.1418 | Train_Accuracy : 0.1988 | Train Perplexity : 173.0539\n",
            "Valid Loss : 4.4804 | Valid_Accuracy : 0.1800 | Valid Perplexity : 288.0384\n",
            "Valid Loss improved from 4.4979 to 4.4804\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 294.0489 to 288.0384\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:14:53<1:34:36, 202.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 23 / 50\n",
            "Train Loss : 4.1064 | Train_Accuracy : 0.2020 | Train Perplexity : 164.1134\n",
            "Valid Loss : 4.4468 | Valid_Accuracy : 0.1859 | Valid Perplexity : 276.2717\n",
            "Valid Loss improved from 4.4804 to 4.4468\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 288.0384 to 276.2717\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:18:15<1:31:11, 202.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 24 / 50\n",
            "Train Loss : 4.0214 | Train_Accuracy : 0.2102 | Train Perplexity : 146.1073\n",
            "Valid Loss : 4.3906 | Valid_Accuracy : 0.1851 | Valid Perplexity : 258.3030\n",
            "Valid Loss improved from 4.4468 to 4.3906\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 276.2717 to 258.3030\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:21:38<1:27:47, 202.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 25 / 50\n",
            "Train Loss : 3.9937 | Train_Accuracy : 0.2119 | Train Perplexity : 140.1120\n",
            "Valid Loss : 4.3902 | Valid_Accuracy : 0.1885 | Valid Perplexity : 258.7487\n",
            "Valid Loss improved from 4.3906 to 4.3902\n",
            "Save the loss Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:25:00<1:24:20, 202.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 26 / 50\n",
            "Train Loss : 3.9381 | Train_Accuracy : 0.2185 | Train Perplexity : 129.3674\n",
            "Valid Loss : 4.3481 | Valid_Accuracy : 0.1959 | Valid Perplexity : 246.3162\n",
            "Valid Loss improved from 4.3902 to 4.3481\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 258.3030 to 246.3162\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:28:22<1:20:57, 202.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:31:43<1:17:27, 202.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 3.9333 | Train_Accuracy : 0.2196 | Train Perplexity : 127.1761\n",
            "Valid Loss : 4.3601 | Valid_Accuracy : 0.1922 | Valid Perplexity : 249.5611\n",
            "Epoch : 28 / 50\n",
            "Train Loss : 3.8667 | Train_Accuracy : 0.2267 | Train Perplexity : 116.4130\n",
            "Valid Loss : 4.3127 | Valid_Accuracy : 0.1930 | Valid Perplexity : 236.7571\n",
            "Valid Loss improved from 4.3481 to 4.3127\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 246.3162 to 236.7571\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:35:06<1:14:07, 202.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:38:27<1:10:40, 201.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 29 / 50\n",
            "Train Loss : 3.8793 | Train_Accuracy : 0.2256 | Train Perplexity : 116.7499\n",
            "Valid Loss : 4.3447 | Valid_Accuracy : 0.1919 | Valid Perplexity : 244.8268\n",
            "Epoch : 30 / 50\n",
            "Train Loss : 3.8027 | Train_Accuracy : 0.2349 | Train Perplexity : 105.2551\n",
            "Valid Loss : 4.2959 | Valid_Accuracy : 0.1953 | Valid Perplexity : 232.0500\n",
            "Valid Loss improved from 4.3127 to 4.2959\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 236.7571 to 232.0500\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:41:50<1:07:23, 202.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 31 / 50\n",
            "Train Loss : 3.7877 | Train_Accuracy : 0.2365 | Train Perplexity : 102.4205\n",
            "Valid Loss : 4.2799 | Valid_Accuracy : 0.1973 | Valid Perplexity : 226.5675\n",
            "Valid Loss improved from 4.2959 to 4.2799\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 232.0500 to 226.5675\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:45:12<1:04:03, 202.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:48:34<1:00:36, 202.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 32 / 50\n",
            "Train Loss : 3.7816 | Train_Accuracy : 0.2380 | Train Perplexity : 100.8776\n",
            "Valid Loss : 4.2907 | Valid_Accuracy : 0.1984 | Valid Perplexity : 228.7008\n",
            "Epoch : 33 / 50\n",
            "Train Loss : 3.7383 | Train_Accuracy : 0.2425 | Train Perplexity : 94.8204\n",
            "Valid Loss : 4.2651 | Valid_Accuracy : 0.1976 | Valid Perplexity : 222.8709\n",
            "Valid Loss improved from 4.2799 to 4.2651\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 226.5675 to 222.8709\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:51:56<57:16, 202.17s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 34 / 50\n",
            "Train Loss : 3.7138 | Train_Accuracy : 0.2466 | Train Perplexity : 91.0937\n",
            "Valid Loss : 4.2446 | Valid_Accuracy : 0.2018 | Valid Perplexity : 216.8825\n",
            "Valid Loss improved from 4.2651 to 4.2446\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 222.8709 to 216.8825\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [1:55:19<53:57, 202.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 35 / 50\n",
            "Train Loss : 3.6892 | Train_Accuracy : 0.2495 | Train Perplexity : 87.9573\n",
            "Valid Loss : 4.2416 | Valid_Accuracy : 0.1993 | Valid Perplexity : 216.6973\n",
            "Valid Loss improved from 4.2446 to 4.2416\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 216.8825 to 216.6973\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [1:58:41<50:35, 202.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 36 / 50\n",
            "Train Loss : 3.6732 | Train_Accuracy : 0.2524 | Train Perplexity : 85.6014\n",
            "Valid Loss : 4.2375 | Valid_Accuracy : 0.1970 | Valid Perplexity : 215.5134\n",
            "Valid Loss improved from 4.2416 to 4.2375\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 216.6973 to 215.5134\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [2:02:04<47:14, 202.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 37 / 50\n",
            "Train Loss : 3.6481 | Train_Accuracy : 0.2552 | Train Perplexity : 82.5269\n",
            "Valid Loss : 4.2253 | Valid_Accuracy : 0.2055 | Valid Perplexity : 212.7557\n",
            "Valid Loss improved from 4.2375 to 4.2253\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 215.5134 to 212.7557\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [2:05:27<43:52, 202.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 38 / 50\n",
            "Train Loss : 3.6296 | Train_Accuracy : 0.2577 | Train Perplexity : 80.3491\n",
            "Valid Loss : 4.2104 | Valid_Accuracy : 0.2024 | Valid Perplexity : 209.1679\n",
            "Valid Loss improved from 4.2253 to 4.2104\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 212.7557 to 209.1679\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [2:08:50<40:32, 202.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 39 / 50\n",
            "Train Loss : 3.6136 | Train_Accuracy : 0.2600 | Train Perplexity : 78.4043\n",
            "Valid Loss : 4.2052 | Valid_Accuracy : 0.2044 | Valid Perplexity : 208.2021\n",
            "Valid Loss improved from 4.2104 to 4.2052\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 209.1679 to 208.2021\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [2:12:12<37:09, 202.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 40 / 50\n",
            "Train Loss : 3.6039 | Train_Accuracy : 0.2618 | Train Perplexity : 77.1135\n",
            "Valid Loss : 4.2003 | Valid_Accuracy : 0.2066 | Valid Perplexity : 206.5980\n",
            "Valid Loss improved from 4.2052 to 4.2003\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 208.2021 to 206.5980\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [2:15:35<33:46, 202.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 41 / 50\n",
            "Train Loss : 3.5854 | Train_Accuracy : 0.2640 | Train Perplexity : 75.1367\n",
            "Valid Loss : 4.1864 | Valid_Accuracy : 0.2029 | Valid Perplexity : 203.6278\n",
            "Valid Loss improved from 4.2003 to 4.1864\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 206.5980 to 203.6278\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [2:18:57<30:22, 202.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [2:22:19<26:57, 202.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 42 / 50\n",
            "Train Loss : 3.5831 | Train_Accuracy : 0.2648 | Train Perplexity : 74.5247\n",
            "Valid Loss : 4.1895 | Valid_Accuracy : 0.2061 | Valid Perplexity : 203.9338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [2:25:40<23:33, 201.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 43 / 50\n",
            "Train Loss : 3.5830 | Train_Accuracy : 0.2649 | Train Perplexity : 74.4557\n",
            "Valid Loss : 4.1934 | Valid_Accuracy : 0.2038 | Valid Perplexity : 205.0751\n",
            "Epoch : 44 / 50\n",
            "Train Loss : 3.5618 | Train_Accuracy : 0.2678 | Train Perplexity : 72.2518\n",
            "Valid Loss : 4.1782 | Valid_Accuracy : 0.2027 | Valid Perplexity : 201.4424\n",
            "Valid Loss improved from 4.1864 to 4.1782\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 203.6278 to 201.4424\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [2:29:02<20:12, 202.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [2:32:24<16:49, 201.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 45 / 50\n",
            "Train Loss : 3.5632 | Train_Accuracy : 0.2678 | Train Perplexity : 72.1304\n",
            "Valid Loss : 4.1850 | Valid_Accuracy : 0.2015 | Valid Perplexity : 203.1642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [2:35:45<13:26, 201.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 46 / 50\n",
            "Train Loss : 3.5551 | Train_Accuracy : 0.2688 | Train Perplexity : 71.2488\n",
            "Valid Loss : 4.1808 | Valid_Accuracy : 0.2049 | Valid Perplexity : 202.5138\n",
            "Epoch : 47 / 50\n",
            "Train Loss : 3.5428 | Train_Accuracy : 0.2706 | Train Perplexity : 69.9179\n",
            "Valid Loss : 4.1758 | Valid_Accuracy : 0.2041 | Valid Perplexity : 201.0778\n",
            "Valid Loss improved from 4.1782 to 4.1758\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 201.4424 to 201.0778\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [2:39:07<10:05, 201.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [2:42:29<06:43, 201.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 48 / 50\n",
            "Train Loss : 3.5412 | Train_Accuracy : 0.2710 | Train Perplexity : 69.6065\n",
            "Valid Loss : 4.1791 | Valid_Accuracy : 0.2029 | Valid Perplexity : 202.4422\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [2:45:50<03:21, 201.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 49 / 50\n",
            "Train Loss : 3.5408 | Train_Accuracy : 0.2714 | Train Perplexity : 69.3381\n",
            "Valid Loss : 4.1836 | Valid_Accuracy : 0.2072 | Valid Perplexity : 203.0005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [2:49:11<00:00, 203.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 50 / 50\n",
            "Train Loss : 3.5297 | Train_Accuracy : 0.2732 | Train Perplexity : 68.1762\n",
            "Valid Loss : 4.1759 | Valid_Accuracy : 0.2049 | Valid Perplexity : 201.1704\n",
            "best_loss_epoch : 47\n",
            "best_ppl_epoch : 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 7\n",
        "\n",
        "MSE - last layer & JS - logits\n",
        "\n",
        "PPL : 291.6763\n",
        "\n",
        "Best Epoch : 29"
      ],
      "metadata": {
        "id": "MaswKG2vzhf5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PP_VO1zT4VnC"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def JS_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  eps=1e-9\n",
        "  student_prob = F.softmax(student_logits / temperature, dim=-1)\n",
        "  teacher_prob = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "  M = 0.5 * (student_prob + teacher_prob)\n",
        "  M_log = torch.log(M + eps)\n",
        "  student_log = torch.log(student_prob + eps)\n",
        "  teacher_log = torch.log(teacher_prob + eps)\n",
        "\n",
        "  D_p = (teacher_prob * (teacher_log - M_log)).sum(dim=-1)\n",
        "  D_q = (student_prob * (student_log - M_log)).sum(dim=-1)\n",
        "\n",
        "  JS = 0.5 * (D_p + D_q)\n",
        "  if mask is not None:\n",
        "    JS = JS * mask\n",
        "    return (JS.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return JS.mean() * (T**2)\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def MSE(s_attn, t_attn):\n",
        "  '''\n",
        "  s_attn: list of student attention tensors (shape: [batch, heads, seq_len, seq_len])\n",
        "  t_attn: list of teacher attention tensors (same shape)\n",
        "\n",
        "  Returns:\n",
        "    MSE Loss from the last layers\n",
        "  '''\n",
        "  last_t_attn = t_attn[-1]\n",
        "  last_s_attn = s_attn[-1]\n",
        "  loss = ((average_head(last_s_attn) - average_head(last_t_attn)) ** 2).mean()\n",
        "  return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, alpha, beta, gamma, temperature=2.0, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "    self.gamma = gamma\n",
        "    self.temperature = temperature\n",
        "    self.label_smoothing = label_smoothing\n",
        "    self.ignore_index = ignore_index\n",
        "\n",
        "  def forward(self, s_attn, t_attn, s_logits, t_logits, labels):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    with torch.no_grad():\n",
        "      t_attn = [a.detach() for a in t_attn]\n",
        "      t_logits = t_logits.detach()\n",
        "\n",
        "    # 1. Attention Loss\n",
        "    attn_loss = MSE(s_attn, t_attn)\n",
        "\n",
        "    # 2. JS Divergence\n",
        "    js_loss = JS_divergence(s_logits, t_logits, self.temperature, mask)\n",
        "\n",
        "    # 3. Cross-Entropy Loss\n",
        "    ce_loss = F.cross_entropy(\n",
        "        s_logits.view(-1, s_logits.size(-1)),\n",
        "        labels.view(-1),\n",
        "        ignore_index=self.ignore_index,\n",
        "        label_smoothing=self.label_smoothing\n",
        "    )\n",
        "\n",
        "    # 4. Final loss\n",
        "    total_loss = (\n",
        "        self.alpha * attn_loss +\n",
        "        self.beta * js_loss +\n",
        "        self.gamma * ce_loss\n",
        "    )\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ca9a8f8ce45c43958d80a1ca15e34d6c",
            "6713490c7c3c40aaa4d3975c10b1cca0",
            "482955b579884612bbf64cbf67fc3386",
            "1b2106a686684cc6967765e00b12aae8",
            "801fd596156d4a91abadfeb26439da74",
            "a628e0845db44a399ed6f595e3cac811",
            "48c142eb2e13433cb4969acd121e0134",
            "46eeed4fa0df411585c581833b698f1f",
            "359ad93a19bc4a48976df985c1b08dd2",
            "60f822c509794bc7bd94b14ffa86bf34",
            "f537be2d24fe49d5b30eea79b4103df4",
            "86bf993d26e94055ad78a1e6b25b1896",
            "586b7c2e22e24b868b4f744c23786f58",
            "3d768cd72a4c4ef382e128ed931ac74e",
            "f0c85a739f484e22b9dc80c8d39689e4",
            "c48b09dc4ab84ca1ab0c9f9873d6bc14",
            "23a8e5ce72c647e6a07b7e1bc7447aab",
            "1094d856dec448c49da48ad4c476ba9e",
            "7c46aa8101b54c2182be133f585c5617",
            "5d7bac48aef644eebfb34b4c959ea21f",
            "e2e28523c451459a8646a5e310ba8a48",
            "87114bf61df642fea7f8b88758b7ec93"
          ]
        },
        "id": "3rpVL3gs4VkS",
        "outputId": "aeb34455-420c-4447-d56c-ac6d4e091e49"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca9a8f8ce45c43958d80a1ca15e34d6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86bf993d26e94055ad78a1e6b25b1896"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Load Model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyZp4YHX4ViH"
      },
      "outputs": [],
      "source": [
        "# Setting loss function, optimizer, and scheduler\n",
        "\n",
        "# alpha : attn loss, beta : JS Divergence, gamma : CE Loss\n",
        "loss_function = TotalLoss(alpha = 0.05, beta = 0.5, gamma = 0.5)\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7O_VHHD4VgQ"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_attn, t_attn, s_outputs.reshape(-1, s_outputs.size(-1)), t_logits.reshape(-1, t_logits.size(-1)), labels.reshape(-1)) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VW88RMnl4VdI",
        "outputId": "fca65817-3d5c-4eae-ec58-6b6991fc5249"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 4.4226 | Train_Accuracy : 0.0507 | Train Perplexity : 1957.2861\n",
            "Valid Loss : 4.4042 | Valid_Accuracy : 0.0400 | Valid Perplexity : 1860.7985\n",
            "Valid Loss improved from inf to 4.4042\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1860.7985\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [02:44<2:14:02, 164.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 4.4095 | Train_Accuracy : 0.0683 | Train Perplexity : 1893.2095\n",
            "Valid Loss : 4.3954 | Valid_Accuracy : 0.0646 | Valid Perplexity : 1816.6137\n",
            "Valid Loss improved from 4.4042 to 4.3954\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1860.7985 to 1816.6137\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [05:16<2:05:54, 157.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 4.2353 | Train_Accuracy : 0.0972 | Train Perplexity : 1317.3702\n",
            "Valid Loss : 4.2386 | Valid_Accuracy : 0.0882 | Valid Perplexity : 1312.2568\n",
            "Valid Loss improved from 4.3954 to 4.2386\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1816.6137 to 1312.2568\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [07:49<2:01:35, 155.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 4.0866 | Train_Accuracy : 0.1162 | Train Perplexity : 972.2279\n",
            "Valid Loss : 4.1009 | Valid_Accuracy : 0.1091 | Valid Perplexity : 991.3378\n",
            "Valid Loss improved from 4.2386 to 4.1009\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1312.2568 to 991.3378\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [10:22<1:58:12, 154.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 4.0396 | Train_Accuracy : 0.1199 | Train Perplexity : 882.0022\n",
            "Valid Loss : 4.0609 | Valid_Accuracy : 0.1122 | Valid Perplexity : 914.6034\n",
            "Valid Loss improved from 4.1009 to 4.0609\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 991.3378 to 914.6034\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [12:54<1:55:11, 153.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 4.0216 | Train_Accuracy : 0.1224 | Train Perplexity : 841.8579\n",
            "Valid Loss : 4.0526 | Valid_Accuracy : 0.1162 | Valid Perplexity : 890.8628\n",
            "Valid Loss improved from 4.0609 to 4.0526\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 914.6034 to 890.8628\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [15:27<1:52:22, 153.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 3.9025 | Train_Accuracy : 0.1359 | Train Perplexity : 662.1750\n",
            "Valid Loss : 3.9562 | Valid_Accuracy : 0.1241 | Valid Perplexity : 738.2634\n",
            "Valid Loss improved from 4.0526 to 3.9562\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 890.8628 to 738.2634\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [17:59<1:49:39, 153.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 3.7990 | Train_Accuracy : 0.1462 | Train Perplexity : 536.7450\n",
            "Valid Loss : 3.8460 | Valid_Accuracy : 0.1341 | Valid Perplexity : 590.4467\n",
            "Valid Loss improved from 3.9562 to 3.8460\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 738.2634 to 590.4467\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [20:32<1:46:59, 152.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 3.7422 | Train_Accuracy : 0.1503 | Train Perplexity : 475.6207\n",
            "Valid Loss : 3.8120 | Valid_Accuracy : 0.1349 | Valid Perplexity : 549.2635\n",
            "Valid Loss improved from 3.8460 to 3.8120\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 590.4467 to 549.2635\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [23:04<1:44:23, 152.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 3.6804 | Train_Accuracy : 0.1558 | Train Perplexity : 416.2592\n",
            "Valid Loss : 3.7632 | Valid_Accuracy : 0.1414 | Valid Perplexity : 496.4534\n",
            "Valid Loss improved from 3.8120 to 3.7632\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 549.2635 to 496.4534\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [25:37<1:41:48, 152.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 3.6401 | Train_Accuracy : 0.1624 | Train Perplexity : 378.0515\n",
            "Valid Loss : 3.7349 | Valid_Accuracy : 0.1477 | Valid Perplexity : 462.4102\n",
            "Valid Loss improved from 3.7632 to 3.7349\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 496.4534 to 462.4102\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [28:09<1:39:14, 152.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 3.5978 | Train_Accuracy : 0.1636 | Train Perplexity : 348.9409\n",
            "Valid Loss : 3.7209 | Valid_Accuracy : 0.1477 | Valid Perplexity : 454.9900\n",
            "Valid Loss improved from 3.7349 to 3.7209\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 462.4102 to 454.9900\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [30:42<1:36:39, 152.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 3.5619 | Train_Accuracy : 0.1693 | Train Perplexity : 321.5581\n",
            "Valid Loss : 3.7036 | Valid_Accuracy : 0.1590 | Valid Perplexity : 435.8627\n",
            "Valid Loss improved from 3.7209 to 3.7036\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 454.9900 to 435.8627\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [33:14<1:34:04, 152.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 3.4790 | Train_Accuracy : 0.1747 | Train Perplexity : 270.9447\n",
            "Valid Loss : 3.6534 | Valid_Accuracy : 0.1618 | Valid Perplexity : 396.2553\n",
            "Valid Loss improved from 3.7036 to 3.6534\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 435.8627 to 396.2553\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [35:47<1:31:31, 152.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 15 / 50\n",
            "Train Loss : 3.4580 | Train_Accuracy : 0.1783 | Train Perplexity : 256.5584\n",
            "Valid Loss : 3.6551 | Valid_Accuracy : 0.1647 | Valid Perplexity : 392.5474\n",
            "Valid Perplexity improved from 396.2553 to 392.5474\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [38:19<1:28:53, 152.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 3.3788 | Train_Accuracy : 0.1878 | Train Perplexity : 216.0372\n",
            "Valid Loss : 3.6066 | Valid_Accuracy : 0.1780 | Valid Perplexity : 353.8389\n",
            "Valid Loss improved from 3.6534 to 3.6066\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 392.5474 to 353.8389\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [40:51<1:26:21, 152.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [43:23<1:23:39, 152.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 17 / 50\n",
            "Train Loss : 3.3795 | Train_Accuracy : 0.1872 | Train Perplexity : 214.9726\n",
            "Valid Loss : 3.6340 | Valid_Accuracy : 0.1766 | Valid Perplexity : 373.1600\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 3.3054 | Train_Accuracy : 0.1955 | Train Perplexity : 182.5428\n",
            "Valid Loss : 3.5886 | Valid_Accuracy : 0.1786 | Valid Perplexity : 337.8325\n",
            "Valid Loss improved from 3.6066 to 3.5886\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 353.8389 to 337.8325\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [45:55<1:21:11, 152.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [48:27<1:18:31, 151.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 19 / 50\n",
            "Train Loss : 3.2830 | Train_Accuracy : 0.1985 | Train Perplexity : 173.0553\n",
            "Valid Loss : 3.5985 | Valid_Accuracy : 0.1814 | Valid Perplexity : 343.5947\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 3.2229 | Train_Accuracy : 0.2056 | Train Perplexity : 152.1954\n",
            "Valid Loss : 3.5716 | Valid_Accuracy : 0.1876 | Valid Perplexity : 326.3017\n",
            "Valid Loss improved from 3.5886 to 3.5716\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 337.8325 to 326.3017\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [50:59<1:16:02, 152.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 3.1665 | Train_Accuracy : 0.2141 | Train Perplexity : 134.2078\n",
            "Valid Loss : 3.5495 | Valid_Accuracy : 0.1876 | Valid Perplexity : 309.6472\n",
            "Valid Loss improved from 3.5716 to 3.5495\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 326.3017 to 309.6472\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [53:31<1:13:34, 152.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [56:03<1:10:55, 151.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 22 / 50\n",
            "Train Loss : 3.1428 | Train_Accuracy : 0.2169 | Train Perplexity : 127.3427\n",
            "Valid Loss : 3.5600 | Valid_Accuracy : 0.1848 | Valid Perplexity : 316.2348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [58:34<1:08:18, 151.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 23 / 50\n",
            "Train Loss : 3.0951 | Train_Accuracy : 0.2237 | Train Perplexity : 114.5012\n",
            "Valid Loss : 3.5518 | Valid_Accuracy : 0.1845 | Valid Perplexity : 310.5438\n",
            "Epoch : 24 / 50\n",
            "Train Loss : 3.0785 | Train_Accuracy : 0.2260 | Train Perplexity : 109.4088\n",
            "Valid Loss : 3.5537 | Valid_Accuracy : 0.1913 | Valid Perplexity : 309.5366\n",
            "Valid Perplexity improved from 309.6472 to 309.5366\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:01:06<1:05:46, 151.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 25 / 50\n",
            "Train Loss : 3.0333 | Train_Accuracy : 0.2333 | Train Perplexity : 99.1657\n",
            "Valid Loss : 3.5437 | Valid_Accuracy : 0.1868 | Valid Perplexity : 303.5959\n",
            "Valid Loss improved from 3.5495 to 3.5437\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 309.5366 to 303.5959\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:03:39<1:03:21, 152.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 26 / 50\n",
            "Train Loss : 2.9979 | Train_Accuracy : 0.2401 | Train Perplexity : 91.2910\n",
            "Valid Loss : 3.5450 | Valid_Accuracy : 0.1891 | Valid Perplexity : 302.6084\n",
            "Valid Perplexity improved from 303.5959 to 302.6084\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:06:11<1:00:49, 152.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:08:42<58:13, 151.90s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 2.9738 | Train_Accuracy : 0.2438 | Train Perplexity : 86.2826\n",
            "Valid Loss : 3.5510 | Valid_Accuracy : 0.1927 | Valid Perplexity : 305.5382\n",
            "Epoch : 28 / 50\n",
            "Train Loss : 2.9247 | Train_Accuracy : 0.2539 | Train Perplexity : 77.3145\n",
            "Valid Loss : 3.5381 | Valid_Accuracy : 0.1939 | Valid Perplexity : 296.9705\n",
            "Valid Loss improved from 3.5437 to 3.5381\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 302.6084 to 296.9705\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:11:15<55:46, 152.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 29 / 50\n",
            "Train Loss : 2.9020 | Train_Accuracy : 0.2586 | Train Perplexity : 73.0296\n",
            "Valid Loss : 3.5333 | Valid_Accuracy : 0.1930 | Valid Perplexity : 291.6763\n",
            "Valid Loss improved from 3.5381 to 3.5333\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 296.9705 to 291.6763\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:13:47<53:17, 152.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:16:19<50:39, 151.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 30 / 50\n",
            "Train Loss : 2.8756 | Train_Accuracy : 0.2638 | Train Perplexity : 68.9582\n",
            "Valid Loss : 3.5428 | Valid_Accuracy : 0.1896 | Valid Perplexity : 298.6130\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:18:50<48:03, 151.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 31 / 50\n",
            "Train Loss : 2.8635 | Train_Accuracy : 0.2659 | Train Perplexity : 66.5418\n",
            "Valid Loss : 3.5592 | Valid_Accuracy : 0.1933 | Valid Perplexity : 306.0963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:21:21<45:29, 151.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 32 / 50\n",
            "Train Loss : 2.8315 | Train_Accuracy : 0.2733 | Train Perplexity : 61.9925\n",
            "Valid Loss : 3.5471 | Valid_Accuracy : 0.1942 | Valid Perplexity : 298.2791\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:23:53<42:56, 151.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 33 / 50\n",
            "Train Loss : 2.8087 | Train_Accuracy : 0.2779 | Train Perplexity : 58.7402\n",
            "Valid Loss : 3.5525 | Valid_Accuracy : 0.1879 | Valid Perplexity : 301.2456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [1:26:24<40:24, 151.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 34 / 50\n",
            "Train Loss : 2.7896 | Train_Accuracy : 0.2828 | Train Perplexity : 56.1612\n",
            "Valid Loss : 3.5502 | Valid_Accuracy : 0.1930 | Valid Perplexity : 298.7617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [1:28:56<41:51, 156.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 35 / 50\n",
            "Train Loss : 2.7607 | Train_Accuracy : 0.2895 | Train Perplexity : 52.6684\n",
            "Valid Loss : 3.5393 | Valid_Accuracy : 0.1942 | Valid Perplexity : 291.8446\n",
            "best_loss_epoch : 29\n",
            "best_ppl_epoch : 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    with torch.no_grad():\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_attn, t_attn, s_outputs.reshape(-1, s_outputs.size(-1)), t_logits.reshape(-1, t_logits.size(-1)), labels.reshape(-1))\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_my_loss_function_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_my_loss_function_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 8\n",
        "\n",
        "MSE - last layer(custom) & KL - logits\n",
        "\n",
        "PPL : 204.5668\n",
        "\n",
        "Best Epoch : 50"
      ],
      "metadata": {
        "id": "NiOR-50T1Zd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def KL_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  student_log_probs = F.log_softmax(student_logits / T, dim=-1)\n",
        "  teacher_probs = F.softmax(teacher_logits / T, dim=-1)\n",
        "  eps = 1e-8\n",
        "  KL = (teacher_probs * (torch.log(teacher_probs + eps) - student_log_probs)).sum(dim=-1)\n",
        "\n",
        "  if mask is not None:\n",
        "    KL = KL * mask\n",
        "    return (KL.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return KL.mean() * (T**2)\n",
        "\n",
        "class KD_Loss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.A = alpha\n",
        "    self.ignore_index = ignore_index\n",
        "    self.label_smoothing = label_smoothing\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    KL_Loss = KL_divergence(student_logits, teacher_logits, self.T, mask)\n",
        "    CE_Loss = F.cross_entropy(student_logits, labels, ignore_index=self.ignore_index, label_smoothing=self.label_smoothing)\n",
        "    total_Loss = self.A * KL_Loss + (1 - self.A) * CE_Loss\n",
        "    return total_Loss\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def MSE(s_attn, t_attn):\n",
        "  '''\n",
        "  s_attn: list of student attention tensors (shape: [batch, heads, seq_len, seq_len])\n",
        "  t_attn: list of teacher attention tensors (same shape)\n",
        "\n",
        "  Returns:\n",
        "    Average MSE loss between each student attention layer and teacher's last attention layer\n",
        "  '''\n",
        "  last_t_attn = average_head(t_attn[-1])  # [batch, seq_len, seq_len]\n",
        "\n",
        "  # loss initialization\n",
        "  loss = torch.zeros((), device=last_t_attn.device, dtype=last_t_attn.dtype)\n",
        "\n",
        "  for attn in s_attn:\n",
        "    attn = average_head(attn)  # [batch, seq_len, seq_len]\n",
        "    loss = loss + ((attn - last_t_attn) ** 2).mean()\n",
        "\n",
        "  loss /= len(s_attn)\n",
        "  return loss\n",
        "\n",
        "class MSE_Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, s_attn, t_attn):\n",
        "    loss = MSE(s_attn, t_attn)\n",
        "    return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, beta, label_smoothing=0.1 ,ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.B = beta\n",
        "    self.ignore_index = ignore_index\n",
        "    self.kd_loss = KD_Loss(temperature, alpha, label_smoothing, ignore_index=ignore_index)\n",
        "    self.mse = MSE_Loss()\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits, s_attn, t_attn):\n",
        "    kd_l = self.kd_loss(student_logits, labels, teacher_logits)\n",
        "    mse_l = self.mse(s_attn, t_attn)\n",
        "    total_loss = kd_l + self.B * mse_l\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "sHGqlV6Byn2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ],
      "metadata": {
        "id": "o7S6BQgOynxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "edd53abb3c7043aea0c51e1045071c98",
            "eb8ed3fbee024932acaba6456b331763",
            "9d7b261fbc824f20b01c4b2cfe4802f0",
            "99a4b06b68464d7c9d933de22b5855c7",
            "84692af977394be69b599b22cfb411bf",
            "1c3889c97218468a82bf6384414282e6",
            "cc5386fd8cae4b97a77878ece0f0ddd0",
            "b7406e2777e44f6b8f94c158fbff5301",
            "4685bee5b53e483dbd13b5ec3f60f15c",
            "5bff0d11331e44f7977aef16cd80cb75",
            "50016c6f0d5d46de8109df74f9f5d8e8",
            "a485b49aaa8c4b2aaa59b8361f0d7acb",
            "13f3ddc876b24db9869e12950cba6d4b",
            "15164159809c41cf8c4c5fdd0cf9a379",
            "48b2f603714845f0be9fdc87131ebd68",
            "6b3dac84a5174e1c96f4e4e1269dd408",
            "a39ba4de13754f89b991649494306f48",
            "69ea3385dc094c7ab2a085d116778940",
            "ba2a1ba44f22441f835486cdc1c6c847",
            "25ac73d491224e21ba6041b95bb48508",
            "1ce576f82216448882305ca5a02901c2",
            "944b88fd371746cfaf4ca70968339d5c"
          ]
        },
        "outputId": "ff0bd533-b581-41ce-f69b-ae625c3b84d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edd53abb3c7043aea0c51e1045071c98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a485b49aaa8c4b2aaa59b8361f0d7acb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting loss functoin, optimizer, and scheduler\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# alpha : KL & CE (1 - alpha), beta : MSE loss\n",
        "\n",
        "loss_function = TotalLoss(temperature=2.0, alpha=0.5, beta=0.05)\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "PzevWkQEynsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ],
      "metadata": {
        "id": "vp036VC0yncu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ],
      "metadata": {
        "id": "NmfdI3qxynPa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada6bd8b-2f34-43c2-c043-3d8b1960f58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 6.2443 | Train_Accuracy : 0.0501 | Train Perplexity : 2063.3432\n",
            "Valid Loss : 6.2478 | Valid_Accuracy : 0.0428 | Valid Perplexity : 1926.4079\n",
            "Valid Loss improved from inf to 6.2478\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1926.4079\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 1/50 [03:57<3:14:18, 237.94s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 6.2380 | Train_Accuracy : 0.0593 | Train Perplexity : 2031.3430\n",
            "Valid Loss : 6.2476 | Valid_Accuracy : 0.0476 | Valid Perplexity : 1909.9462\n",
            "Valid Loss improved from 6.2478 to 6.2476\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1926.4079 to 1909.9462\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 2/50 [07:22<2:54:31, 218.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 5.7891 | Train_Accuracy : 0.0892 | Train Perplexity : 1302.0746\n",
            "Valid Loss : 5.8168 | Valid_Accuracy : 0.0833 | Valid Perplexity : 1268.2956\n",
            "Valid Loss improved from 6.2476 to 5.8168\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1909.9462 to 1268.2956\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 3/50 [10:46<2:46:05, 212.03s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 5.7182 | Train_Accuracy : 0.0995 | Train Perplexity : 1200.4960\n",
            "Valid Loss : 5.7653 | Valid_Accuracy : 0.0955 | Valid Perplexity : 1194.8420\n",
            "Valid Loss improved from 5.8168 to 5.7653\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1268.2956 to 1194.8420\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 4/50 [14:11<2:40:15, 209.02s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 5.5278 | Train_Accuracy : 0.1098 | Train Perplexity : 1003.5501\n",
            "Valid Loss : 5.5926 | Valid_Accuracy : 0.0984 | Valid Perplexity : 1022.2628\n",
            "Valid Loss improved from 5.7653 to 5.5926\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1194.8420 to 1022.2628\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 5/50 [17:35<2:35:33, 207.40s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 5.3971 | Train_Accuracy : 0.1138 | Train Perplexity : 866.5005\n",
            "Valid Loss : 5.4329 | Valid_Accuracy : 0.1049 | Valid Perplexity : 869.6076\n",
            "Valid Loss improved from 5.5926 to 5.4329\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1022.2628 to 869.6076\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 6/50 [20:59<2:31:03, 206.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 5.2159 | Train_Accuracy : 0.1287 | Train Perplexity : 687.3879\n",
            "Valid Loss : 5.2576 | Valid_Accuracy : 0.1173 | Valid Perplexity : 698.5033\n",
            "Valid Loss improved from 5.4329 to 5.2576\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 869.6076 to 698.5033\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [24:21<2:26:52, 204.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 5.0787 | Train_Accuracy : 0.1352 | Train Perplexity : 587.6223\n",
            "Valid Loss : 5.1119 | Valid_Accuracy : 0.1267 | Valid Perplexity : 596.2657\n",
            "Valid Loss improved from 5.2576 to 5.1119\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 698.5033 to 596.2657\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [27:45<2:23:12, 204.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 4.9696 | Train_Accuracy : 0.1439 | Train Perplexity : 512.1690\n",
            "Valid Loss : 4.9894 | Valid_Accuracy : 0.1315 | Valid Perplexity : 514.8932\n",
            "Valid Loss improved from 5.1119 to 4.9894\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 596.2657 to 514.8932\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [31:08<2:19:23, 203.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 4.9006 | Train_Accuracy : 0.1450 | Train Perplexity : 475.7048\n",
            "Valid Loss : 4.9603 | Valid_Accuracy : 0.1312 | Valid Perplexity : 509.8474\n",
            "Valid Loss improved from 4.9894 to 4.9603\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 514.8932 to 509.8474\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [34:31<2:15:42, 203.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 4.8363 | Train_Accuracy : 0.1499 | Train Perplexity : 434.5024\n",
            "Valid Loss : 4.8965 | Valid_Accuracy : 0.1389 | Valid Perplexity : 467.6934\n",
            "Valid Loss improved from 4.9603 to 4.8965\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 509.8474 to 467.6934\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [37:54<2:12:11, 203.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 4.7262 | Train_Accuracy : 0.1573 | Train Perplexity : 381.3804\n",
            "Valid Loss : 4.8378 | Valid_Accuracy : 0.1420 | Valid Perplexity : 439.6152\n",
            "Valid Loss improved from 4.8965 to 4.8378\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 467.6934 to 439.6152\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [41:17<2:08:43, 203.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 4.6581 | Train_Accuracy : 0.1606 | Train Perplexity : 351.5346\n",
            "Valid Loss : 4.7972 | Valid_Accuracy : 0.1522 | Valid Perplexity : 422.3111\n",
            "Valid Loss improved from 4.8378 to 4.7972\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 439.6152 to 422.3111\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [44:40<2:05:21, 203.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 4.6142 | Train_Accuracy : 0.1634 | Train Perplexity : 331.9342\n",
            "Valid Loss : 4.7671 | Valid_Accuracy : 0.1477 | Valid Perplexity : 407.4298\n",
            "Valid Loss improved from 4.7972 to 4.7671\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 422.3111 to 407.4298\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [48:03<2:01:58, 203.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [51:25<1:58:17, 202.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 15 / 50\n",
            "Train Loss : 4.6129 | Train_Accuracy : 0.1644 | Train Perplexity : 325.6635\n",
            "Valid Loss : 4.7868 | Valid_Accuracy : 0.1542 | Valid Perplexity : 414.8476\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 4.4325 | Train_Accuracy : 0.1770 | Train Perplexity : 261.8913\n",
            "Valid Loss : 4.6261 | Valid_Accuracy : 0.1667 | Valid Perplexity : 342.8715\n",
            "Valid Loss improved from 4.7671 to 4.6261\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 407.4298 to 342.8715\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [54:47<1:54:53, 202.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [58:09<1:51:20, 202.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 17 / 50\n",
            "Train Loss : 4.4715 | Train_Accuracy : 0.1746 | Train Perplexity : 270.5392\n",
            "Valid Loss : 4.6675 | Valid_Accuracy : 0.1633 | Valid Perplexity : 357.0297\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 4.3652 | Train_Accuracy : 0.1811 | Train Perplexity : 237.3796\n",
            "Valid Loss : 4.5836 | Valid_Accuracy : 0.1687 | Valid Perplexity : 325.8708\n",
            "Valid Loss improved from 4.6261 to 4.5836\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 342.8715 to 325.8708\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [1:01:31<1:47:56, 202.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 19 / 50\n",
            "Train Loss : 4.2529 | Train_Accuracy : 0.1895 | Train Perplexity : 204.6791\n",
            "Valid Loss : 4.5271 | Valid_Accuracy : 0.1763 | Valid Perplexity : 305.4530\n",
            "Valid Loss improved from 4.5836 to 4.5271\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 325.8708 to 305.4530\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [1:04:54<1:44:37, 202.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 4.2254 | Train_Accuracy : 0.1916 | Train Perplexity : 197.6573\n",
            "Valid Loss : 4.5234 | Valid_Accuracy : 0.1746 | Valid Perplexity : 303.9985\n",
            "Valid Loss improved from 4.5271 to 4.5234\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 305.4530 to 303.9985\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:08:18<1:41:22, 202.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 4.1936 | Train_Accuracy : 0.1957 | Train Perplexity : 187.1080\n",
            "Valid Loss : 4.4937 | Valid_Accuracy : 0.1823 | Valid Perplexity : 292.0655\n",
            "Valid Loss improved from 4.5234 to 4.4937\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 303.9985 to 292.0655\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:11:40<1:37:58, 202.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:15:02<1:34:26, 202.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 22 / 50\n",
            "Train Loss : 4.1891 | Train_Accuracy : 0.1965 | Train Perplexity : 183.2159\n",
            "Valid Loss : 4.5045 | Valid_Accuracy : 0.1840 | Valid Perplexity : 294.8488\n",
            "Epoch : 23 / 50\n",
            "Train Loss : 4.1427 | Train_Accuracy : 0.1997 | Train Perplexity : 172.5951\n",
            "Valid Loss : 4.4739 | Valid_Accuracy : 0.1814 | Valid Perplexity : 286.9917\n",
            "Valid Loss improved from 4.4937 to 4.4739\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 292.0655 to 286.9917\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:18:24<1:31:04, 202.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 24 / 50\n",
            "Train Loss : 4.0813 | Train_Accuracy : 0.2053 | Train Perplexity : 158.5847\n",
            "Valid Loss : 4.4294 | Valid_Accuracy : 0.1854 | Valid Perplexity : 270.3822\n",
            "Valid Loss improved from 4.4739 to 4.4294\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 286.9917 to 270.3822\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:21:47<1:27:43, 202.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 25 / 50\n",
            "Train Loss : 4.0300 | Train_Accuracy : 0.2084 | Train Perplexity : 147.3279\n",
            "Valid Loss : 4.4017 | Valid_Accuracy : 0.1834 | Valid Perplexity : 260.4896\n",
            "Valid Loss improved from 4.4294 to 4.4017\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 270.3822 to 260.4896\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:25:10<1:24:23, 202.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 26 / 50\n",
            "Train Loss : 3.9618 | Train_Accuracy : 0.2163 | Train Perplexity : 134.1733\n",
            "Valid Loss : 4.3697 | Valid_Accuracy : 0.1874 | Valid Perplexity : 253.5633\n",
            "Valid Loss improved from 4.4017 to 4.3697\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 260.4896 to 253.5633\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:28:32<1:21:02, 202.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:31:54<1:17:32, 202.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 3.9769 | Train_Accuracy : 0.2157 | Train Perplexity : 135.4008\n",
            "Valid Loss : 4.3968 | Valid_Accuracy : 0.1908 | Valid Perplexity : 260.6296\n",
            "Epoch : 28 / 50\n",
            "Train Loss : 3.9206 | Train_Accuracy : 0.2218 | Train Perplexity : 125.6639\n",
            "Valid Loss : 4.3576 | Valid_Accuracy : 0.1891 | Valid Perplexity : 249.4783\n",
            "Valid Loss improved from 4.3697 to 4.3576\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 253.5633 to 249.4783\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:35:16<1:14:12, 202.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:38:38<1:10:42, 202.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 29 / 50\n",
            "Train Loss : 3.9074 | Train_Accuracy : 0.2230 | Train Perplexity : 122.0951\n",
            "Valid Loss : 4.3675 | Valid_Accuracy : 0.1913 | Valid Perplexity : 251.2411\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:41:59<1:07:18, 201.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 30 / 50\n",
            "Train Loss : 3.8983 | Train_Accuracy : 0.2241 | Train Perplexity : 120.0287\n",
            "Valid Loss : 4.3741 | Valid_Accuracy : 0.1868 | Valid Perplexity : 255.0734\n",
            "Epoch : 31 / 50\n",
            "Train Loss : 3.8319 | Train_Accuracy : 0.2307 | Train Perplexity : 109.4912\n",
            "Valid Loss : 4.3078 | Valid_Accuracy : 0.1981 | Valid Perplexity : 234.2559\n",
            "Valid Loss improved from 4.3576 to 4.3078\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 249.4783 to 234.2559\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:45:22<1:04:00, 202.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:48:43<1:00:35, 201.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 32 / 50\n",
            "Train Loss : 3.8135 | Train_Accuracy : 0.2340 | Train Perplexity : 106.3117\n",
            "Valid Loss : 4.3110 | Valid_Accuracy : 0.1942 | Valid Perplexity : 235.5979\n",
            "Epoch : 33 / 50\n",
            "Train Loss : 3.7892 | Train_Accuracy : 0.2367 | Train Perplexity : 102.4296\n",
            "Valid Loss : 4.3059 | Valid_Accuracy : 0.1922 | Valid Perplexity : 233.7580\n",
            "Valid Loss improved from 4.3078 to 4.3059\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 234.2559 to 233.7580\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:52:06<57:16, 202.14s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 34 / 50\n",
            "Train Loss : 3.7392 | Train_Accuracy : 0.2428 | Train Perplexity : 95.6180\n",
            "Valid Loss : 4.2615 | Valid_Accuracy : 0.1959 | Valid Perplexity : 221.7530\n",
            "Valid Loss improved from 4.3059 to 4.2615\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 233.7580 to 221.7530\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [1:55:29<53:55, 202.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [1:58:50<50:30, 202.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 35 / 50\n",
            "Train Loss : 3.7284 | Train_Accuracy : 0.2440 | Train Perplexity : 93.8264\n",
            "Valid Loss : 4.2745 | Valid_Accuracy : 0.1933 | Valid Perplexity : 225.0391\n",
            "Epoch : 36 / 50\n",
            "Train Loss : 3.7082 | Train_Accuracy : 0.2471 | Train Perplexity : 90.7881\n",
            "Valid Loss : 4.2532 | Valid_Accuracy : 0.1942 | Valid Perplexity : 219.1607\n",
            "Valid Loss improved from 4.2615 to 4.2532\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 221.7530 to 219.1607\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [2:02:13<47:11, 202.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [2:05:34<43:46, 202.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 37 / 50\n",
            "Train Loss : 3.6979 | Train_Accuracy : 0.2482 | Train Perplexity : 89.1415\n",
            "Valid Loss : 4.2535 | Valid_Accuracy : 0.1984 | Valid Perplexity : 219.7281\n",
            "Epoch : 38 / 50\n",
            "Train Loss : 3.6663 | Train_Accuracy : 0.2522 | Train Perplexity : 85.4114\n",
            "Valid Loss : 4.2317 | Valid_Accuracy : 0.1993 | Valid Perplexity : 214.2318\n",
            "Valid Loss improved from 4.2532 to 4.2317\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 219.1607 to 214.2318\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [2:08:57<40:26, 202.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [2:12:18<37:01, 202.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 39 / 50\n",
            "Train Loss : 3.6673 | Train_Accuracy : 0.2525 | Train Perplexity : 85.1159\n",
            "Valid Loss : 4.2366 | Valid_Accuracy : 0.1959 | Valid Perplexity : 215.1196\n",
            "Epoch : 40 / 50\n",
            "Train Loss : 3.6459 | Train_Accuracy : 0.2555 | Train Perplexity : 82.6055\n",
            "Valid Loss : 4.2283 | Valid_Accuracy : 0.1947 | Valid Perplexity : 212.8977\n",
            "Valid Loss improved from 4.2317 to 4.2283\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 214.2318 to 212.8977\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [2:15:41<33:41, 202.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 41 / 50\n",
            "Train Loss : 3.6285 | Train_Accuracy : 0.2575 | Train Perplexity : 80.5759\n",
            "Valid Loss : 4.2137 | Valid_Accuracy : 0.1990 | Valid Perplexity : 209.2359\n",
            "Valid Loss improved from 4.2283 to 4.2137\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 212.8977 to 209.2359\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [2:19:04<30:21, 202.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [2:22:25<26:56, 202.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 42 / 50\n",
            "Train Loss : 3.6274 | Train_Accuracy : 0.2582 | Train Perplexity : 80.0588\n",
            "Valid Loss : 4.2181 | Valid_Accuracy : 0.1984 | Valid Perplexity : 210.1908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [2:25:47<23:33, 201.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 43 / 50\n",
            "Train Loss : 3.6272 | Train_Accuracy : 0.2580 | Train Perplexity : 79.8516\n",
            "Valid Loss : 4.2179 | Valid_Accuracy : 0.1998 | Valid Perplexity : 210.3716\n",
            "Epoch : 44 / 50\n",
            "Train Loss : 3.6086 | Train_Accuracy : 0.2608 | Train Perplexity : 77.7548\n",
            "Valid Loss : 4.2090 | Valid_Accuracy : 0.1964 | Valid Perplexity : 208.1439\n",
            "Valid Loss improved from 4.2137 to 4.2090\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 209.2359 to 208.1439\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [2:29:10<20:13, 202.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 45 / 50\n",
            "Train Loss : 3.6016 | Train_Accuracy : 0.2615 | Train Perplexity : 76.8968\n",
            "Valid Loss : 4.2042 | Valid_Accuracy : 0.1973 | Valid Perplexity : 207.2093\n",
            "Valid Loss improved from 4.2090 to 4.2042\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 208.1439 to 207.2093\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [2:32:33<16:52, 202.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [2:35:55<13:29, 202.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 46 / 50\n",
            "Train Loss : 3.5945 | Train_Accuracy : 0.2625 | Train Perplexity : 76.0310\n",
            "Valid Loss : 4.2045 | Valid_Accuracy : 0.1987 | Valid Perplexity : 207.2470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [2:39:16<10:06, 202.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 47 / 50\n",
            "Train Loss : 3.5938 | Train_Accuracy : 0.2630 | Train Perplexity : 75.7618\n",
            "Valid Loss : 4.2115 | Valid_Accuracy : 0.1970 | Valid Perplexity : 208.7500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [2:42:38<06:43, 201.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 48 / 50\n",
            "Train Loss : 3.5842 | Train_Accuracy : 0.2643 | Train Perplexity : 74.6637\n",
            "Valid Loss : 4.2080 | Valid_Accuracy : 0.1959 | Valid Perplexity : 208.6674\n",
            "Epoch : 49 / 50\n",
            "Train Loss : 3.5745 | Train_Accuracy : 0.2653 | Train Perplexity : 73.5173\n",
            "Valid Loss : 4.1997 | Valid_Accuracy : 0.1970 | Valid Perplexity : 206.4060\n",
            "Valid Loss improved from 4.2042 to 4.1997\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 207.2093 to 206.4060\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [2:46:01<03:22, 202.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 50 / 50\n",
            "Train Loss : 3.5669 | Train_Accuracy : 0.2670 | Train Perplexity : 72.7042\n",
            "Valid Loss : 4.1926 | Valid_Accuracy : 0.1978 | Valid Perplexity : 204.5668\n",
            "Valid Loss improved from 4.1997 to 4.1926\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 206.4060 to 204.5668\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [2:49:23<00:00, 203.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "best_loss_epoch : 50\n",
            "best_ppl_epoch : 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 9\n",
        "\n",
        "MSE - last layer(custom) & JS - logits\n",
        "\n",
        "PPL : 272.1792\n",
        "\n",
        "Best Epoch : 22"
      ],
      "metadata": {
        "id": "Bzi3qHrg2V5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def JS_divergence(student_logits, teacher_logits, temperature, mask=None): # logits에 적용\n",
        "  T = temperature\n",
        "  eps=1e-9\n",
        "  student_prob = F.softmax(student_logits / temperature, dim=-1)\n",
        "  teacher_prob = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "  M = 0.5 * (student_prob + teacher_prob)\n",
        "  M_log = torch.log(M + eps)\n",
        "  student_log = torch.log(student_prob + eps)\n",
        "  teacher_log = torch.log(teacher_prob + eps)\n",
        "\n",
        "  D_p = (teacher_prob * (teacher_log - M_log)).sum(dim=-1)\n",
        "  D_q = (student_prob * (student_log - M_log)).sum(dim=-1)\n",
        "\n",
        "  JS = 0.5 * (D_p + D_q)\n",
        "  if mask is not None:\n",
        "    JS = JS * mask\n",
        "    return (JS.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return JS.mean() * (T**2)\n",
        "\n",
        "class KD_Loss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.A = alpha\n",
        "    self.ignore_index = ignore_index\n",
        "    self.label_smoothing = label_smoothing\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    JS_Loss = JS_divergence(student_logits, teacher_logits, self.T, mask)\n",
        "    CE_Loss = F.cross_entropy(student_logits, labels, ignore_index=self.ignore_index, label_smoothing=self.label_smoothing)\n",
        "    total_Loss = self.A * JS_Loss + (1 - self.A) * CE_Loss\n",
        "    return total_Loss\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def MSE(s_attn, t_attn):\n",
        "  '''\n",
        "  s_attn: list of student attention tensors (shape: [batch, heads, seq_len, seq_len])\n",
        "  t_attn: list of teacher attention tensors (same shape)\n",
        "\n",
        "  Returns:\n",
        "    Average MSE loss between each student attention layer and teacher's last attention layer\n",
        "  '''\n",
        "  last_t_attn = average_head(t_attn[-1])  # [batch, seq_len, seq_len]\n",
        "\n",
        "  loss = torch.zeros((), device=last_t_attn.device, dtype=last_t_attn.dtype)\n",
        "\n",
        "  for attn in s_attn:\n",
        "    attn = average_head(attn)  # [batch, seq_len, seq_len]\n",
        "    loss = loss + ((attn - last_t_attn) ** 2).mean()\n",
        "\n",
        "  loss /= len(s_attn)\n",
        "  return loss\n",
        "\n",
        "class MSE_Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, s_attn, t_attn):\n",
        "    loss = MSE(s_attn, t_attn)\n",
        "    return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, beta, label_smoothing=0.1 ,ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.B = beta\n",
        "    self.ignore_index = ignore_index\n",
        "    self.kd_loss = KD_Loss(temperature, alpha, label_smoothing, ignore_index=ignore_index)\n",
        "    self.mse = MSE_Loss()\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits, s_attn, t_attn):\n",
        "    kd_l = self.kd_loss(student_logits, labels, teacher_logits)\n",
        "    mse_l = self.mse(s_attn, t_attn)\n",
        "    total_loss = kd_l + self.B * mse_l\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "F3rpx-Sv6pGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ],
      "metadata": {
        "id": "wqwUI1N96p3D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "36482bf621ba41d6b6a87e91ac211c5d",
            "bcbf0f44a3354f11805da063d62cf3f2",
            "54252322e3e54986972c23df40c6b1d8",
            "e8ddf9330d2144b09ed502c9cdb3e624",
            "d72f4ff0a1924deaa4e9fd3b1d5c67f0",
            "50d656fa817847c6bf293430076bedcf",
            "9cf48e6bca094eec8bf19aa354fcbaad",
            "bab6d375c2364400924b073259f5937a",
            "b1cd45f8ce6140a682904b836c79c65d",
            "8e607b7026b8494c87028563b1ef0f14",
            "b8207fcc62944bb0810d552d86ac149c",
            "1c9fd10e25ac4bee9efdf4272073cc5b",
            "c89baadfe4ad4638bdd9fdb909fdab52",
            "2c395254515a4a1fb2aaaff0fc2aa0b9",
            "8c337e246ad945d1acf1905bb0bbff57",
            "c4e1e6a9c5f74eca98bdc3cf3921ec95",
            "0f8f8794fdd043aabdfd18a0fcfccc6c",
            "b4e133100abe4dec839b5631b22c291c",
            "5980430b8ad14d0db89239e9f7638ff5",
            "f1c912d71898454b9b98e02e21e70dfc",
            "f2cabbe46f9146f38715761b31b95dbd",
            "015b298765b54ab9ba1d2e8eaf10a239"
          ]
        },
        "outputId": "65ae3ba4-aa3b-4205-b2f8-e24c6090090c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36482bf621ba41d6b6a87e91ac211c5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c9fd10e25ac4bee9efdf4272073cc5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting loss function, optimzer, and scheduler\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# alpha : JS & CE (1-alpha), beta : MSE\n",
        "loss_function = TotalLoss(temperature=2.0, alpha=0.5, beta=0.05)\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "NavDJIBD6pxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Evaluation function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ],
      "metadata": {
        "id": "4Ol-oonZ6pp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ],
      "metadata": {
        "id": "9KTsMxUC6pPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7246d67d-e73b-4d68-af9c-b0cb0bbf2aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 4.4259 | Train_Accuracy : 0.0507 | Train Perplexity : 1968.4336\n",
            "Valid Loss : 4.4097 | Valid_Accuracy : 0.0400 | Valid Perplexity : 1880.8474\n",
            "Valid Loss improved from inf to 4.4097\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1880.8474\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [04:45<3:53:06, 285.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 4.2608 | Train_Accuracy : 0.0965 | Train Perplexity : 1395.1080\n",
            "Valid Loss : 4.2612 | Valid_Accuracy : 0.0935 | Valid Perplexity : 1381.7139\n",
            "Valid Loss improved from 4.4097 to 4.2612\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1880.8474 to 1381.7139\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [08:49<3:28:53, 261.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 4.0929 | Train_Accuracy : 0.1140 | Train Perplexity : 987.4102\n",
            "Valid Loss : 4.1077 | Valid_Accuracy : 0.1052 | Valid Perplexity : 1006.3383\n",
            "Valid Loss improved from 4.2612 to 4.1077\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1381.7139 to 1006.3383\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [12:53<3:18:23, 253.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 4.0048 | Train_Accuracy : 0.1275 | Train Perplexity : 822.0382\n",
            "Valid Loss : 4.0230 | Valid_Accuracy : 0.1182 | Valid Perplexity : 845.8413\n",
            "Valid Loss improved from 4.1077 to 4.0230\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1006.3383 to 845.8413\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [16:57<3:11:19, 249.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 3.8737 | Train_Accuracy : 0.1408 | Train Perplexity : 632.0602\n",
            "Valid Loss : 3.9097 | Valid_Accuracy : 0.1284 | Valid Perplexity : 677.3722\n",
            "Valid Loss improved from 4.0230 to 3.9097\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 845.8413 to 677.3722\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [21:01<3:05:36, 247.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 3.8189 | Train_Accuracy : 0.1460 | Train Perplexity : 561.5114\n",
            "Valid Loss : 3.8516 | Valid_Accuracy : 0.1352 | Valid Perplexity : 599.6227\n",
            "Valid Loss improved from 3.9097 to 3.8516\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 677.3722 to 599.6227\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [25:05<3:00:37, 246.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 3.7613 | Train_Accuracy : 0.1481 | Train Perplexity : 501.3448\n",
            "Valid Loss : 3.8195 | Valid_Accuracy : 0.1386 | Valid Perplexity : 568.0191\n",
            "Valid Loss improved from 3.8516 to 3.8195\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 599.6227 to 568.0191\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [29:09<2:55:57, 245.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 3.6818 | Train_Accuracy : 0.1609 | Train Perplexity : 418.7763\n",
            "Valid Loss : 3.7448 | Valid_Accuracy : 0.1528 | Valid Perplexity : 479.7109\n",
            "Valid Loss improved from 3.8195 to 3.7448\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 568.0191 to 479.7109\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [33:12<2:51:28, 244.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 3.6061 | Train_Accuracy : 0.1676 | Train Perplexity : 356.4964\n",
            "Valid Loss : 3.7059 | Valid_Accuracy : 0.1593 | Valid Perplexity : 441.1084\n",
            "Valid Loss improved from 3.7448 to 3.7059\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 479.7109 to 441.1084\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [37:16<2:47:13, 244.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 3.5469 | Train_Accuracy : 0.1722 | Train Perplexity : 316.4320\n",
            "Valid Loss : 3.6676 | Valid_Accuracy : 0.1607 | Valid Perplexity : 410.0151\n",
            "Valid Loss improved from 3.7059 to 3.6676\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 441.1084 to 410.0151\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [41:20<2:42:56, 244.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 3.4778 | Train_Accuracy : 0.1800 | Train Perplexity : 272.2783\n",
            "Valid Loss : 3.6162 | Valid_Accuracy : 0.1704 | Valid Perplexity : 367.8697\n",
            "Valid Loss improved from 3.6676 to 3.6162\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 410.0151 to 367.8697\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [45:24<2:38:44, 244.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 3.4448 | Train_Accuracy : 0.1856 | Train Perplexity : 253.3825\n",
            "Valid Loss : 3.6113 | Valid_Accuracy : 0.1811 | Valid Perplexity : 363.1274\n",
            "Valid Loss improved from 3.6162 to 3.6113\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 367.8697 to 363.1274\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [49:28<2:34:34, 244.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 3.4156 | Train_Accuracy : 0.1889 | Train Perplexity : 236.2782\n",
            "Valid Loss : 3.5982 | Valid_Accuracy : 0.1783 | Valid Perplexity : 350.6801\n",
            "Valid Loss improved from 3.6113 to 3.5982\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 363.1274 to 350.6801\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [53:32<2:30:34, 244.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 3.3417 | Train_Accuracy : 0.1965 | Train Perplexity : 201.5110\n",
            "Valid Loss : 3.5641 | Valid_Accuracy : 0.1882 | Valid Perplexity : 326.4922\n",
            "Valid Loss improved from 3.5982 to 3.5641\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 350.6801 to 326.4922\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [57:36<2:26:26, 244.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 15 / 50\n",
            "Train Loss : 3.2797 | Train_Accuracy : 0.2039 | Train Perplexity : 177.1435\n",
            "Valid Loss : 3.5419 | Valid_Accuracy : 0.1825 | Valid Perplexity : 313.6293\n",
            "Valid Loss improved from 3.5641 to 3.5419\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 326.4922 to 313.6293\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [1:01:40<2:22:19, 243.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 3.2380 | Train_Accuracy : 0.2089 | Train Perplexity : 161.6031\n",
            "Valid Loss : 3.5256 | Valid_Accuracy : 0.1882 | Valid Perplexity : 302.8589\n",
            "Valid Loss improved from 3.5419 to 3.5256\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 313.6293 to 302.8589\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [1:05:44<2:18:13, 243.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 17 / 50\n",
            "Train Loss : 3.1911 | Train_Accuracy : 0.2151 | Train Perplexity : 144.3994\n",
            "Valid Loss : 3.5229 | Valid_Accuracy : 0.1882 | Valid Perplexity : 297.8982\n",
            "Valid Loss improved from 3.5256 to 3.5229\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 302.8589 to 297.8982\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [1:09:47<2:14:06, 243.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [1:13:50<2:09:51, 243.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 18 / 50\n",
            "Train Loss : 3.1740 | Train_Accuracy : 0.2180 | Train Perplexity : 138.6615\n",
            "Valid Loss : 3.5313 | Valid_Accuracy : 0.1888 | Valid Perplexity : 302.6015\n",
            "Epoch : 19 / 50\n",
            "Train Loss : 3.1015 | Train_Accuracy : 0.2289 | Train Perplexity : 118.1056\n",
            "Valid Loss : 3.5091 | Valid_Accuracy : 0.1905 | Valid Perplexity : 288.5363\n",
            "Valid Loss improved from 3.5229 to 3.5091\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 297.8982 to 288.5363\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [1:17:54<2:05:56, 243.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 3.0586 | Train_Accuracy : 0.2372 | Train Perplexity : 107.0371\n",
            "Valid Loss : 3.4998 | Valid_Accuracy : 0.1944 | Valid Perplexity : 281.7413\n",
            "Valid Loss improved from 3.5091 to 3.4998\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 288.5363 to 281.7413\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:21:58<2:01:53, 243.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 3.0177 | Train_Accuracy : 0.2443 | Train Perplexity : 97.6925\n",
            "Valid Loss : 3.4965 | Valid_Accuracy : 0.1981 | Valid Perplexity : 279.5396\n",
            "Valid Loss improved from 3.4998 to 3.4965\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 281.7413 to 279.5396\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:26:02<1:57:50, 243.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 22 / 50\n",
            "Train Loss : 2.9680 | Train_Accuracy : 0.2539 | Train Perplexity : 87.0110\n",
            "Valid Loss : 3.4872 | Valid_Accuracy : 0.2024 | Valid Perplexity : 272.1792\n",
            "Valid Loss improved from 3.4965 to 3.4872\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 279.5396 to 272.1792\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:30:06<1:53:49, 243.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:34:09<1:49:38, 243.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 23 / 50\n",
            "Train Loss : 2.9318 | Train_Accuracy : 0.2615 | Train Perplexity : 80.1181\n",
            "Valid Loss : 3.4928 | Valid_Accuracy : 0.1998 | Valid Perplexity : 275.4059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:38:12<1:45:26, 243.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 24 / 50\n",
            "Train Loss : 2.8820 | Train_Accuracy : 0.2717 | Train Perplexity : 71.7690\n",
            "Valid Loss : 3.4925 | Valid_Accuracy : 0.2004 | Valid Perplexity : 274.4773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:42:14<1:41:18, 243.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 25 / 50\n",
            "Train Loss : 2.8603 | Train_Accuracy : 0.2765 | Train Perplexity : 67.4500\n",
            "Valid Loss : 3.5096 | Valid_Accuracy : 0.2061 | Valid Perplexity : 280.9874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:46:17<1:37:11, 242.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 26 / 50\n",
            "Train Loss : 2.8243 | Train_Accuracy : 0.2852 | Train Perplexity : 62.3876\n",
            "Valid Loss : 3.5136 | Valid_Accuracy : 0.1998 | Valid Perplexity : 284.3473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:50:20<1:33:06, 242.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 2.7860 | Train_Accuracy : 0.2933 | Train Perplexity : 56.9739\n",
            "Valid Loss : 3.5203 | Valid_Accuracy : 0.1959 | Valid Perplexity : 286.6892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:54:23<1:37:26, 254.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 28 / 50\n",
            "Train Loss : 2.7434 | Train_Accuracy : 0.3049 | Train Perplexity : 51.6878\n",
            "Valid Loss : 3.5154 | Valid_Accuracy : 0.1970 | Valid Perplexity : 283.1749\n",
            "best_loss_epoch : 22\n",
            "best_ppl_epoch : 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 10\n",
        "\n",
        "MSE - layerwise & KL and Cos - logits\n",
        "\n",
        "PPL : 198.7038\n",
        "\n",
        "Best Epoch : 49"
      ],
      "metadata": {
        "id": "Tyx-mz5A3Y9g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt3GQKGobNP2"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def KL_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  student_log_probs = F.log_softmax(student_logits / T, dim=-1)\n",
        "  teacher_probs = F.softmax(teacher_logits / T, dim=-1)\n",
        "  eps = 1e-8\n",
        "  KL = (teacher_probs * (torch.log(teacher_probs + eps) - student_log_probs)).sum(dim=-1)\n",
        "\n",
        "  if mask is not None:\n",
        "    KL = KL * mask\n",
        "    return (KL.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return KL.mean() * (T**2)\n",
        "\n",
        "def logit_cosine_similarity(s_logit, t_logit, mask=None):\n",
        "  eps = 1e-9\n",
        "  norm_x = torch.sqrt((s_logit * s_logit).sum(dim=-1) + eps)\n",
        "  norm_y = torch.sqrt((t_logit * t_logit).sum(dim=-1) + eps)\n",
        "  dot = (s_logit * t_logit).sum(dim=-1)\n",
        "  cos_sim = dot / (norm_x * norm_y)\n",
        "  cos_sim = 1 - cos_sim\n",
        "  if mask is not None:\n",
        "    cos_sim = cos_sim * mask\n",
        "    return cos_sim.sum() / mask.sum()\n",
        "  else:\n",
        "    return cos_sim.mean() # (B,)\n",
        "\n",
        "class KD_Loss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.A = alpha\n",
        "    self.ignore_index = ignore_index\n",
        "    self.label_smoothing = label_smoothing\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    KL_Loss = KL_divergence(student_logits, teacher_logits, self.T, mask)\n",
        "    CE_Loss = F.cross_entropy(student_logits, labels, ignore_index=self.ignore_index, label_smoothing=self.label_smoothing)\n",
        "    total_Loss = self.A * KL_Loss + (1 - self.A) * CE_Loss\n",
        "    return total_Loss\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def MSE(s_attn, t_attn):\n",
        "  assert len(t_attn) % 2 == 0, 'Len of teacher attention layers must be divisible by 2.'\n",
        "  loss = 0.0\n",
        "  num_s_layer = len(s_attn)\n",
        "  num_t_layer = len(t_attn)\n",
        "  idx_list = []\n",
        "  t_attn_list = []\n",
        "  if 2 * num_s_layer == num_t_layer:\n",
        "    for i in range(num_s_layer):\n",
        "      t_attn_list.append(t_attn[2*i+1])\n",
        "  elif 2 * num_s_layer > num_t_layer:\n",
        "    for i in range(num_s_layer):\n",
        "      if 2*i + 1 >= num_t_layer:\n",
        "        break\n",
        "      idx_list.append(2*i+1)\n",
        "    while len(idx_list) < num_s_layer:\n",
        "      for i in range(num_t_layer - 2, -1, -2):\n",
        "        if i not in idx_list:\n",
        "          idx_list.append(i)\n",
        "        if len(idx_list) == num_s_layer:\n",
        "          break\n",
        "    idx_list.sort()\n",
        "    for idx in idx_list:\n",
        "      t_attn_list.append(t_attn[idx])\n",
        "  elif 2 * num_s_layer < num_t_layer:\n",
        "    for i in range(num_t_layer-1, -1, -2):\n",
        "      if len(idx_list) == 2 * num_s_layer:\n",
        "        break\n",
        "      idx_list.append(i)\n",
        "    idx_list.sort()\n",
        "    for idx in idx_list:\n",
        "      t_attn_list.append(t_attn[idx])\n",
        "\n",
        "  assert num_s_layer == len(t_attn_list), f'Len of t_attn_list ({len(t_attn_list)}) do no match len of s_attn ({num_s_layer})'\n",
        "  for i in range(num_s_layer):\n",
        "    loss += torch.mean((average_head(s_attn[i]) - average_head(t_attn_list[i])) ** 2)\n",
        "  loss /= num_s_layer\n",
        "  return loss\n",
        "\n",
        "class MSE_Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, s_attn, t_attn):\n",
        "    loss = MSE(s_attn, t_attn)\n",
        "    return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, beta, gamma, label_smoothing=0.1 ,ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.B = beta\n",
        "    self.G = gamma\n",
        "    self.ignore_index = ignore_index\n",
        "    self.kd_loss = KD_Loss(temperature, alpha, label_smoothing, ignore_index=ignore_index)\n",
        "    self.mse = MSE_Loss()\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits, s_attn, t_attn):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    kd_l = self.kd_loss(student_logits, labels, teacher_logits)\n",
        "    mse_l = self.mse(s_attn, t_attn)\n",
        "    logit_cos = logit_cosine_similarity(student_logits, teacher_logits, mask)\n",
        "    total_loss = kd_l + self.B * mse_l + self.G * logit_cos\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a113267204e4489cabe7b0ebd4a1c546",
            "0690a4422a0341bb8af73bb3c396daeb",
            "b8b0d27047de41db96ffb890fb04eb4a",
            "f5995f949fda47259f04d6e17781a36d",
            "7ad8be1d6e78458e8e7f035a4574e90e",
            "8312da941393409e85f67af302b390a9",
            "7e1a3dc8909d457b894f22cb87c7f0b9",
            "cd5fe320068e4b5db4b7031596959581",
            "45306eea31044bf68fc805872bebd488",
            "a5d9e446cc3b48b2984348ea60e7c569",
            "138d76d727074102bd12d40e829f2473",
            "a197d93302b946d7980f43ebd7690d2c",
            "b6d39d68d1f647c19e2529d0a234ba7a",
            "06372719f0df477bb273e25da83cd36e",
            "8b8abc0cf0554410933722e7b9d00af2",
            "3aa8448d25a74bbeaefb7f43ac94dd83",
            "8466a5e36019483da8457b638c10e8c6",
            "17b073b81ce646de992699ec07e763d6",
            "1bcc5dfe4d6742d882c9a9d625df15ea",
            "71043e83fd1846e89d07e48c0deb43c1",
            "ef44dd16c83d4274976219af2833406b",
            "235af82358e4443eb393b06e1bcc9e13"
          ]
        },
        "id": "Iq1SZj5Sxp53",
        "outputId": "c4feb11b-52a0-4053-8734-a4d518e4f784"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a113267204e4489cabe7b0ebd4a1c546"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a197d93302b946d7980f43ebd7690d2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Load Model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtgWlM7uxp_f"
      },
      "outputs": [],
      "source": [
        "# Setting loss function, optimzer, and scheduler\n",
        "\n",
        "# alpha : KL-divergence & CE loss (1-alpha)\n",
        "# beta : MSE for layers\n",
        "# gamma : cos for logits\n",
        "\n",
        "loss_function = TotalLoss(temperature = 2.0, alpha = 0.5, beta = 0.05, gamma = 0.05)\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GLu-WckxqD-"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJco9bh7xqHe",
        "outputId": "756c5024-7ad9-4c4a-8701-2a029fd1848d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 6.2539 | Train_Accuracy : 0.0507 | Train Perplexity : 2058.5437\n",
            "Valid Loss : 6.2668 | Valid_Accuracy : 0.0400 | Valid Perplexity : 1944.3027\n",
            "Valid Loss improved from inf to 6.2668\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1944.3027\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [02:40<2:10:46, 160.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 6.2373 | Train_Accuracy : 0.0632 | Train Perplexity : 2008.1948\n",
            "Valid Loss : 6.2485 | Valid_Accuracy : 0.0524 | Valid Perplexity : 1902.6980\n",
            "Valid Loss improved from 6.2668 to 6.2485\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1944.3027 to 1902.6980\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [05:08<2:02:35, 153.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 5.7926 | Train_Accuracy : 0.0911 | Train Perplexity : 1300.4858\n",
            "Valid Loss : 5.8229 | Valid_Accuracy : 0.0799 | Valid Perplexity : 1279.0895\n",
            "Valid Loss improved from 6.2485 to 5.8229\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1902.6980 to 1279.0895\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [07:36<1:58:07, 150.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 5.6192 | Train_Accuracy : 0.1046 | Train Perplexity : 1106.9544\n",
            "Valid Loss : 5.6708 | Valid_Accuracy : 0.0938 | Valid Perplexity : 1110.2924\n",
            "Valid Loss improved from 5.8229 to 5.6708\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1279.0895 to 1110.2924\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [10:03<1:54:29, 149.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 5.4253 | Train_Accuracy : 0.1179 | Train Perplexity : 882.0116\n",
            "Valid Loss : 5.4824 | Valid_Accuracy : 0.1071 | Valid Perplexity : 891.6808\n",
            "Valid Loss improved from 5.6708 to 5.4824\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1110.2924 to 891.6808\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [12:31<1:51:30, 148.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 5.3566 | Train_Accuracy : 0.1212 | Train Perplexity : 809.3449\n",
            "Valid Loss : 5.4206 | Valid_Accuracy : 0.1088 | Valid Perplexity : 845.1608\n",
            "Valid Loss improved from 5.4824 to 5.4206\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 891.6808 to 845.1608\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [14:58<1:48:37, 148.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 5.2290 | Train_Accuracy : 0.1312 | Train Perplexity : 678.9912\n",
            "Valid Loss : 5.2323 | Valid_Accuracy : 0.1239 | Valid Perplexity : 660.7738\n",
            "Valid Loss improved from 5.4206 to 5.2323\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 845.1608 to 660.7738\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [17:24<1:45:50, 147.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 5.0894 | Train_Accuracy : 0.1357 | Train Perplexity : 578.2993\n",
            "Valid Loss : 5.1183 | Valid_Accuracy : 0.1253 | Valid Perplexity : 581.1533\n",
            "Valid Loss improved from 5.2323 to 5.1183\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 660.7738 to 581.1533\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [19:51<1:43:06, 147.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 4.9651 | Train_Accuracy : 0.1436 | Train Perplexity : 500.4581\n",
            "Valid Loss : 5.0240 | Valid_Accuracy : 0.1298 | Valid Perplexity : 532.0038\n",
            "Valid Loss improved from 5.1183 to 5.0240\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 581.1533 to 532.0038\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [22:17<1:40:29, 147.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 4.8532 | Train_Accuracy : 0.1503 | Train Perplexity : 440.1106\n",
            "Valid Loss : 4.9369 | Valid_Accuracy : 0.1344 | Valid Perplexity : 484.1135\n",
            "Valid Loss improved from 5.0240 to 4.9369\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 532.0038 to 484.1135\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [24:44<1:37:53, 146.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 4.7313 | Train_Accuracy : 0.1564 | Train Perplexity : 383.8557\n",
            "Valid Loss : 4.8030 | Valid_Accuracy : 0.1471 | Valid Perplexity : 420.1173\n",
            "Valid Loss improved from 4.9369 to 4.8030\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 484.1135 to 420.1173\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [27:10<1:35:23, 146.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 4.6638 | Train_Accuracy : 0.1609 | Train Perplexity : 352.4440\n",
            "Valid Loss : 4.7976 | Valid_Accuracy : 0.1477 | Valid Perplexity : 417.5582\n",
            "Valid Loss improved from 4.8030 to 4.7976\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 420.1173 to 417.5582\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [29:37<1:32:53, 146.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [32:03<1:30:17, 146.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 13 / 50\n",
            "Train Loss : 4.6901 | Train_Accuracy : 0.1584 | Train Perplexity : 357.1914\n",
            "Valid Loss : 4.8559 | Valid_Accuracy : 0.1499 | Valid Perplexity : 444.3626\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 4.5647 | Train_Accuracy : 0.1671 | Train Perplexity : 307.6186\n",
            "Valid Loss : 4.7309 | Valid_Accuracy : 0.1514 | Valid Perplexity : 387.8292\n",
            "Valid Loss improved from 4.7976 to 4.7309\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 417.5582 to 387.8292\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [34:29<1:27:51, 146.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 15 / 50\n",
            "Train Loss : 4.4965 | Train_Accuracy : 0.1703 | Train Perplexity : 280.3853\n",
            "Valid Loss : 4.6862 | Valid_Accuracy : 0.1630 | Valid Perplexity : 365.9777\n",
            "Valid Loss improved from 4.7309 to 4.6862\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 387.8292 to 365.9777\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [36:57<1:25:35, 146.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 4.4148 | Train_Accuracy : 0.1778 | Train Perplexity : 252.2326\n",
            "Valid Loss : 4.6316 | Valid_Accuracy : 0.1687 | Valid Perplexity : 347.1828\n",
            "Valid Loss improved from 4.6862 to 4.6316\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 365.9777 to 347.1828\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [39:23<1:23:07, 146.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 17 / 50\n",
            "Train Loss : 4.4313 | Train_Accuracy : 0.1784 | Train Perplexity : 253.2309\n",
            "Valid Loss : 4.6319 | Valid_Accuracy : 0.1652 | Valid Perplexity : 341.1788\n",
            "Valid Perplexity improved from 347.1828 to 341.1788\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [41:49<1:20:34, 146.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 4.3013 | Train_Accuracy : 0.1862 | Train Perplexity : 216.9985\n",
            "Valid Loss : 4.5416 | Valid_Accuracy : 0.1732 | Valid Perplexity : 312.0896\n",
            "Valid Loss improved from 4.6316 to 4.5416\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 341.1788 to 312.0896\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [44:16<1:18:08, 146.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 19 / 50\n",
            "Train Loss : 4.2435 | Train_Accuracy : 0.1916 | Train Perplexity : 199.5576\n",
            "Valid Loss : 4.4944 | Valid_Accuracy : 0.1752 | Valid Perplexity : 292.6566\n",
            "Valid Loss improved from 4.5416 to 4.4944\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 312.0896 to 292.6566\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [46:43<1:15:44, 146.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 4.1514 | Train_Accuracy : 0.1985 | Train Perplexity : 176.3942\n",
            "Valid Loss : 4.4367 | Valid_Accuracy : 0.1806 | Valid Perplexity : 272.8808\n",
            "Valid Loss improved from 4.4944 to 4.4367\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 292.6566 to 272.8808\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [49:09<1:13:19, 146.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [51:35<1:10:41, 146.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 21 / 50\n",
            "Train Loss : 4.1796 | Train_Accuracy : 0.1961 | Train Perplexity : 180.5908\n",
            "Valid Loss : 4.4790 | Valid_Accuracy : 0.1772 | Valid Perplexity : 286.6798\n",
            "Epoch : 22 / 50\n",
            "Train Loss : 4.1005 | Train_Accuracy : 0.2020 | Train Perplexity : 162.7157\n",
            "Valid Loss : 4.4241 | Valid_Accuracy : 0.1837 | Valid Perplexity : 269.2365\n",
            "Valid Loss improved from 4.4367 to 4.4241\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 272.8808 to 269.2365\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [54:02<1:08:23, 146.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 23 / 50\n",
            "Train Loss : 4.0819 | Train_Accuracy : 0.2047 | Train Perplexity : 157.7185\n",
            "Valid Loss : 4.4260 | Valid_Accuracy : 0.1871 | Valid Perplexity : 269.2299\n",
            "Valid Perplexity improved from 269.2365 to 269.2299\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [56:28<1:05:53, 146.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 24 / 50\n",
            "Train Loss : 4.0313 | Train_Accuracy : 0.2095 | Train Perplexity : 146.4589\n",
            "Valid Loss : 4.3916 | Valid_Accuracy : 0.1817 | Valid Perplexity : 258.7557\n",
            "Valid Loss improved from 4.4241 to 4.3916\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 269.2299 to 258.7557\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [58:55<1:03:29, 146.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 25 / 50\n",
            "Train Loss : 3.9859 | Train_Accuracy : 0.2138 | Train Perplexity : 137.3881\n",
            "Valid Loss : 4.3693 | Valid_Accuracy : 0.1857 | Valid Perplexity : 252.2816\n",
            "Valid Loss improved from 4.3916 to 4.3693\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 258.7557 to 252.2816\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:01:21<1:01:02, 146.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 26 / 50\n",
            "Train Loss : 3.9508 | Train_Accuracy : 0.2182 | Train Perplexity : 130.3480\n",
            "Valid Loss : 4.3433 | Valid_Accuracy : 0.1893 | Valid Perplexity : 244.1539\n",
            "Valid Loss improved from 4.3693 to 4.3433\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 252.2816 to 244.1539\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:03:47<58:33, 146.42s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 27 / 50\n",
            "Train Loss : 3.8858 | Train_Accuracy : 0.2242 | Train Perplexity : 119.4369\n",
            "Valid Loss : 4.3231 | Valid_Accuracy : 0.1905 | Valid Perplexity : 237.7785\n",
            "Valid Loss improved from 4.3433 to 4.3231\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 244.1539 to 237.7785\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:06:14<56:05, 146.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 28 / 50\n",
            "Train Loss : 3.8551 | Train_Accuracy : 0.2286 | Train Perplexity : 113.6967\n",
            "Valid Loss : 4.2975 | Valid_Accuracy : 0.1933 | Valid Perplexity : 230.9574\n",
            "Valid Loss improved from 4.3231 to 4.2975\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 237.7785 to 230.9574\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:08:40<53:43, 146.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 29 / 50\n",
            "Train Loss : 3.8218 | Train_Accuracy : 0.2324 | Train Perplexity : 107.7640\n",
            "Valid Loss : 4.2861 | Valid_Accuracy : 0.1959 | Valid Perplexity : 226.9910\n",
            "Valid Loss improved from 4.2975 to 4.2861\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 230.9574 to 226.9910\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:11:07<51:17, 146.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:13:33<48:44, 146.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 30 / 50\n",
            "Train Loss : 3.8212 | Train_Accuracy : 0.2335 | Train Perplexity : 106.8071\n",
            "Valid Loss : 4.3043 | Valid_Accuracy : 0.1993 | Valid Perplexity : 231.9208\n",
            "Epoch : 31 / 50\n",
            "Train Loss : 3.7673 | Train_Accuracy : 0.2396 | Train Perplexity : 99.2698\n",
            "Valid Loss : 4.2711 | Valid_Accuracy : 0.1978 | Valid Perplexity : 223.4398\n",
            "Valid Loss improved from 4.2861 to 4.2711\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 226.9910 to 223.4398\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:15:59<46:20, 146.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 32 / 50\n",
            "Train Loss : 3.7332 | Train_Accuracy : 0.2437 | Train Perplexity : 94.2958\n",
            "Valid Loss : 4.2490 | Valid_Accuracy : 0.2012 | Valid Perplexity : 217.0776\n",
            "Valid Loss improved from 4.2711 to 4.2490\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 223.4398 to 217.0776\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:18:26<43:54, 146.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 33 / 50\n",
            "Train Loss : 3.7067 | Train_Accuracy : 0.2473 | Train Perplexity : 90.6456\n",
            "Valid Loss : 4.2298 | Valid_Accuracy : 0.1987 | Valid Perplexity : 213.2599\n",
            "Valid Loss improved from 4.2490 to 4.2298\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 217.0776 to 213.2599\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:20:52<41:28, 146.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [1:23:18<38:59, 146.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 34 / 50\n",
            "Train Loss : 3.6986 | Train_Accuracy : 0.2485 | Train Perplexity : 88.9117\n",
            "Valid Loss : 4.2418 | Valid_Accuracy : 0.2004 | Valid Perplexity : 215.7379\n",
            "Epoch : 35 / 50\n",
            "Train Loss : 3.6692 | Train_Accuracy : 0.2527 | Train Perplexity : 85.3682\n",
            "Valid Loss : 4.2307 | Valid_Accuracy : 0.2032 | Valid Perplexity : 213.1103\n",
            "Valid Perplexity improved from 213.2599 to 213.1103\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [1:25:44<36:31, 146.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 36 / 50\n",
            "Train Loss : 3.6470 | Train_Accuracy : 0.2557 | Train Perplexity : 82.3793\n",
            "Valid Loss : 4.2132 | Valid_Accuracy : 0.2038 | Valid Perplexity : 208.2130\n",
            "Valid Loss improved from 4.2298 to 4.2132\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 213.1103 to 208.2130\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [1:28:10<34:07, 146.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 37 / 50\n",
            "Train Loss : 3.6310 | Train_Accuracy : 0.2577 | Train Perplexity : 80.3418\n",
            "Valid Loss : 4.2075 | Valid_Accuracy : 0.1990 | Valid Perplexity : 207.3096\n",
            "Valid Loss improved from 4.2132 to 4.2075\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 208.2130 to 207.3096\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [1:30:37<31:42, 146.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 38 / 50\n",
            "Train Loss : 3.6255 | Train_Accuracy : 0.2588 | Train Perplexity : 79.3443\n",
            "Valid Loss : 4.1975 | Valid_Accuracy : 0.2018 | Valid Perplexity : 204.6468\n",
            "Valid Loss improved from 4.2075 to 4.1975\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 207.3096 to 204.6468\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [1:33:04<29:17, 146.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [1:35:29<26:46, 146.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 39 / 50\n",
            "Train Loss : 3.6094 | Train_Accuracy : 0.2613 | Train Perplexity : 77.4649\n",
            "Valid Loss : 4.2079 | Valid_Accuracy : 0.1984 | Valid Perplexity : 207.2546\n",
            "Epoch : 40 / 50\n",
            "Train Loss : 3.5897 | Train_Accuracy : 0.2640 | Train Perplexity : 75.3631\n",
            "Valid Loss : 4.1899 | Valid_Accuracy : 0.2032 | Valid Perplexity : 203.2435\n",
            "Valid Loss improved from 4.1975 to 4.1899\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 204.6468 to 203.2435\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [1:37:55<24:21, 146.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 41 / 50\n",
            "Train Loss : 3.5864 | Train_Accuracy : 0.2645 | Train Perplexity : 74.7239\n",
            "Valid Loss : 4.1927 | Valid_Accuracy : 0.2001 | Valid Perplexity : 203.0898\n",
            "Valid Perplexity improved from 203.2435 to 203.0898\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [1:40:21<21:55, 146.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 42 / 50\n",
            "Train Loss : 3.5710 | Train_Accuracy : 0.2672 | Train Perplexity : 73.0364\n",
            "Valid Loss : 4.1857 | Valid_Accuracy : 0.2046 | Valid Perplexity : 201.7978\n",
            "Valid Loss improved from 4.1899 to 4.1857\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 203.0898 to 201.7978\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [1:42:48<19:30, 146.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 43 / 50\n",
            "Train Loss : 3.5631 | Train_Accuracy : 0.2679 | Train Perplexity : 72.1325\n",
            "Valid Loss : 4.1840 | Valid_Accuracy : 0.2061 | Valid Perplexity : 201.5610\n",
            "Valid Loss improved from 4.1857 to 4.1840\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 201.7978 to 201.5610\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [1:45:15<17:04, 146.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [1:47:40<14:37, 146.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 44 / 50\n",
            "Train Loss : 3.5587 | Train_Accuracy : 0.2689 | Train Perplexity : 71.5014\n",
            "Valid Loss : 4.1857 | Valid_Accuracy : 0.2021 | Valid Perplexity : 201.7063\n",
            "Epoch : 45 / 50\n",
            "Train Loss : 3.5486 | Train_Accuracy : 0.2704 | Train Perplexity : 70.4232\n",
            "Valid Loss : 4.1821 | Valid_Accuracy : 0.2058 | Valid Perplexity : 200.7486\n",
            "Valid Loss improved from 4.1840 to 4.1821\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 201.5610 to 200.7486\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [1:50:07<12:11, 146.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 46 / 50\n",
            "Train Loss : 3.5448 | Train_Accuracy : 0.2709 | Train Perplexity : 69.8855\n",
            "Valid Loss : 4.1768 | Valid_Accuracy : 0.2029 | Valid Perplexity : 199.9349\n",
            "Valid Loss improved from 4.1821 to 4.1768\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 200.7486 to 199.9349\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [1:52:34<09:45, 146.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 47 / 50\n",
            "Train Loss : 3.5364 | Train_Accuracy : 0.2718 | Train Perplexity : 68.9543\n",
            "Valid Loss : 4.1767 | Valid_Accuracy : 0.2046 | Valid Perplexity : 199.8334\n",
            "Valid Loss improved from 4.1768 to 4.1767\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 199.9349 to 199.8334\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [1:55:00<07:19, 146.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 48 / 50\n",
            "Train Loss : 3.5315 | Train_Accuracy : 0.2730 | Train Perplexity : 68.3067\n",
            "Valid Loss : 4.1751 | Valid_Accuracy : 0.2049 | Valid Perplexity : 199.2545\n",
            "Valid Loss improved from 4.1767 to 4.1751\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 199.8334 to 199.2545\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [1:57:27<04:52, 146.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Epoch : 49 / 50\n",
            "Train Loss : 3.5216 | Train_Accuracy : 0.2742 | Train Perplexity : 67.3592\n",
            "Valid Loss : 4.1719 | Valid_Accuracy : 0.2024 | Valid Perplexity : 198.7038\n",
            "Valid Loss improved from 4.1751 to 4.1719\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 199.2545 to 198.7038\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [1:59:53<02:26, 146.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_my_loss_function_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [2:02:19<00:00, 146.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 50 / 50\n",
            "Train Loss : 3.5144 | Train_Accuracy : 0.2756 | Train Perplexity : 66.5345\n",
            "Valid Loss : 4.1742 | Valid_Accuracy : 0.2032 | Valid Perplexity : 199.2251\n",
            "best_loss_epoch : 49\n",
            "best_ppl_epoch : 49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    with torch.no_grad():\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_my_loss_function_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_my_loss_function_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 11\n",
        "\n",
        "MSE - layerwise & JS and Cos - logits\n",
        "\n",
        "PPL : 276.6832\n",
        "\n",
        "Best Epoch : 28"
      ],
      "metadata": {
        "id": "FfeX_Vy94i3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def JS_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  eps=1e-9\n",
        "  student_prob = F.softmax(student_logits / temperature, dim=-1)\n",
        "  teacher_prob = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "  M = 0.5 * (student_prob + teacher_prob)\n",
        "  M_log = torch.log(M + eps)\n",
        "  student_log = torch.log(student_prob + eps)\n",
        "  teacher_log = torch.log(teacher_prob + eps)\n",
        "\n",
        "  D_p = (teacher_prob * (teacher_log - M_log)).sum(dim=-1)\n",
        "  D_q = (student_prob * (student_log - M_log)).sum(dim=-1)\n",
        "\n",
        "  JS = 0.5 * (D_p + D_q)\n",
        "  if mask is not None:\n",
        "    JS = JS * mask\n",
        "    return (JS.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return JS.mean() * (T**2)\n",
        "\n",
        "def logit_cosine_similarity(s_logit, t_logit, mask=None):\n",
        "  eps = 1e-9\n",
        "  norm_x = torch.sqrt((s_logit * s_logit).sum(dim=-1) + eps)\n",
        "  norm_y = torch.sqrt((t_logit * t_logit).sum(dim=-1) + eps)\n",
        "  dot = (s_logit * t_logit).sum(dim=-1)\n",
        "  cos_sim = dot / (norm_x * norm_y)\n",
        "  cos_sim = 1 - cos_sim\n",
        "  if mask is not None:\n",
        "    cos_sim = cos_sim * mask\n",
        "    return cos_sim.sum() / mask.sum()\n",
        "  else:\n",
        "    return cos_sim.mean() # (B,)\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L]\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def layerwise_MSE(s_attn, t_attn):\n",
        "  assert len(t_attn) % 2 == 0, 'Len of teacher attention layers must be divisible by 2.'\n",
        "  weighted_loss = 0.0\n",
        "  eps = 1e-9\n",
        "  num_s_layer = len(s_attn)\n",
        "  num_t_layer = len(t_attn)\n",
        "  idx_list = []\n",
        "  t_attn_list = []\n",
        "  if 2 * num_s_layer == num_t_layer:\n",
        "    for i in range(num_s_layer):\n",
        "      t_attn_list.append(t_attn[2*i+1])\n",
        "  elif 2 * num_s_layer > num_t_layer:\n",
        "    for i in range(num_s_layer):\n",
        "      if 2*i + 1 >= num_t_layer:\n",
        "        break\n",
        "      idx_list.append(2*i+1)\n",
        "    while len(idx_list) < num_s_layer:\n",
        "      for i in range(num_t_layer - 2, -1, -2):\n",
        "        if i not in idx_list:\n",
        "          idx_list.append(i)\n",
        "        if len(idx_list) == num_s_layer:\n",
        "          break\n",
        "    idx_list.sort()\n",
        "    for idx in idx_list:\n",
        "      t_attn_list.append(t_attn[idx])\n",
        "  elif 2 * num_s_layer < num_t_layer:\n",
        "    for i in range(num_t_layer-1, -1, -2):\n",
        "      if len(idx_list) == 2 * num_s_layer:\n",
        "        break\n",
        "      idx_list.append(i)\n",
        "    idx_list.sort()\n",
        "    for idx in idx_list:\n",
        "      t_attn_list.append(t_attn[idx])\n",
        "\n",
        "  assert num_s_layer == len(t_attn_list), f'Len of t_attn_list ({len(t_attn_list)}) do no match len of s_attn ({num_s_layer})'\n",
        "\n",
        "  per_layer_mse = []\n",
        "  loss = 0.0\n",
        "  for i in range(num_s_layer):\n",
        "    s_avg = average_head(s_attn[i])\n",
        "    t_avg = average_head(t_attn_list[i]).detach()\n",
        "    diff = s_avg - t_avg\n",
        "    mse = torch.mean(diff ** 2)\n",
        "    loss += mse\n",
        "  loss /= num_s_layer\n",
        "  return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, alpha, beta, gamma, delta, temperature=2.0, label_smoothing=0.1, ignore_index=-100):\n",
        "      super().__init__()\n",
        "      self.alpha = alpha\n",
        "      self.beta = beta\n",
        "      self.gamma = gamma\n",
        "      self.delta = delta\n",
        "      self.temperature = temperature\n",
        "      self.label_smoothing = label_smoothing\n",
        "      self.ignore_index = ignore_index\n",
        "\n",
        "  def forward(self, s_attn, t_attn, s_logits, t_logits, labels):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    with torch.no_grad():\n",
        "      t_attn = [a.detach() for a in t_attn]\n",
        "      t_logits = t_logits.detach()\n",
        "\n",
        "    # 1. Attention Loss\n",
        "    attn_loss = layerwise_MSE(s_attn, t_attn)\n",
        "\n",
        "    # 2. JS Divergence\n",
        "    js_loss = JS_divergence(s_logits, t_logits, self.temperature, mask)\n",
        "\n",
        "    # 3. Cross-Entropy Loss\n",
        "    ce_loss = F.cross_entropy(\n",
        "        s_logits.view(-1, s_logits.size(-1)),\n",
        "        labels.view(-1),\n",
        "        ignore_index=self.ignore_index,\n",
        "        label_smoothing=self.label_smoothing\n",
        "    )\n",
        "\n",
        "    # 4. Cos for logits\n",
        "    logit_cos = logit_cosine_similarity(s_logits, t_logits, mask)\n",
        "\n",
        "    # 4. Final loss\n",
        "    total_loss = (\n",
        "        self.alpha * attn_loss +\n",
        "        self.beta * js_loss +\n",
        "        self.gamma * ce_loss +\n",
        "        self.delta * logit_cos\n",
        "    )\n",
        "\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "JKgj8VCCKPbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ],
      "metadata": {
        "id": "DuhtsVCTKQCo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed035b1-a89d-4622-ddab-65a7b24891e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting loss function, optimzer, and scheduler\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "'''\n",
        "self.alpha * attn_loss +\n",
        "self.beta * js_loss +\n",
        "self.gamma * ce_loss +\n",
        "self.delta * logit_cos\n",
        "'''\n",
        "loss_function = TotalLoss(alpha= 0.05, beta= 0.5, gamma= 0.5, delta= 0.05)\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "9w7v-vB8KP86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Evaluation function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_attn, t_attn, s_outputs.reshape(-1, s_outputs.size(-1)), t_logits.reshape(-1, t_logits.size(-1)), labels.reshape(-1)) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ],
      "metadata": {
        "id": "RlMEzdEcKP23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_attn, t_attn, s_outputs.reshape(-1, s_outputs.size(-1)), t_logits.reshape(-1, t_logits.size(-1)), labels.reshape(-1))\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ],
      "metadata": {
        "id": "jlV44EtMKPuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58f5ec2-fdcc-4460-f385-409d61128e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 4.4311 | Train_Accuracy : 0.0507 | Train Perplexity : 1968.8800\n",
            "Valid Loss : 4.4148 | Valid_Accuracy : 0.0400 | Valid Perplexity : 1880.5205\n",
            "Valid Loss improved from inf to 4.4148\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1880.5205\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [03:03<2:29:44, 183.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 4.2703 | Train_Accuracy : 0.0924 | Train Perplexity : 1410.8175\n",
            "Valid Loss : 4.2710 | Valid_Accuracy : 0.0882 | Valid Perplexity : 1398.3865\n",
            "Valid Loss improved from 4.4148 to 4.2710\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1880.5205 to 1398.3865\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [06:05<2:26:20, 182.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 4.1663 | Train_Accuracy : 0.1030 | Train Perplexity : 1146.5921\n",
            "Valid Loss : 4.1779 | Valid_Accuracy : 0.0927 | Valid Perplexity : 1160.7957\n",
            "Valid Loss improved from 4.2710 to 4.1779\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1398.3865 to 1160.7957\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [09:08<2:23:13, 182.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 4.0020 | Train_Accuracy : 0.1284 | Train Perplexity : 809.6438\n",
            "Valid Loss : 4.0336 | Valid_Accuracy : 0.1190 | Valid Perplexity : 855.4391\n",
            "Valid Loss improved from 4.1779 to 4.0336\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1160.7957 to 855.4391\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [12:11<2:20:10, 182.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 3.8998 | Train_Accuracy : 0.1379 | Train Perplexity : 655.3231\n",
            "Valid Loss : 3.9297 | Valid_Accuracy : 0.1224 | Valid Perplexity : 692.7315\n",
            "Valid Loss improved from 4.0336 to 3.9297\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 855.4391 to 692.7315\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [15:14<2:17:07, 182.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 3.7925 | Train_Accuracy : 0.1484 | Train Perplexity : 526.8983\n",
            "Valid Loss : 3.8219 | Valid_Accuracy : 0.1355 | Valid Perplexity : 559.5460\n",
            "Valid Loss improved from 3.9297 to 3.8219\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 692.7315 to 559.5460\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [18:17<2:14:04, 182.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 3.7477 | Train_Accuracy : 0.1501 | Train Perplexity : 482.4461\n",
            "Valid Loss : 3.8184 | Valid_Accuracy : 0.1346 | Valid Perplexity : 559.6696\n",
            "Valid Loss improved from 3.8219 to 3.8184\n",
            "Save the loss Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [21:19<2:10:51, 182.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 3.6687 | Train_Accuracy : 0.1611 | Train Perplexity : 405.9931\n",
            "Valid Loss : 3.7359 | Valid_Accuracy : 0.1539 | Valid Perplexity : 466.8189\n",
            "Valid Loss improved from 3.8184 to 3.7359\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 559.5460 to 466.8189\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [24:21<2:07:49, 182.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 3.6110 | Train_Accuracy : 0.1670 | Train Perplexity : 359.0203\n",
            "Valid Loss : 3.6948 | Valid_Accuracy : 0.1565 | Valid Perplexity : 428.8381\n",
            "Valid Loss improved from 3.7359 to 3.6948\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 466.8189 to 428.8381\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [27:24<2:04:44, 182.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 3.5458 | Train_Accuracy : 0.1722 | Train Perplexity : 312.8153\n",
            "Valid Loss : 3.6732 | Valid_Accuracy : 0.1576 | Valid Perplexity : 410.5471\n",
            "Valid Loss improved from 3.6948 to 3.6732\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 428.8381 to 410.5471\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [30:26<2:01:42, 182.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 3.4754 | Train_Accuracy : 0.1814 | Train Perplexity : 268.3242\n",
            "Valid Loss : 3.6107 | Valid_Accuracy : 0.1635 | Valid Perplexity : 359.7132\n",
            "Valid Loss improved from 3.6732 to 3.6107\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 410.5471 to 359.7132\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [33:29<1:58:42, 182.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 3.4297 | Train_Accuracy : 0.1858 | Train Perplexity : 243.9896\n",
            "Valid Loss : 3.6020 | Valid_Accuracy : 0.1738 | Valid Perplexity : 353.6693\n",
            "Valid Loss improved from 3.6107 to 3.6020\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 359.7132 to 353.6693\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [36:33<1:55:50, 182.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 3.3996 | Train_Accuracy : 0.1905 | Train Perplexity : 227.9988\n",
            "Valid Loss : 3.5857 | Valid_Accuracy : 0.1828 | Valid Perplexity : 340.8322\n",
            "Valid Loss improved from 3.6020 to 3.5857\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 353.6693 to 340.8322\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [39:35<1:52:44, 182.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 3.3366 | Train_Accuracy : 0.1966 | Train Perplexity : 197.8415\n",
            "Valid Loss : 3.5598 | Valid_Accuracy : 0.1825 | Valid Perplexity : 322.2102\n",
            "Valid Loss improved from 3.5857 to 3.5598\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 340.8322 to 322.2102\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [42:38<1:49:40, 182.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [45:40<1:46:23, 182.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 15 / 50\n",
            "Train Loss : 3.3060 | Train_Accuracy : 0.1997 | Train Perplexity : 185.7181\n",
            "Valid Loss : 3.5628 | Valid_Accuracy : 0.1814 | Valid Perplexity : 325.2333\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 3.2429 | Train_Accuracy : 0.2090 | Train Perplexity : 161.1680\n",
            "Valid Loss : 3.5404 | Valid_Accuracy : 0.1868 | Valid Perplexity : 308.2635\n",
            "Valid Loss improved from 3.5598 to 3.5404\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 322.2102 to 308.2635\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [48:42<1:43:21, 182.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 17 / 50\n",
            "Train Loss : 3.2353 | Train_Accuracy : 0.2093 | Train Perplexity : 156.5303\n",
            "Valid Loss : 3.5432 | Valid_Accuracy : 0.1854 | Valid Perplexity : 307.3423\n",
            "Valid Perplexity improved from 308.2635 to 307.3423\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [51:44<1:40:15, 182.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 3.1798 | Train_Accuracy : 0.2174 | Train Perplexity : 139.1614\n",
            "Valid Loss : 3.5259 | Valid_Accuracy : 0.1888 | Valid Perplexity : 296.9025\n",
            "Valid Loss improved from 3.5404 to 3.5259\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 307.3423 to 296.9025\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [54:47<1:37:19, 182.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 19 / 50\n",
            "Train Loss : 3.1315 | Train_Accuracy : 0.2231 | Train Perplexity : 123.9913\n",
            "Valid Loss : 3.5277 | Valid_Accuracy : 0.1908 | Valid Perplexity : 295.2977\n",
            "Valid Perplexity improved from 296.9025 to 295.2977\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [57:49<1:34:14, 182.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 3.0602 | Train_Accuracy : 0.2357 | Train Perplexity : 105.8527\n",
            "Valid Loss : 3.5071 | Valid_Accuracy : 0.1902 | Valid Perplexity : 281.8508\n",
            "Valid Loss improved from 3.5259 to 3.5071\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 295.2977 to 281.8508\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:00:52<1:31:13, 182.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:03:53<1:28:03, 182.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 21 / 50\n",
            "Train Loss : 3.0168 | Train_Accuracy : 0.2440 | Train Perplexity : 96.3473\n",
            "Valid Loss : 3.5073 | Valid_Accuracy : 0.1967 | Valid Perplexity : 282.6724\n",
            "Epoch : 22 / 50\n",
            "Train Loss : 2.9825 | Train_Accuracy : 0.2512 | Train Perplexity : 88.8119\n",
            "Valid Loss : 3.5054 | Valid_Accuracy : 0.2018 | Valid Perplexity : 279.3387\n",
            "Valid Loss improved from 3.5071 to 3.5054\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 281.8508 to 279.3387\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:06:56<1:25:04, 182.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:09:58<1:21:58, 182.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 23 / 50\n",
            "Train Loss : 2.9477 | Train_Accuracy : 0.2570 | Train Perplexity : 81.9588\n",
            "Valid Loss : 3.5081 | Valid_Accuracy : 0.1967 | Valid Perplexity : 281.4202\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:12:59<1:18:52, 182.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 24 / 50\n",
            "Train Loss : 2.8957 | Train_Accuracy : 0.2686 | Train Perplexity : 73.0695\n",
            "Valid Loss : 3.5075 | Valid_Accuracy : 0.2015 | Valid Perplexity : 280.6039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:16:01<1:15:46, 181.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 25 / 50\n",
            "Train Loss : 2.8653 | Train_Accuracy : 0.2749 | Train Perplexity : 67.1843\n",
            "Valid Loss : 3.5158 | Valid_Accuracy : 0.2069 | Valid Perplexity : 281.0288\n",
            "Epoch : 26 / 50\n",
            "Train Loss : 2.8167 | Train_Accuracy : 0.2868 | Train Perplexity : 60.7756\n",
            "Valid Loss : 3.5072 | Valid_Accuracy : 0.2032 | Valid Perplexity : 277.9291\n",
            "Valid Perplexity improved from 279.3387 to 277.9291\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:19:03<1:12:44, 181.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 27 / 50\n",
            "Train Loss : 2.7806 | Train_Accuracy : 0.2956 | Train Perplexity : 55.9532\n",
            "Valid Loss : 3.5080 | Valid_Accuracy : 0.2010 | Valid Perplexity : 277.3673\n",
            "Valid Perplexity improved from 277.9291 to 277.3673\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:22:05<1:09:44, 181.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 28 / 50\n",
            "Train Loss : 2.7444 | Train_Accuracy : 0.3048 | Train Perplexity : 51.2358\n",
            "Valid Loss : 3.5099 | Valid_Accuracy : 0.1976 | Valid Perplexity : 276.6832\n",
            "Valid Perplexity improved from 277.3673 to 276.6832\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:25:07<1:06:43, 181.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:28:08<1:03:39, 181.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 29 / 50\n",
            "Train Loss : 2.7208 | Train_Accuracy : 0.3116 | Train Perplexity : 48.4654\n",
            "Valid Loss : 3.5207 | Valid_Accuracy : 0.2024 | Valid Perplexity : 282.6368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:31:10<1:00:36, 181.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 30 / 50\n",
            "Train Loss : 2.6805 | Train_Accuracy : 0.3224 | Train Perplexity : 44.2560\n",
            "Valid Loss : 3.5223 | Valid_Accuracy : 0.2004 | Valid Perplexity : 283.1758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:34:12<57:36, 181.94s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 31 / 50\n",
            "Train Loss : 2.6663 | Train_Accuracy : 0.3277 | Train Perplexity : 42.6436\n",
            "Valid Loss : 3.5323 | Valid_Accuracy : 0.2052 | Valid Perplexity : 287.5803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:37:14<54:33, 181.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 32 / 50\n",
            "Train Loss : 2.6257 | Train_Accuracy : 0.3386 | Train Perplexity : 38.9127\n",
            "Valid Loss : 3.5306 | Valid_Accuracy : 0.2046 | Valid Perplexity : 286.0246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:40:15<51:29, 181.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 33 / 50\n",
            "Train Loss : 2.6069 | Train_Accuracy : 0.3456 | Train Perplexity : 37.1783\n",
            "Valid Loss : 3.5371 | Valid_Accuracy : 0.2049 | Valid Perplexity : 289.9820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:43:17<53:12, 187.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 34 / 50\n",
            "Train Loss : 2.5811 | Train_Accuracy : 0.3529 | Train Perplexity : 34.9486\n",
            "Valid Loss : 3.5457 | Valid_Accuracy : 0.2089 | Valid Perplexity : 293.9117\n",
            "best_loss_epoch : 22\n",
            "best_ppl_epoch : 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 12\n",
        "\n",
        "MSE - last layer & KL and Cos - logits\n",
        "\n",
        "PPL : 203.5941\n",
        "\n",
        "Best Epoch : 50"
      ],
      "metadata": {
        "id": "xNueMXAw5shC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def KL_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  student_log_probs = F.log_softmax(student_logits / T, dim=-1)\n",
        "  teacher_probs = F.softmax(teacher_logits / T, dim=-1)\n",
        "  eps = 1e-8\n",
        "  KL = (teacher_probs * (torch.log(teacher_probs + eps) - student_log_probs)).sum(dim=-1)\n",
        "\n",
        "  if mask is not None:\n",
        "    KL = KL * mask\n",
        "    return (KL.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return KL.mean() * (T**2)\n",
        "\n",
        "def logit_cosine_similarity(s_logit, t_logit, mask=None):\n",
        "  eps = 1e-9\n",
        "  norm_x = torch.sqrt((s_logit * s_logit).sum(dim=-1) + eps)\n",
        "  norm_y = torch.sqrt((t_logit * t_logit).sum(dim=-1) + eps)\n",
        "  dot = (s_logit * t_logit).sum(dim=-1)\n",
        "  cos_sim = dot / (norm_x * norm_y)\n",
        "  cos_sim = 1 - cos_sim\n",
        "  if mask is not None:\n",
        "    cos_sim = cos_sim * mask\n",
        "    return cos_sim.sum() / mask.sum()\n",
        "  else:\n",
        "    return cos_sim.mean() # (B,)\n",
        "\n",
        "class KD_Loss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.A = alpha\n",
        "    self.ignore_index = ignore_index\n",
        "    self.label_smoothing = label_smoothing\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    KL_Loss = KL_divergence(student_logits, teacher_logits, self.T, mask)\n",
        "    CE_Loss = F.cross_entropy(student_logits, labels, ignore_index=self.ignore_index, label_smoothing=self.label_smoothing)\n",
        "    total_Loss = self.A * KL_Loss + (1 - self.A) * CE_Loss\n",
        "    return total_Loss\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def MSE(s_attn, t_attn):\n",
        "  last_t_attn = t_attn[-1]\n",
        "  last_s_attn = s_attn[-1]\n",
        "  loss = ((average_head(last_s_attn) - average_head(last_t_attn)) ** 2).mean()\n",
        "  return loss\n",
        "\n",
        "class MSE_Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, s_attn, t_attn):\n",
        "    loss = MSE(s_attn, t_attn)\n",
        "    return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, beta, gamma, label_smoothing=0.1 ,ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.B = beta\n",
        "    self.G = gamma\n",
        "    self.ignore_index = ignore_index\n",
        "    self.kd_loss = KD_Loss(temperature, alpha, label_smoothing, ignore_index=ignore_index)\n",
        "    self.mse = MSE_Loss()\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits, s_attn, t_attn):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    kd_l = self.kd_loss(student_logits, labels, teacher_logits)\n",
        "    mse_l = self.mse(s_attn, t_attn)\n",
        "    cos_logits = logit_cosine_similarity(student_logits, teacher_logits, mask)\n",
        "    total_loss = kd_l + self.B * mse_l + self.G * cos_logits\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "JcudOPslOpV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ],
      "metadata": {
        "id": "b0hjxQzXOpQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d010fb-0698-4eaf-d9a6-b5769cdacb6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting loss funciton, optimizer, and scheduler\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# alpha : KL & CE(1-alpha), beta : MSE, gamma : cos for logits\n",
        "loss_function = TotalLoss(temperature=2.0, alpha=0.5, beta=0.05, gamma=0.05)\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "_ion5hnOOpL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ],
      "metadata": {
        "id": "JyACnBWqOpEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ],
      "metadata": {
        "id": "hpENQ7JlOozo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adde85ca-c58c-4867-ec5d-f9cc3195f38a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 6.2539 | Train_Accuracy : 0.0503 | Train Perplexity : 2062.3977\n",
            "Valid Loss : 6.2576 | Valid_Accuracy : 0.0422 | Valid Perplexity : 1925.7958\n",
            "Valid Loss improved from inf to 6.2576\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1925.7958\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [03:35<2:55:43, 215.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 6.2416 | Train_Accuracy : 0.0599 | Train Perplexity : 2018.9945\n",
            "Valid Loss : 6.2511 | Valid_Accuracy : 0.0485 | Valid Perplexity : 1897.5121\n",
            "Valid Loss improved from 6.2576 to 6.2511\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1925.7958 to 1897.5121\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [07:10<2:52:02, 215.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 5.8018 | Train_Accuracy : 0.0922 | Train Perplexity : 1301.5869\n",
            "Valid Loss : 5.8330 | Valid_Accuracy : 0.0819 | Valid Perplexity : 1274.6221\n",
            "Valid Loss improved from 6.2511 to 5.8330\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1897.5121 to 1274.6221\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [10:45<2:48:39, 215.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 5.6203 | Train_Accuracy : 0.1024 | Train Perplexity : 1087.7059\n",
            "Valid Loss : 5.6545 | Valid_Accuracy : 0.0972 | Valid Perplexity : 1072.9651\n",
            "Valid Loss improved from 5.8330 to 5.6545\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1274.6221 to 1072.9651\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [14:20<2:44:55, 215.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 5.5766 | Train_Accuracy : 0.1057 | Train Perplexity : 1034.8092\n",
            "Valid Loss : 5.6151 | Valid_Accuracy : 0.0952 | Valid Perplexity : 1029.7297\n",
            "Valid Loss improved from 5.6545 to 5.6151\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1072.9651 to 1029.7297\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [17:55<2:41:11, 214.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 5.3117 | Train_Accuracy : 0.1202 | Train Perplexity : 777.3714\n",
            "Valid Loss : 5.3553 | Valid_Accuracy : 0.1103 | Valid Perplexity : 790.0454\n",
            "Valid Loss improved from 5.6151 to 5.3553\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1029.7297 to 790.0454\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [21:30<2:37:37, 214.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 5.1664 | Train_Accuracy : 0.1318 | Train Perplexity : 649.5478\n",
            "Valid Loss : 5.2024 | Valid_Accuracy : 0.1176 | Valid Perplexity : 657.3550\n",
            "Valid Loss improved from 5.3553 to 5.2024\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 790.0454 to 657.3550\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [25:04<2:34:00, 214.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 5.0475 | Train_Accuracy : 0.1391 | Train Perplexity : 559.4276\n",
            "Valid Loss : 5.0893 | Valid_Accuracy : 0.1293 | Valid Perplexity : 574.8038\n",
            "Valid Loss improved from 5.2024 to 5.0893\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 657.3550 to 574.8038\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [28:39<2:30:22, 214.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 5.0230 | Train_Accuracy : 0.1400 | Train Perplexity : 540.6968\n",
            "Valid Loss : 5.0564 | Valid_Accuracy : 0.1304 | Valid Perplexity : 555.6623\n",
            "Valid Loss improved from 5.0893 to 5.0564\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 574.8038 to 555.6623\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [32:14<2:26:45, 214.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 4.9317 | Train_Accuracy : 0.1452 | Train Perplexity : 488.7328\n",
            "Valid Loss : 4.9961 | Valid_Accuracy : 0.1327 | Valid Perplexity : 527.6358\n",
            "Valid Loss improved from 5.0564 to 4.9961\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 555.6623 to 527.6358\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [35:49<2:23:10, 214.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 4.8244 | Train_Accuracy : 0.1510 | Train Perplexity : 427.1977\n",
            "Valid Loss : 4.8966 | Valid_Accuracy : 0.1389 | Valid Perplexity : 465.8652\n",
            "Valid Loss improved from 4.9961 to 4.8966\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 527.6358 to 465.8652\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [39:23<2:19:36, 214.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 4.6916 | Train_Accuracy : 0.1576 | Train Perplexity : 366.2243\n",
            "Valid Loss : 4.8025 | Valid_Accuracy : 0.1417 | Valid Perplexity : 422.2840\n",
            "Valid Loss improved from 4.8966 to 4.8025\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 465.8652 to 422.2840\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [42:58<2:16:00, 214.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [46:31<2:12:10, 214.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 13 / 50\n",
            "Train Loss : 4.7170 | Train_Accuracy : 0.1558 | Train Perplexity : 370.9054\n",
            "Valid Loss : 4.8468 | Valid_Accuracy : 0.1386 | Valid Perplexity : 444.0011\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 4.6378 | Train_Accuracy : 0.1621 | Train Perplexity : 335.3563\n",
            "Valid Loss : 4.7951 | Valid_Accuracy : 0.1477 | Valid Perplexity : 415.5489\n",
            "Valid Loss improved from 4.8025 to 4.7951\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 422.2840 to 415.5489\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [50:06<2:08:37, 214.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 15 / 50\n",
            "Train Loss : 4.5696 | Train_Accuracy : 0.1665 | Train Perplexity : 306.8394\n",
            "Valid Loss : 4.7290 | Valid_Accuracy : 0.1548 | Valid Perplexity : 384.4150\n",
            "Valid Loss improved from 4.7951 to 4.7290\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 415.5489 to 384.4150\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [53:40<2:05:05, 214.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 4.4576 | Train_Accuracy : 0.1757 | Train Perplexity : 266.4701\n",
            "Valid Loss : 4.6237 | Valid_Accuracy : 0.1624 | Valid Perplexity : 340.3393\n",
            "Valid Loss improved from 4.7290 to 4.6237\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 384.4150 to 340.3393\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [57:15<2:01:33, 214.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 17 / 50\n",
            "Train Loss : 4.3940 | Train_Accuracy : 0.1800 | Train Perplexity : 246.0953\n",
            "Valid Loss : 4.5904 | Valid_Accuracy : 0.1647 | Valid Perplexity : 327.9896\n",
            "Valid Loss improved from 4.6237 to 4.5904\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 340.3393 to 327.9896\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [1:00:50<1:57:58, 214.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 4.3593 | Train_Accuracy : 0.1813 | Train Perplexity : 233.9409\n",
            "Valid Loss : 4.5802 | Valid_Accuracy : 0.1706 | Valid Perplexity : 323.0529\n",
            "Valid Loss improved from 4.5904 to 4.5802\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 327.9896 to 323.0529\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [1:04:24<1:54:25, 214.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [1:07:58<1:50:43, 214.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 19 / 50\n",
            "Train Loss : 4.3566 | Train_Accuracy : 0.1815 | Train Perplexity : 230.8459\n",
            "Valid Loss : 4.6039 | Valid_Accuracy : 0.1658 | Valid Perplexity : 334.7443\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 4.2461 | Train_Accuracy : 0.1910 | Train Perplexity : 200.6279\n",
            "Valid Loss : 4.5153 | Valid_Accuracy : 0.1755 | Valid Perplexity : 300.6608\n",
            "Valid Loss improved from 4.5802 to 4.5153\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 323.0529 to 300.6608\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:11:33<1:47:13, 214.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 4.2192 | Train_Accuracy : 0.1936 | Train Perplexity : 191.4140\n",
            "Valid Loss : 4.5195 | Valid_Accuracy : 0.1766 | Valid Perplexity : 298.6793\n",
            "Valid Perplexity improved from 300.6608 to 298.6793\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:15:07<1:43:35, 214.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 22 / 50\n",
            "Train Loss : 4.1689 | Train_Accuracy : 0.1982 | Train Perplexity : 178.6875\n",
            "Valid Loss : 4.4796 | Valid_Accuracy : 0.1820 | Valid Perplexity : 287.2646\n",
            "Valid Loss improved from 4.5153 to 4.4796\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 298.6793 to 287.2646\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:18:41<1:40:04, 214.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 23 / 50\n",
            "Train Loss : 4.1054 | Train_Accuracy : 0.2020 | Train Perplexity : 163.7624\n",
            "Valid Loss : 4.4604 | Valid_Accuracy : 0.1823 | Valid Perplexity : 281.1385\n",
            "Valid Loss improved from 4.4796 to 4.4604\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 287.2646 to 281.1385\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:22:16<1:36:31, 214.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:25:50<1:32:48, 214.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 24 / 50\n",
            "Train Loss : 4.1090 | Train_Accuracy : 0.2028 | Train Perplexity : 162.7420\n",
            "Valid Loss : 4.4727 | Valid_Accuracy : 0.1854 | Valid Perplexity : 282.6656\n",
            "Epoch : 25 / 50\n",
            "Train Loss : 4.0223 | Train_Accuracy : 0.2091 | Train Perplexity : 145.0015\n",
            "Valid Loss : 4.4107 | Valid_Accuracy : 0.1891 | Valid Perplexity : 263.8861\n",
            "Valid Loss improved from 4.4604 to 4.4107\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 281.1385 to 263.8861\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:29:24<1:29:18, 214.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 26 / 50\n",
            "Train Loss : 3.9818 | Train_Accuracy : 0.2143 | Train Perplexity : 136.4013\n",
            "Valid Loss : 4.3889 | Valid_Accuracy : 0.1922 | Valid Perplexity : 258.5416\n",
            "Valid Loss improved from 4.4107 to 4.3889\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 263.8861 to 258.5416\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:32:59<1:25:47, 214.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:36:32<1:22:05, 214.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 3.9736 | Train_Accuracy : 0.2155 | Train Perplexity : 133.6914\n",
            "Valid Loss : 4.4041 | Valid_Accuracy : 0.1876 | Valid Perplexity : 261.7279\n",
            "Epoch : 28 / 50\n",
            "Train Loss : 3.9131 | Train_Accuracy : 0.2225 | Train Perplexity : 123.0856\n",
            "Valid Loss : 4.3608 | Valid_Accuracy : 0.1908 | Valid Perplexity : 249.0883\n",
            "Valid Loss improved from 4.3889 to 4.3608\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 258.5416 to 249.0883\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:40:07<1:18:37, 214.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:43:41<1:14:57, 214.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 29 / 50\n",
            "Train Loss : 3.9105 | Train_Accuracy : 0.2227 | Train Perplexity : 121.4890\n",
            "Valid Loss : 4.3783 | Valid_Accuracy : 0.1947 | Valid Perplexity : 254.1738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:47:14<1:11:18, 213.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 30 / 50\n",
            "Train Loss : 3.8925 | Train_Accuracy : 0.2248 | Train Perplexity : 117.7013\n",
            "Valid Loss : 4.3803 | Valid_Accuracy : 0.1840 | Valid Perplexity : 256.0440\n",
            "Epoch : 31 / 50\n",
            "Train Loss : 3.8247 | Train_Accuracy : 0.2318 | Train Perplexity : 107.3708\n",
            "Valid Loss : 4.3152 | Valid_Accuracy : 0.1896 | Valid Perplexity : 236.5394\n",
            "Valid Loss improved from 4.3608 to 4.3152\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 249.0883 to 236.5394\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:50:49<1:07:48, 214.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 32 / 50\n",
            "Train Loss : 3.8119 | Train_Accuracy : 0.2346 | Train Perplexity : 104.7896\n",
            "Valid Loss : 4.3030 | Valid_Accuracy : 0.1973 | Valid Perplexity : 231.8118\n",
            "Valid Loss improved from 4.3152 to 4.3030\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 236.5394 to 231.8118\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:54:24<1:04:16, 214.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 33 / 50\n",
            "Train Loss : 3.7729 | Train_Accuracy : 0.2387 | Train Perplexity : 99.3676\n",
            "Valid Loss : 4.2904 | Valid_Accuracy : 0.1953 | Valid Perplexity : 228.9942\n",
            "Valid Loss improved from 4.3030 to 4.2904\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 231.8118 to 228.9942\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:57:58<1:00:42, 214.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 34 / 50\n",
            "Train Loss : 3.7423 | Train_Accuracy : 0.2430 | Train Perplexity : 94.9790\n",
            "Valid Loss : 4.2720 | Valid_Accuracy : 0.1967 | Valid Perplexity : 223.9289\n",
            "Valid Loss improved from 4.2904 to 4.2720\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 228.9942 to 223.9289\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [2:01:33<57:10, 214.43s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 35 / 50\n",
            "Train Loss : 3.7185 | Train_Accuracy : 0.2456 | Train Perplexity : 91.6033\n",
            "Valid Loss : 4.2645 | Valid_Accuracy : 0.1981 | Valid Perplexity : 222.3976\n",
            "Valid Loss improved from 4.2720 to 4.2645\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 223.9289 to 222.3976\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [2:05:09<53:42, 214.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 36 / 50\n",
            "Train Loss : 3.7060 | Train_Accuracy : 0.2479 | Train Perplexity : 89.5233\n",
            "Valid Loss : 4.2515 | Valid_Accuracy : 0.1981 | Valid Perplexity : 217.7282\n",
            "Valid Loss improved from 4.2645 to 4.2515\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 222.3976 to 217.7282\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [2:08:44<50:10, 215.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 37 / 50\n",
            "Train Loss : 3.6845 | Train_Accuracy : 0.2503 | Train Perplexity : 86.7267\n",
            "Valid Loss : 4.2485 | Valid_Accuracy : 0.2001 | Valid Perplexity : 217.5376\n",
            "Valid Loss improved from 4.2515 to 4.2485\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 217.7282 to 217.5376\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [2:12:19<46:37, 215.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 38 / 50\n",
            "Train Loss : 3.6629 | Train_Accuracy : 0.2533 | Train Perplexity : 84.0840\n",
            "Valid Loss : 4.2308 | Valid_Accuracy : 0.1964 | Valid Perplexity : 212.8999\n",
            "Valid Loss improved from 4.2485 to 4.2308\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 217.5376 to 212.8999\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [2:15:55<43:02, 215.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 39 / 50\n",
            "Train Loss : 3.6504 | Train_Accuracy : 0.2552 | Train Perplexity : 82.4157\n",
            "Valid Loss : 4.2321 | Valid_Accuracy : 0.1984 | Valid Perplexity : 212.8657\n",
            "Valid Perplexity improved from 212.8999 to 212.8657\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [2:19:30<39:26, 215.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 40 / 50\n",
            "Train Loss : 3.6373 | Train_Accuracy : 0.2570 | Train Perplexity : 80.7265\n",
            "Valid Loss : 4.2266 | Valid_Accuracy : 0.1995 | Valid Perplexity : 211.6936\n",
            "Valid Loss improved from 4.2308 to 4.2266\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 212.8657 to 211.6936\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [2:23:05<35:50, 215.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 41 / 50\n",
            "Train Loss : 3.6310 | Train_Accuracy : 0.2583 | Train Perplexity : 79.8841\n",
            "Valid Loss : 4.2203 | Valid_Accuracy : 0.1995 | Valid Perplexity : 209.7972\n",
            "Valid Loss improved from 4.2266 to 4.2203\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 211.6936 to 209.7972\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [2:26:39<32:14, 214.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 42 / 50\n",
            "Train Loss : 3.6207 | Train_Accuracy : 0.2599 | Train Perplexity : 78.4118\n",
            "Valid Loss : 4.2140 | Valid_Accuracy : 0.2007 | Valid Perplexity : 208.5972\n",
            "Valid Loss improved from 4.2203 to 4.2140\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 209.7972 to 208.5972\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [2:30:14<28:38, 214.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 43 / 50\n",
            "Train Loss : 3.6115 | Train_Accuracy : 0.2609 | Train Perplexity : 77.4473\n",
            "Valid Loss : 4.2122 | Valid_Accuracy : 0.2001 | Valid Perplexity : 208.1870\n",
            "Valid Loss improved from 4.2140 to 4.2122\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 208.5972 to 208.1870\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [2:33:48<25:02, 214.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 44 / 50\n",
            "Train Loss : 3.6074 | Train_Accuracy : 0.2618 | Train Perplexity : 76.7123\n",
            "Valid Loss : 4.2093 | Valid_Accuracy : 0.1993 | Valid Perplexity : 207.0197\n",
            "Valid Loss improved from 4.2122 to 4.2093\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 208.1870 to 207.0197\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [2:37:23<21:27, 214.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 45 / 50\n",
            "Train Loss : 3.5960 | Train_Accuracy : 0.2633 | Train Perplexity : 75.4037\n",
            "Valid Loss : 4.2073 | Valid_Accuracy : 0.2018 | Valid Perplexity : 206.6700\n",
            "Valid Loss improved from 4.2093 to 4.2073\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 207.0197 to 206.6700\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [2:40:57<17:53, 214.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 46 / 50\n",
            "Train Loss : 3.5901 | Train_Accuracy : 0.2639 | Train Perplexity : 74.6618\n",
            "Valid Loss : 4.2017 | Valid_Accuracy : 0.2018 | Valid Perplexity : 204.8114\n",
            "Valid Loss improved from 4.2073 to 4.2017\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 206.6700 to 204.8114\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [2:44:32<14:18, 214.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [2:48:06<10:43, 214.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 47 / 50\n",
            "Train Loss : 3.5849 | Train_Accuracy : 0.2649 | Train Perplexity : 74.1090\n",
            "Valid Loss : 4.2026 | Valid_Accuracy : 0.2012 | Valid Perplexity : 205.3616\n",
            "Epoch : 48 / 50\n",
            "Train Loss : 3.5768 | Train_Accuracy : 0.2663 | Train Perplexity : 72.9393\n",
            "Valid Loss : 4.2005 | Valid_Accuracy : 0.2010 | Valid Perplexity : 205.0783\n",
            "Valid Loss improved from 4.2017 to 4.2005\n",
            "Save the loss Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [2:51:40<07:08, 214.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 49 / 50\n",
            "Train Loss : 3.5660 | Train_Accuracy : 0.2676 | Train Perplexity : 71.8623\n",
            "Valid Loss : 4.1959 | Valid_Accuracy : 0.2044 | Valid Perplexity : 203.8968\n",
            "Valid Loss improved from 4.2005 to 4.1959\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 204.8114 to 203.8968\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [2:55:15<03:34, 214.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 50 / 50\n",
            "Train Loss : 3.5638 | Train_Accuracy : 0.2684 | Train Perplexity : 71.5161\n",
            "Valid Loss : 4.1950 | Valid_Accuracy : 0.2021 | Valid Perplexity : 203.5941\n",
            "Valid Loss improved from 4.1959 to 4.1950\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 203.8968 to 203.5941\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [2:58:50<00:00, 214.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "best_loss_epoch : 50\n",
            "best_ppl_epoch : 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 13\n",
        "\n",
        "MSE - last layer & JS and Cos - logits\n",
        "\n",
        "PPL : 264.7178\n",
        "\n",
        "Best Epoch : 23"
      ],
      "metadata": {
        "id": "76pDVPks7Ig2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def JS_divergence(student_logits, teacher_logits, temperature, mask=None): # logits에 적용\n",
        "  T = temperature\n",
        "  eps=1e-9\n",
        "  student_prob = F.softmax(student_logits / temperature, dim=-1)\n",
        "  teacher_prob = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "  M = 0.5 * (student_prob + teacher_prob)\n",
        "  M_log = torch.log(M + eps)\n",
        "  student_log = torch.log(student_prob + eps)\n",
        "  teacher_log = torch.log(teacher_prob + eps)\n",
        "\n",
        "  D_p = (teacher_prob * (teacher_log - M_log)).sum(dim=-1)\n",
        "  D_q = (student_prob * (student_log - M_log)).sum(dim=-1)\n",
        "\n",
        "  JS = 0.5 * (D_p + D_q)\n",
        "  if mask is not None:\n",
        "    JS = JS * mask\n",
        "    return (JS.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return JS.mean() * (T**2)\n",
        "\n",
        "def logit_cosine_similarity(s_logit, t_logit, mask=None):\n",
        "  eps = 1e-9\n",
        "  norm_x = torch.sqrt((s_logit * s_logit).sum(dim=-1) + eps)\n",
        "  norm_y = torch.sqrt((t_logit * t_logit).sum(dim=-1) + eps)\n",
        "  dot = (s_logit * t_logit).sum(dim=-1)\n",
        "  cos_sim = dot / (norm_x * norm_y)\n",
        "  cos_sim = 1 - cos_sim\n",
        "  if mask is not None:\n",
        "    cos_sim = cos_sim * mask\n",
        "    return cos_sim.sum() / mask.sum()\n",
        "  else:\n",
        "    return cos_sim.mean() # (B,)\n",
        "\n",
        "class KD_Loss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.A = alpha\n",
        "    self.ignore_index = ignore_index\n",
        "    self.label_smoothing = label_smoothing\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    JS_Loss = JS_divergence(student_logits, teacher_logits, self.T, mask)\n",
        "    CE_Loss = F.cross_entropy(student_logits, labels, ignore_index=self.ignore_index, label_smoothing=self.label_smoothing)\n",
        "    total_Loss = self.A * JS_Loss + (1 - self.A) * CE_Loss\n",
        "    return total_Loss\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def MSE(s_attn, t_attn):\n",
        "  last_t_attn = t_attn[-1]\n",
        "  last_s_attn = s_attn[-1]\n",
        "  loss = ((average_head(last_s_attn) - average_head(last_t_attn)) ** 2).mean()\n",
        "  return loss\n",
        "\n",
        "\n",
        "class MSE_Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, s_attn, t_attn):\n",
        "    loss = MSE(s_attn, t_attn)\n",
        "    return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, beta, gamma, label_smoothing=0.1 ,ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.B = beta\n",
        "    self.G = gamma\n",
        "    self.ignore_index = ignore_index\n",
        "    self.kd_loss = KD_Loss(temperature, alpha, label_smoothing, ignore_index=ignore_index)\n",
        "    self.mse = MSE_Loss()\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits, s_attn, t_attn):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    kd_l = self.kd_loss(student_logits, labels, teacher_logits)\n",
        "    mse_l = self.mse(s_attn, t_attn)\n",
        "    cos_logits = logit_cosine_similarity(student_logits, teacher_logits, mask)\n",
        "    total_loss = kd_l + self.B * mse_l + self.G * cos_logits\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "Q5dGjOZ1QUBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Toklenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ],
      "metadata": {
        "id": "u-NFx7rGQT9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad632f6c-8e2c-4ffd-a502-bf4ec09db981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting loss funciton, optimizer, and scheduler\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# alpha : JS & CE(1-alpha), beta : MSE, gamma : cos for logits\n",
        "loss_function = TotalLoss(temperature=2.0, alpha=0.5, beta=0.05, gamma=0.05)\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "8HLjRPrzQT5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ],
      "metadata": {
        "id": "3ZqXED4RQTy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ],
      "metadata": {
        "id": "FY9i0uttQTVN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557a8be0-bf7e-445f-a04d-c250cef59f30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 4.4310 | Train_Accuracy : 0.0507 | Train Perplexity : 1968.8778\n",
            "Valid Loss : 4.4148 | Valid_Accuracy : 0.0400 | Valid Perplexity : 1880.5205\n",
            "Valid Loss improved from inf to 4.4148\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1880.5205\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [04:17<3:30:30, 257.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 4.2725 | Train_Accuracy : 0.0952 | Train Perplexity : 1416.2115\n",
            "Valid Loss : 4.2718 | Valid_Accuracy : 0.0859 | Valid Perplexity : 1399.5374\n",
            "Valid Loss improved from 4.4148 to 4.2718\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1880.5205 to 1399.5374\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [08:34<3:25:55, 257.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 4.1667 | Train_Accuracy : 0.1076 | Train Perplexity : 1142.6216\n",
            "Valid Loss : 4.1755 | Valid_Accuracy : 0.0975 | Valid Perplexity : 1149.6460\n",
            "Valid Loss improved from 4.2718 to 4.1755\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1399.5374 to 1149.6460\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [12:52<3:21:31, 257.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 4.0599 | Train_Accuracy : 0.1201 | Train Perplexity : 908.5303\n",
            "Valid Loss : 4.0853 | Valid_Accuracy : 0.1139 | Valid Perplexity : 946.4880\n",
            "Valid Loss improved from 4.1755 to 4.0853\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1149.6460 to 946.4880\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [17:09<3:17:13, 257.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 3.9185 | Train_Accuracy : 0.1364 | Train Perplexity : 682.3300\n",
            "Valid Loss : 3.9389 | Valid_Accuracy : 0.1250 | Valid Perplexity : 707.1026\n",
            "Valid Loss improved from 4.0853 to 3.9389\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 946.4880 to 707.1026\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [21:26<3:12:58, 257.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 3.8615 | Train_Accuracy : 0.1422 | Train Perplexity : 604.4179\n",
            "Valid Loss : 3.8783 | Valid_Accuracy : 0.1295 | Valid Perplexity : 623.1356\n",
            "Valid Loss improved from 3.9389 to 3.8783\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 707.1026 to 623.1356\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [25:44<3:08:46, 257.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 3.8001 | Train_Accuracy : 0.1406 | Train Perplexity : 539.3096\n",
            "Valid Loss : 3.8642 | Valid_Accuracy : 0.1278 | Valid Perplexity : 617.6869\n",
            "Valid Loss improved from 3.8783 to 3.8642\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 623.1356 to 617.6869\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [30:01<3:04:25, 257.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 3.7046 | Train_Accuracy : 0.1560 | Train Perplexity : 435.5143\n",
            "Valid Loss : 3.7647 | Valid_Accuracy : 0.1460 | Valid Perplexity : 493.2935\n",
            "Valid Loss improved from 3.8642 to 3.7647\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 617.6869 to 493.2935\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [34:18<3:00:05, 257.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 3.6480 | Train_Accuracy : 0.1624 | Train Perplexity : 387.7456\n",
            "Valid Loss : 3.7329 | Valid_Accuracy : 0.1539 | Valid Perplexity : 464.0551\n",
            "Valid Loss improved from 3.7647 to 3.7329\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 493.2935 to 464.0551\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [38:35<2:55:44, 257.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 3.5546 | Train_Accuracy : 0.1723 | Train Perplexity : 318.0488\n",
            "Valid Loss : 3.6697 | Valid_Accuracy : 0.1627 | Valid Perplexity : 407.1443\n",
            "Valid Loss improved from 3.7329 to 3.6697\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 464.0551 to 407.1443\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [42:52<2:51:28, 257.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 3.4988 | Train_Accuracy : 0.1781 | Train Perplexity : 282.2716\n",
            "Valid Loss : 3.6288 | Valid_Accuracy : 0.1630 | Valid Perplexity : 373.9239\n",
            "Valid Loss improved from 3.6697 to 3.6288\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 407.1443 to 373.9239\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [47:10<2:47:11, 257.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 3.4482 | Train_Accuracy : 0.1811 | Train Perplexity : 254.0922\n",
            "Valid Loss : 3.6201 | Valid_Accuracy : 0.1681 | Valid Perplexity : 368.2544\n",
            "Valid Loss improved from 3.6288 to 3.6201\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 373.9239 to 368.2544\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [51:27<2:42:54, 257.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 3.4012 | Train_Accuracy : 0.1896 | Train Perplexity : 229.2889\n",
            "Valid Loss : 3.5836 | Valid_Accuracy : 0.1752 | Valid Perplexity : 340.4444\n",
            "Valid Loss improved from 3.6201 to 3.5836\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 368.2544 to 340.4444\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [55:44<2:38:38, 257.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 3.3668 | Train_Accuracy : 0.1938 | Train Perplexity : 209.9624\n",
            "Valid Loss : 3.5782 | Valid_Accuracy : 0.1791 | Valid Perplexity : 332.1273\n",
            "Valid Loss improved from 3.5836 to 3.5782\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 340.4444 to 332.1273\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [1:00:02<2:34:23, 257.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [1:04:18<2:29:53, 256.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 15 / 50\n",
            "Train Loss : 3.3294 | Train_Accuracy : 0.1965 | Train Perplexity : 195.9083\n",
            "Valid Loss : 3.5816 | Valid_Accuracy : 0.1817 | Valid Perplexity : 339.9201\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 3.2477 | Train_Accuracy : 0.2077 | Train Perplexity : 162.6785\n",
            "Valid Loss : 3.5358 | Valid_Accuracy : 0.1842 | Valid Perplexity : 305.0002\n",
            "Valid Loss improved from 3.5782 to 3.5358\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 332.1273 to 305.0002\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [1:08:35<2:25:36, 256.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 17 / 50\n",
            "Train Loss : 3.2266 | Train_Accuracy : 0.2109 | Train Perplexity : 153.6838\n",
            "Valid Loss : 3.5405 | Valid_Accuracy : 0.1905 | Valid Perplexity : 304.9370\n",
            "Valid Perplexity improved from 305.0002 to 304.9370\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [1:12:52<2:21:18, 256.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 3.1571 | Train_Accuracy : 0.2211 | Train Perplexity : 132.7341\n",
            "Valid Loss : 3.5156 | Valid_Accuracy : 0.1905 | Valid Perplexity : 290.6184\n",
            "Valid Loss improved from 3.5358 to 3.5156\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 304.9370 to 290.6184\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [1:17:08<2:17:01, 256.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [1:21:24<2:12:34, 256.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 19 / 50\n",
            "Train Loss : 3.1224 | Train_Accuracy : 0.2242 | Train Perplexity : 122.4361\n",
            "Valid Loss : 3.5288 | Valid_Accuracy : 0.1947 | Valid Perplexity : 298.1645\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 3.0644 | Train_Accuracy : 0.2363 | Train Perplexity : 107.4795\n",
            "Valid Loss : 3.5036 | Valid_Accuracy : 0.1961 | Valid Perplexity : 282.1827\n",
            "Valid Loss improved from 3.5156 to 3.5036\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 290.6184 to 282.1827\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:25:41<2:08:20, 256.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 3.0174 | Train_Accuracy : 0.2439 | Train Perplexity : 96.3837\n",
            "Valid Loss : 3.4967 | Valid_Accuracy : 0.1959 | Valid Perplexity : 275.9998\n",
            "Valid Loss improved from 3.5036 to 3.4967\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 282.1827 to 275.9998\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:29:58<2:04:07, 256.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:34:15<1:59:45, 256.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 22 / 50\n",
            "Train Loss : 2.9792 | Train_Accuracy : 0.2524 | Train Perplexity : 87.8573\n",
            "Valid Loss : 3.5013 | Valid_Accuracy : 0.1984 | Valid Perplexity : 276.0351\n",
            "Epoch : 23 / 50\n",
            "Train Loss : 2.9292 | Train_Accuracy : 0.2614 | Train Perplexity : 78.7118\n",
            "Valid Loss : 3.4801 | Valid_Accuracy : 0.1981 | Valid Perplexity : 264.7178\n",
            "Valid Loss improved from 3.4967 to 3.4801\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 275.9998 to 264.7178\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:38:32<1:55:34, 256.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:42:48<1:51:15, 256.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 24 / 50\n",
            "Train Loss : 2.8902 | Train_Accuracy : 0.2697 | Train Perplexity : 72.5041\n",
            "Valid Loss : 3.4898 | Valid_Accuracy : 0.1993 | Valid Perplexity : 270.8691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:47:04<1:46:53, 256.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 25 / 50\n",
            "Train Loss : 2.8653 | Train_Accuracy : 0.2752 | Train Perplexity : 67.4307\n",
            "Valid Loss : 3.5060 | Valid_Accuracy : 0.2001 | Valid Perplexity : 276.4807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:51:20<1:42:33, 256.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 26 / 50\n",
            "Train Loss : 2.8337 | Train_Accuracy : 0.2827 | Train Perplexity : 63.1165\n",
            "Valid Loss : 3.5183 | Valid_Accuracy : 0.1981 | Valid Perplexity : 285.4101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:55:37<1:38:14, 256.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 2.7881 | Train_Accuracy : 0.2942 | Train Perplexity : 56.6277\n",
            "Valid Loss : 3.5061 | Valid_Accuracy : 0.1964 | Valid Perplexity : 275.8194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:59:52<1:33:56, 256.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 28 / 50\n",
            "Train Loss : 2.7496 | Train_Accuracy : 0.3035 | Train Perplexity : 51.8134\n",
            "Valid Loss : 3.5104 | Valid_Accuracy : 0.1956 | Valid Perplexity : 277.5678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [2:04:08<1:37:32, 266.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 29 / 50\n",
            "Train Loss : 2.7225 | Train_Accuracy : 0.3105 | Train Perplexity : 48.5602\n",
            "Valid Loss : 3.5230 | Valid_Accuracy : 0.1973 | Valid Perplexity : 283.7224\n",
            "best_loss_epoch : 23\n",
            "best_ppl_epoch : 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 14\n",
        "\n",
        "MSE - last layer(custom) & KL and Cos - logits\n",
        "\n",
        "PPL : 199.9793\n",
        "\n",
        "Best Epoch : 50"
      ],
      "metadata": {
        "id": "ltspXAkf7yoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def KL_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  student_log_probs = F.log_softmax(student_logits / T, dim=-1)\n",
        "  teacher_probs = F.softmax(teacher_logits / T, dim=-1)\n",
        "  eps = 1e-8\n",
        "  KL = (teacher_probs * (torch.log(teacher_probs + eps) - student_log_probs)).sum(dim=-1)\n",
        "\n",
        "  if mask is not None:\n",
        "    KL = KL * mask\n",
        "    return (KL.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return KL.mean() * (T**2)\n",
        "\n",
        "def logit_cosine_similarity(s_logit, t_logit, mask=None):\n",
        "  eps = 1e-9\n",
        "  norm_x = torch.sqrt((s_logit * s_logit).sum(dim=-1) + eps)\n",
        "  norm_y = torch.sqrt((t_logit * t_logit).sum(dim=-1) + eps)\n",
        "  dot = (s_logit * t_logit).sum(dim=-1)\n",
        "  cos_sim = dot / (norm_x * norm_y)\n",
        "  cos_sim = 1 - cos_sim\n",
        "  if mask is not None:\n",
        "    cos_sim = cos_sim * mask\n",
        "    return cos_sim.sum() / mask.sum()\n",
        "  else:\n",
        "    return cos_sim.mean() # (B,)\n",
        "\n",
        "class KD_Loss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.A = alpha\n",
        "    self.ignore_index = ignore_index\n",
        "    self.label_smoothing = label_smoothing\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    KL_Loss = KL_divergence(student_logits, teacher_logits, self.T, mask)\n",
        "    CE_Loss = F.cross_entropy(student_logits, labels, ignore_index=self.ignore_index, label_smoothing=self.label_smoothing)\n",
        "    total_Loss = self.A * KL_Loss + (1 - self.A) * CE_Loss\n",
        "    return total_Loss\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def MSE(s_attn, t_attn):\n",
        "  last_t_attn = average_head(t_attn[-1])  # [batch, seq_len, seq_len]\n",
        "\n",
        "  loss = torch.zeros((), device=last_t_attn.device, dtype=last_t_attn.dtype)\n",
        "\n",
        "  for attn in s_attn:\n",
        "      attn = average_head(attn)  # [batch, seq_len, seq_len]\n",
        "      loss = loss + ((attn - last_t_attn) ** 2).mean()\n",
        "\n",
        "  loss /= len(s_attn)\n",
        "  return loss\n",
        "\n",
        "class MSE_Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, s_attn, t_attn):\n",
        "    loss = MSE(s_attn, t_attn)\n",
        "    return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, beta, gamma, label_smoothing=0.1 ,ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.B = beta\n",
        "    self.G = gamma\n",
        "    self.ignore_index = ignore_index\n",
        "    self.kd_loss = KD_Loss(temperature, alpha, label_smoothing, ignore_index=ignore_index)\n",
        "    self.mse = MSE_Loss()\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits, s_attn, t_attn):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    kd_l = self.kd_loss(student_logits, labels, teacher_logits)\n",
        "    mse_l = self.mse(s_attn, t_attn)\n",
        "    cos_for_logits = logit_cosine_similarity(student_logits, teacher_logits, mask)\n",
        "    total_loss = kd_l + self.B * mse_l + self.G * cos_for_logits\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "SD0Kuu0JRanB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ],
      "metadata": {
        "id": "GZ4rfawzRajJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1cdffb6-f39b-4f2e-9007-22e89bcae810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting loss function, optimizer, and scheduler\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# alpha : KL & CE(1-alpha), beta : MSE, gamma : cos for logits\n",
        "loss_function = TotalLoss(temperature=2.0, alpha=0.5, beta=0.05, gamma=0.05)\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "nPGxOHnXRaf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ],
      "metadata": {
        "id": "_z1ykQmeRabQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ],
      "metadata": {
        "id": "g1Uqr3uhRaRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d1bec2-7a81-4b0c-9100-5c14088e83bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 6.2539 | Train_Accuracy : 0.0504 | Train Perplexity : 2062.3988\n",
            "Valid Loss : 6.2576 | Valid_Accuracy : 0.0422 | Valid Perplexity : 1925.8022\n",
            "Valid Loss improved from inf to 6.2576\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1925.8022\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [03:35<2:56:22, 215.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 6.2436 | Train_Accuracy : 0.0584 | Train Perplexity : 2023.8495\n",
            "Valid Loss : 6.2535 | Valid_Accuracy : 0.0476 | Valid Perplexity : 1902.8581\n",
            "Valid Loss improved from 6.2576 to 6.2535\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1925.8022 to 1902.8581\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [07:11<2:52:29, 215.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 5.8913 | Train_Accuracy : 0.0877 | Train Perplexity : 1456.0374\n",
            "Valid Loss : 5.9167 | Valid_Accuracy : 0.0828 | Valid Perplexity : 1407.0178\n",
            "Valid Loss improved from 6.2535 to 5.9167\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1902.8581 to 1407.0178\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [10:47<2:48:55, 215.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 5.6788 | Train_Accuracy : 0.1019 | Train Perplexity : 1176.2928\n",
            "Valid Loss : 5.7415 | Valid_Accuracy : 0.0947 | Valid Perplexity : 1187.5958\n",
            "Valid Loss improved from 5.9167 to 5.7415\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1407.0178 to 1187.5958\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [14:22<2:45:20, 215.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 5.4677 | Train_Accuracy : 0.1132 | Train Perplexity : 932.5963\n",
            "Valid Loss : 5.5192 | Valid_Accuracy : 0.1035 | Valid Perplexity : 947.6026\n",
            "Valid Loss improved from 5.7415 to 5.5192\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1187.5958 to 947.6026\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [17:58<2:41:51, 215.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 5.4330 | Train_Accuracy : 0.1174 | Train Perplexity : 885.4295\n",
            "Valid Loss : 5.4898 | Valid_Accuracy : 0.1063 | Valid Perplexity : 907.6231\n",
            "Valid Loss improved from 5.5192 to 5.4898\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 947.6026 to 907.6231\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [21:34<2:38:13, 215.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 5.2836 | Train_Accuracy : 0.1274 | Train Perplexity : 721.1070\n",
            "Valid Loss : 5.3013 | Valid_Accuracy : 0.1139 | Valid Perplexity : 716.2929\n",
            "Valid Loss improved from 5.4898 to 5.3013\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 907.6231 to 716.2929\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [25:10<2:34:35, 215.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 5.1377 | Train_Accuracy : 0.1310 | Train Perplexity : 622.4359\n",
            "Valid Loss : 5.1790 | Valid_Accuracy : 0.1185 | Valid Perplexity : 635.7608\n",
            "Valid Loss improved from 5.3013 to 5.1790\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 716.2929 to 635.7608\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [28:45<2:30:55, 215.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 4.9906 | Train_Accuracy : 0.1371 | Train Perplexity : 525.5603\n",
            "Valid Loss : 5.0376 | Valid_Accuracy : 0.1250 | Valid Perplexity : 547.0343\n",
            "Valid Loss improved from 5.1790 to 5.0376\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 635.7608 to 547.0343\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [32:21<2:27:19, 215.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 4.9368 | Train_Accuracy : 0.1428 | Train Perplexity : 489.0013\n",
            "Valid Loss : 4.9753 | Valid_Accuracy : 0.1312 | Valid Perplexity : 511.2250\n",
            "Valid Loss improved from 5.0376 to 4.9753\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 547.0343 to 511.2250\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [35:57<2:23:50, 215.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 4.8164 | Train_Accuracy : 0.1511 | Train Perplexity : 423.3095\n",
            "Valid Loss : 4.8867 | Valid_Accuracy : 0.1363 | Valid Perplexity : 456.5251\n",
            "Valid Loss improved from 4.9753 to 4.8867\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 511.2250 to 456.5251\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [39:32<2:20:10, 215.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 4.7389 | Train_Accuracy : 0.1544 | Train Perplexity : 386.3839\n",
            "Valid Loss : 4.8417 | Valid_Accuracy : 0.1437 | Valid Perplexity : 438.3726\n",
            "Valid Loss improved from 4.8867 to 4.8417\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 456.5251 to 438.3726\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [43:08<2:16:33, 215.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 4.6453 | Train_Accuracy : 0.1623 | Train Perplexity : 343.2510\n",
            "Valid Loss : 4.7527 | Valid_Accuracy : 0.1474 | Valid Perplexity : 396.1048\n",
            "Valid Loss improved from 4.8417 to 4.7527\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 438.3726 to 396.1048\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [46:43<2:12:56, 215.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [50:18<2:09:11, 215.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 14 / 50\n",
            "Train Loss : 4.6408 | Train_Accuracy : 0.1604 | Train Perplexity : 338.4275\n",
            "Valid Loss : 4.7783 | Valid_Accuracy : 0.1502 | Valid Perplexity : 407.0159\n",
            "Epoch : 15 / 50\n",
            "Train Loss : 4.5688 | Train_Accuracy : 0.1664 | Train Perplexity : 308.3437\n",
            "Valid Loss : 4.7386 | Valid_Accuracy : 0.1570 | Valid Perplexity : 383.7595\n",
            "Valid Loss improved from 4.7527 to 4.7386\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 396.1048 to 383.7595\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [53:53<2:05:40, 215.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 4.4732 | Train_Accuracy : 0.1743 | Train Perplexity : 271.7341\n",
            "Valid Loss : 4.6338 | Valid_Accuracy : 0.1644 | Valid Perplexity : 343.3878\n",
            "Valid Loss improved from 4.7386 to 4.6338\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 383.7595 to 343.3878\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [57:29<2:02:06, 215.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [1:01:04<1:58:21, 215.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 17 / 50\n",
            "Train Loss : 4.4452 | Train_Accuracy : 0.1737 | Train Perplexity : 262.3395\n",
            "Valid Loss : 4.6569 | Valid_Accuracy : 0.1627 | Valid Perplexity : 355.0657\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 4.3503 | Train_Accuracy : 0.1813 | Train Perplexity : 232.0006\n",
            "Valid Loss : 4.5940 | Valid_Accuracy : 0.1670 | Valid Perplexity : 326.2833\n",
            "Valid Loss improved from 4.6338 to 4.5940\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 343.3878 to 326.2833\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [1:04:39<1:54:49, 215.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 19 / 50\n",
            "Train Loss : 4.3434 | Train_Accuracy : 0.1827 | Train Perplexity : 227.6909\n",
            "Valid Loss : 4.5815 | Valid_Accuracy : 0.1723 | Valid Perplexity : 324.6911\n",
            "Valid Loss improved from 4.5940 to 4.5815\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 326.2833 to 324.6911\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [1:08:15<1:51:17, 215.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 4.2826 | Train_Accuracy : 0.1884 | Train Perplexity : 209.3392\n",
            "Valid Loss : 4.5328 | Valid_Accuracy : 0.1752 | Valid Perplexity : 305.2834\n",
            "Valid Loss improved from 4.5815 to 4.5328\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 324.6911 to 305.2834\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:11:51<1:47:45, 215.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 4.2346 | Train_Accuracy : 0.1899 | Train Perplexity : 196.5412\n",
            "Valid Loss : 4.5296 | Valid_Accuracy : 0.1752 | Valid Perplexity : 303.3588\n",
            "Valid Loss improved from 4.5328 to 4.5296\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 305.2834 to 303.3588\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:15:26<1:44:11, 215.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 22 / 50\n",
            "Train Loss : 4.1455 | Train_Accuracy : 0.1982 | Train Perplexity : 174.4553\n",
            "Valid Loss : 4.4787 | Valid_Accuracy : 0.1794 | Valid Perplexity : 286.5525\n",
            "Valid Loss improved from 4.5296 to 4.4787\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 303.3588 to 286.5525\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:19:02<1:40:36, 215.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:22:36<1:36:51, 215.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 23 / 50\n",
            "Train Loss : 4.1676 | Train_Accuracy : 0.1964 | Train Perplexity : 177.1950\n",
            "Valid Loss : 4.5016 | Valid_Accuracy : 0.1774 | Valid Perplexity : 293.4584\n",
            "Epoch : 24 / 50\n",
            "Train Loss : 4.0949 | Train_Accuracy : 0.2040 | Train Perplexity : 160.4626\n",
            "Valid Loss : 4.4462 | Valid_Accuracy : 0.1874 | Valid Perplexity : 274.1807\n",
            "Valid Loss improved from 4.4787 to 4.4462\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 286.5525 to 274.1807\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:26:12<1:33:19, 215.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 25 / 50\n",
            "Train Loss : 4.0553 | Train_Accuracy : 0.2059 | Train Perplexity : 151.6307\n",
            "Valid Loss : 4.4343 | Valid_Accuracy : 0.1888 | Valid Perplexity : 270.3307\n",
            "Valid Loss improved from 4.4462 to 4.4343\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 274.1807 to 270.3307\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:29:48<1:29:46, 215.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 26 / 50\n",
            "Train Loss : 3.9932 | Train_Accuracy : 0.2129 | Train Perplexity : 139.3737\n",
            "Valid Loss : 4.3851 | Valid_Accuracy : 0.1902 | Valid Perplexity : 257.3668\n",
            "Valid Loss improved from 4.4343 to 4.3851\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 270.3307 to 257.3668\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:33:24<1:26:16, 215.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 27 / 50\n",
            "Train Loss : 3.9576 | Train_Accuracy : 0.2166 | Train Perplexity : 131.7537\n",
            "Valid Loss : 4.3699 | Valid_Accuracy : 0.1913 | Valid Perplexity : 252.9873\n",
            "Valid Loss improved from 4.3851 to 4.3699\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 257.3668 to 252.9873\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:36:59<1:22:40, 215.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 28 / 50\n",
            "Train Loss : 3.8979 | Train_Accuracy : 0.2233 | Train Perplexity : 121.7874\n",
            "Valid Loss : 4.3279 | Valid_Accuracy : 0.1919 | Valid Perplexity : 240.2750\n",
            "Valid Loss improved from 4.3699 to 4.3279\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 252.9873 to 240.2750\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [1:40:35<1:19:03, 215.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 29/50 [1:44:10<1:15:21, 215.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 29 / 50\n",
            "Train Loss : 3.9409 | Train_Accuracy : 0.2199 | Train Perplexity : 126.4439\n",
            "Valid Loss : 4.3781 | Valid_Accuracy : 0.1888 | Valid Perplexity : 251.7149\n",
            "Epoch : 30 / 50\n",
            "Train Loss : 3.8604 | Train_Accuracy : 0.2284 | Train Perplexity : 113.5993\n",
            "Valid Loss : 4.3276 | Valid_Accuracy : 0.1967 | Valid Perplexity : 238.4120\n",
            "Valid Loss improved from 4.3279 to 4.3276\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 240.2750 to 238.4120\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 30/50 [1:47:45<1:11:49, 215.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 31 / 50\n",
            "Train Loss : 3.8382 | Train_Accuracy : 0.2301 | Train Perplexity : 110.0042\n",
            "Valid Loss : 4.3046 | Valid_Accuracy : 0.1947 | Valid Perplexity : 231.5258\n",
            "Valid Loss improved from 4.3276 to 4.3046\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 238.4120 to 231.5258\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 31/50 [1:51:21<1:08:16, 215.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 32/50 [1:54:56<1:04:35, 215.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 32 / 50\n",
            "Train Loss : 3.8154 | Train_Accuracy : 0.2341 | Train Perplexity : 106.0563\n",
            "Valid Loss : 4.3083 | Valid_Accuracy : 0.1978 | Valid Perplexity : 232.7357\n",
            "Epoch : 33 / 50\n",
            "Train Loss : 3.7753 | Train_Accuracy : 0.2384 | Train Perplexity : 99.8323\n",
            "Valid Loss : 4.2864 | Valid_Accuracy : 0.2004 | Valid Perplexity : 226.3781\n",
            "Valid Loss improved from 4.3046 to 4.2864\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 231.5258 to 226.3781\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 33/50 [1:58:32<1:01:06, 215.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 34 / 50\n",
            "Train Loss : 3.7531 | Train_Accuracy : 0.2420 | Train Perplexity : 96.8656\n",
            "Valid Loss : 4.2686 | Valid_Accuracy : 0.2012 | Valid Perplexity : 221.6278\n",
            "Valid Loss improved from 4.2864 to 4.2686\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 226.3781 to 221.6278\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 34/50 [2:02:08<57:31, 215.73s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 35 / 50\n",
            "Train Loss : 3.7224 | Train_Accuracy : 0.2458 | Train Perplexity : 92.5623\n",
            "Valid Loss : 4.2529 | Valid_Accuracy : 0.1973 | Valid Perplexity : 217.2685\n",
            "Valid Loss improved from 4.2686 to 4.2529\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 221.6278 to 217.2685\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 35/50 [2:05:44<53:56, 215.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 36 / 50\n",
            "Train Loss : 3.7014 | Train_Accuracy : 0.2489 | Train Perplexity : 89.4473\n",
            "Valid Loss : 4.2416 | Valid_Accuracy : 0.1987 | Valid Perplexity : 214.6385\n",
            "Valid Loss improved from 4.2529 to 4.2416\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 217.2685 to 214.6385\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 36/50 [2:09:20<50:21, 215.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 37 / 50\n",
            "Train Loss : 3.6793 | Train_Accuracy : 0.2512 | Train Perplexity : 86.7875\n",
            "Valid Loss : 4.2274 | Valid_Accuracy : 0.2021 | Valid Perplexity : 211.5450\n",
            "Valid Loss improved from 4.2416 to 4.2274\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 214.6385 to 211.5450\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 37/50 [2:12:56<46:45, 215.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 38 / 50\n",
            "Train Loss : 3.6588 | Train_Accuracy : 0.2540 | Train Perplexity : 84.1641\n",
            "Valid Loss : 4.2209 | Valid_Accuracy : 0.2041 | Valid Perplexity : 209.8680\n",
            "Valid Loss improved from 4.2274 to 4.2209\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 211.5450 to 209.8680\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 38/50 [2:16:32<43:09, 215.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 39/50 [2:20:07<39:31, 215.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 39 / 50\n",
            "Train Loss : 3.6551 | Train_Accuracy : 0.2547 | Train Perplexity : 83.4248\n",
            "Valid Loss : 4.2283 | Valid_Accuracy : 0.2024 | Valid Perplexity : 211.4696\n",
            "Epoch : 40 / 50\n",
            "Train Loss : 3.6334 | Train_Accuracy : 0.2581 | Train Perplexity : 80.9202\n",
            "Valid Loss : 4.2136 | Valid_Accuracy : 0.2029 | Valid Perplexity : 207.6154\n",
            "Valid Loss improved from 4.2209 to 4.2136\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 209.8680 to 207.6154\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 40/50 [2:23:42<35:55, 215.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 41 / 50\n",
            "Train Loss : 3.6234 | Train_Accuracy : 0.2594 | Train Perplexity : 79.6432\n",
            "Valid Loss : 4.2035 | Valid_Accuracy : 0.2052 | Valid Perplexity : 205.5347\n",
            "Valid Loss improved from 4.2136 to 4.2035\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 207.6154 to 205.5347\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 41/50 [2:27:18<32:19, 215.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 42/50 [2:30:53<28:43, 215.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 42 / 50\n",
            "Train Loss : 3.6212 | Train_Accuracy : 0.2600 | Train Perplexity : 79.1560\n",
            "Valid Loss : 4.2109 | Valid_Accuracy : 0.2032 | Valid Perplexity : 206.8956\n",
            "Epoch : 43 / 50\n",
            "Train Loss : 3.6112 | Train_Accuracy : 0.2614 | Train Perplexity : 77.9644\n",
            "Valid Loss : 4.2029 | Valid_Accuracy : 0.2046 | Valid Perplexity : 205.3242\n",
            "Valid Loss improved from 4.2035 to 4.2029\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 205.5347 to 205.3242\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 43/50 [2:34:29<25:09, 215.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 44 / 50\n",
            "Train Loss : 3.6018 | Train_Accuracy : 0.2624 | Train Perplexity : 76.7950\n",
            "Valid Loss : 4.1968 | Valid_Accuracy : 0.2029 | Valid Perplexity : 203.7075\n",
            "Valid Loss improved from 4.2029 to 4.1968\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 205.3242 to 203.7075\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 44/50 [2:38:06<21:35, 215.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 45/50 [2:41:41<17:58, 215.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 45 / 50\n",
            "Train Loss : 3.5973 | Train_Accuracy : 0.2633 | Train Perplexity : 76.1426\n",
            "Valid Loss : 4.1987 | Valid_Accuracy : 0.2052 | Valid Perplexity : 204.0037\n",
            "Epoch : 46 / 50\n",
            "Train Loss : 3.5908 | Train_Accuracy : 0.2640 | Train Perplexity : 75.2477\n",
            "Valid Loss : 4.1970 | Valid_Accuracy : 0.2055 | Valid Perplexity : 203.0788\n",
            "Valid Perplexity improved from 203.7075 to 203.0788\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 46/50 [2:45:17<14:23, 215.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 47 / 50\n",
            "Train Loss : 3.5830 | Train_Accuracy : 0.2652 | Train Perplexity : 74.4689\n",
            "Valid Loss : 4.1938 | Valid_Accuracy : 0.2069 | Valid Perplexity : 202.4999\n",
            "Valid Loss improved from 4.1968 to 4.1938\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 203.0788 to 202.4999\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 47/50 [2:48:54<10:48, 216.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 48/50 [2:52:29<07:11, 215.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 48 / 50\n",
            "Train Loss : 3.5798 | Train_Accuracy : 0.2659 | Train Perplexity : 73.8584\n",
            "Valid Loss : 4.1955 | Valid_Accuracy : 0.2046 | Valid Perplexity : 203.6748\n",
            "Epoch : 49 / 50\n",
            "Train Loss : 3.5707 | Train_Accuracy : 0.2671 | Train Perplexity : 72.8130\n",
            "Valid Loss : 4.1897 | Valid_Accuracy : 0.2066 | Valid Perplexity : 201.6053\n",
            "Valid Loss improved from 4.1938 to 4.1897\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 202.4999 to 201.6053\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 49/50 [2:56:05<03:36, 216.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 50 / 50\n",
            "Train Loss : 3.5611 | Train_Accuracy : 0.2690 | Train Perplexity : 71.7721\n",
            "Valid Loss : 4.1845 | Valid_Accuracy : 0.2072 | Valid Perplexity : 199.9793\n",
            "Valid Loss improved from 4.1897 to 4.1845\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 201.6053 to 199.9793\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [2:59:42<00:00, 215.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "best_loss_epoch : 50\n",
            "best_ppl_epoch : 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 15\n",
        "\n",
        "MSE - last layer(custom) & JS and Cos - logits\n",
        "\n",
        "PPL : 269.9587\n",
        "\n",
        "Best Epoch : 23"
      ],
      "metadata": {
        "id": "phzEaN_H8ZI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "def JS_divergence(student_logits, teacher_logits, temperature, mask=None):\n",
        "  T = temperature\n",
        "  eps=1e-9\n",
        "  student_prob = F.softmax(student_logits / temperature, dim=-1)\n",
        "  teacher_prob = F.softmax(teacher_logits / temperature, dim=-1)\n",
        "  M = 0.5 * (student_prob + teacher_prob)\n",
        "  M_log = torch.log(M + eps)\n",
        "  student_log = torch.log(student_prob + eps)\n",
        "  teacher_log = torch.log(teacher_prob + eps)\n",
        "\n",
        "  D_p = (teacher_prob * (teacher_log - M_log)).sum(dim=-1)\n",
        "  D_q = (student_prob * (student_log - M_log)).sum(dim=-1)\n",
        "\n",
        "  JS = 0.5 * (D_p + D_q)\n",
        "  if mask is not None:\n",
        "    JS = JS * mask\n",
        "    return (JS.sum() / mask.sum()) * (T**2)\n",
        "  else:\n",
        "    return JS.mean() * (T**2)\n",
        "\n",
        "def logit_cosine_similarity(s_logit, t_logit, mask=None):\n",
        "  eps = 1e-9\n",
        "  norm_x = torch.sqrt((s_logit * s_logit).sum(dim=-1) + eps)\n",
        "  norm_y = torch.sqrt((t_logit * t_logit).sum(dim=-1) + eps)\n",
        "  dot = (s_logit * t_logit).sum(dim=-1)\n",
        "  cos_sim = dot / (norm_x * norm_y)\n",
        "  cos_sim = 1 - cos_sim\n",
        "  if mask is not None:\n",
        "    cos_sim = cos_sim * mask\n",
        "    return cos_sim.sum() / mask.sum()\n",
        "  else:\n",
        "    return cos_sim.mean() # (B,)\n",
        "\n",
        "class KD_Loss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, label_smoothing=0.1, ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.A = alpha\n",
        "    self.ignore_index = ignore_index\n",
        "    self.label_smoothing = label_smoothing\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    JS_Loss = JS_divergence(student_logits, teacher_logits, self.T, mask)\n",
        "    CE_Loss = F.cross_entropy(student_logits, labels, ignore_index=self.ignore_index, label_smoothing=self.label_smoothing)\n",
        "    total_Loss = self.A * JS_Loss + (1 - self.A) * CE_Loss\n",
        "    return total_Loss\n",
        "\n",
        "def average_head(attn):  # [B, H, L, L] → [B, L, L].\n",
        "    return attn.mean(dim=1)\n",
        "\n",
        "def MSE(s_attn, t_attn):\n",
        "  last_t_attn = average_head(t_attn[-1])  # [batch, seq_len, seq_len]\n",
        "\n",
        "  loss = torch.zeros((), device=last_t_attn.device, dtype=last_t_attn.dtype)\n",
        "\n",
        "  for attn in s_attn:\n",
        "      attn = average_head(attn)  # [batch, seq_len, seq_len]\n",
        "      loss = loss + ((attn - last_t_attn) ** 2).mean()\n",
        "\n",
        "  loss /= len(s_attn)\n",
        "  return loss\n",
        "\n",
        "class MSE_Loss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, s_attn, t_attn):\n",
        "    loss = MSE(s_attn, t_attn)\n",
        "    return loss\n",
        "\n",
        "class TotalLoss(nn.Module):\n",
        "  def __init__(self, temperature, alpha, beta, gamma, label_smoothing=0.1 ,ignore_index=-100):\n",
        "    super().__init__()\n",
        "    self.T = temperature\n",
        "    self.B = beta\n",
        "    self.G = gamma\n",
        "    self.ignore_index = ignore_index\n",
        "    self.kd_loss = KD_Loss(temperature, alpha, label_smoothing, ignore_index=ignore_index)\n",
        "    self.mse = MSE_Loss()\n",
        "\n",
        "  def forward(self, student_logits, labels, teacher_logits, s_attn, t_attn):\n",
        "    mask = (labels != self.ignore_index).float()\n",
        "    kd_l = self.kd_loss(student_logits, labels, teacher_logits)\n",
        "    mse_l = self.mse(s_attn, t_attn)\n",
        "    cos_for_logits = logit_cosine_similarity(student_logits, teacher_logits, mask)\n",
        "    total_loss = kd_l + self.B * mse_l + self.G * cos_for_logits\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "gMpJot8USJgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Model and Tokenizer\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "model_name = \"gpt2\"  # GPT-small\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "teacher_model = GPT2LMHeadModel.from_pretrained(model_name, output_attentions=True)\n",
        "student_model = TinyGPT(TinyGPTConfig)\n",
        "print(f'teacher_model : \\n{teacher_model}\\n')\n",
        "print(f'student_model : \\n{student_model}\\n')\n",
        "\n",
        "def count_params(model):\n",
        "  total_params = sum(p.numel() for p in model.parameters())\n",
        "  train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "  return total_params, train_params\n",
        "\n",
        "teacher_total_params, teacher_train_params = count_params(teacher_model)\n",
        "student_total_params, student_train_params = count_params(student_model)\n",
        "\n",
        "print(f'teacher total parameters : {teacher_total_params} | teacher trainable parameters : {teacher_train_params}')\n",
        "print(f'student total parameters : {student_total_params} | student trainable parameters : {student_train_params}')\n",
        "teacher_model.to(TinyGPTConfig.device)\n",
        "student_model.to(TinyGPTConfig.device)"
      ],
      "metadata": {
        "id": "_BoKfRyRSJd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b028d22a4c8a4cb0bee5c8358662ad5b",
            "e8668dd781d4451cb2b50f0dd4f28b70",
            "ef0abc6a066944e0b66f98077a4fdace",
            "a61831c95d0f459e949fab44ceb08bc7",
            "c52117feafab4751a8eabbfc2e6a5f75",
            "4c257bbc83244d08a927b8d950405026",
            "6fd24f80bfbd4ad9a3b034a7a4f6958b",
            "c7b6f794824d4364862b8e7d3ed95567",
            "ecd568cab72c4a848aee26ccd2ff599d",
            "8d9da15352a14a8890d1c253bb173269",
            "1b4f23653b08405cb10fd8d9cfcd92e4",
            "86dab26fdb1d4100a1948743fefe21ea",
            "c5dbb227c4f0448a8eea16e960d1ea2e",
            "0ff08dda28d64d1d98d1ead6942c010c",
            "3b66a0a442694d5f8ae9d6eacbbe661d",
            "528502fdd9624da997fabc1a0c9cfb67",
            "5dcb9863432441a5842dc4cb7429ce6c",
            "4fb28bff75c94051aff1a5f3af5eb40c",
            "3fe8fdb20a4146d6b158325fb89e94e5",
            "b361d1af75394d56ab7e7d1c6353efc3",
            "65735d64051b4c34bb1d47d636ed97f3",
            "3975119eff354434afd4b7b7416bfe83"
          ]
        },
        "outputId": "144a4543-fcf1-4929-85e1-43fdc95dfe93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b028d22a4c8a4cb0bee5c8358662ad5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86dab26fdb1d4100a1948743fefe21ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The following generation flags are not valid and may be ignored: ['output_attentions']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "teacher_model : \n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "student_model : \n",
            "TinyGPT(\n",
            "  (token_emb): Embedding(50257, 512)\n",
            "  (pos_emb): PositionalEmbedding()\n",
            "  (drop): Dropout(p=0.2, inplace=False)\n",
            "  (blocks): ModuleList(\n",
            "    (0-7): 8 x TinyGPTBlock(\n",
            "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): MHSA(\n",
            "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      (ff): FFNN(\n",
            "        (FFNN_net): Sequential(\n",
            "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "teacher total parameters : 124439808 | teacher trainable parameters : 124439808\n",
            "student total parameters : 50951680 | student trainable parameters : 50951680\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyGPT(\n",
              "  (token_emb): Embedding(50257, 512)\n",
              "  (pos_emb): PositionalEmbedding()\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (blocks): ModuleList(\n",
              "    (0-7): 8 x TinyGPTBlock(\n",
              "      (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (attn): MHSA(\n",
              "        (qkv_linear): Linear(in_features=512, out_features=1536, bias=True)\n",
              "        (linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (ff): FFNN(\n",
              "        (FFNN_net): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  (Linear_f): Linear(in_features=512, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting loss function, optimzer, and scheduler\n",
        "num_epochs = 50\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# alpha : JS & CE(1-alpha), beta : MSE, gamma : cos for logits\n",
        "loss_function = TotalLoss(temperature=2.0, alpha=0.5, beta=0.05, gamma=0.05)\n",
        "optimizer = torch.optim.AdamW(student_model.parameters(), lr=4e-4, betas=(0.9, 0.95), weight_decay=0.01)\n",
        "\n",
        "total_steps = num_epochs * len(train_dataloader)\n",
        "warmup_steps = int(0.05 * total_steps)\n",
        "\n",
        "def lr_lambda(current_step):\n",
        "  if current_step < warmup_steps:\n",
        "    return float(current_step) / float(warmup_steps)\n",
        "  progress = float(current_step - warmup_steps) / float(max(1, total_steps - warmup_steps))\n",
        "  return max(0.1, 0.5 * (1.0 + math.cos(math.pi * progress))) # min_lr = 0.1 * lr\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)"
      ],
      "metadata": {
        "id": "9tBVdG9RSJa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Evaluation Function\n",
        "'''\n",
        "def evaluation(student_model, teacher_model, dataloader, loss_function, return_attentions, device):\n",
        "  student_model.eval()\n",
        "  teacher_model.eval()\n",
        "  total_loss = 0.0\n",
        "  total_correct = 0\n",
        "  total_cnt = 0\n",
        "  total_ce_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for inputs, _ in dataloader:\n",
        "      inputs = inputs.to(device)\n",
        "\n",
        "      input_ids = inputs[:,:-1]\n",
        "      labels = inputs[:,1:]\n",
        "      labels[:, -1] = -100\n",
        "\n",
        "      s_outputs, s_attn = student_model(input_ids, return_attentions=return_attentions)\n",
        "      t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "      t_attn = t_outputs.attentions\n",
        "      t_logits = t_outputs.logits\n",
        "\n",
        "      loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn) # total_loss, kd_loss, mse_loss 반환. 체크용으로 그렇게 만듦.\n",
        "      ce_loss = F.cross_entropy(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), ignore_index=-100, reduction='sum')\n",
        "      total_ce_loss += ce_loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      preds = s_outputs.argmax(dim=-1)\n",
        "\n",
        "      mask = labels != -100\n",
        "      correct = (preds == labels) & mask\n",
        "\n",
        "      total_correct += correct.sum().item()\n",
        "      total_cnt += mask.sum().item()\n",
        "    ppl = math.exp(total_ce_loss / total_cnt)\n",
        "\n",
        "  return total_loss / len(dataloader), total_correct / total_cnt, ppl"
      ],
      "metadata": {
        "id": "hzT8H9YcSJYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/TinyGPT_checkpoints'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "best_val_loss = float('inf')\n",
        "best_ppl = float('inf')\n",
        "best_epoch = 0\n",
        "cnt_to_stop = 0\n",
        "\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  student_model.train()\n",
        "  teacher_model.eval()\n",
        "\n",
        "  for step, (inputs, _) in enumerate(train_dataloader):\n",
        "    inputs = inputs.to(TinyGPTConfig.device)\n",
        "\n",
        "    input_ids = inputs[:,:-1]\n",
        "    labels = inputs[:,1:]\n",
        "\n",
        "    labels[:, -1] = -100\n",
        "    assert labels.max().item() < TinyGPTConfig.vocab_size\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    s_outputs, s_attn = student_model(input_ids, return_attentions=True)\n",
        "    t_outputs = teacher_model(input_ids, output_attentions=True)\n",
        "    t_attn = t_outputs.attentions\n",
        "    t_logits = t_outputs.logits\n",
        "\n",
        "    loss = loss_function(s_outputs.reshape(-1, s_outputs.size(-1)), labels.reshape(-1), t_logits.reshape(-1, t_logits.size(-1)), s_attn, t_attn)\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(student_model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "    # if step % 10 == 0:\n",
        "    #   print(f\"[Loss Check] KD: {kd_l.item():.6f} | MSE: {mse_l.item():.6f} | total: {loss.item():.6f}\")\n",
        "\n",
        "  train_loss, train_acc, train_ppl = evaluation(student_model, teacher_model, train_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "  valid_loss, valid_acc, valid_ppl = evaluation(student_model, teacher_model, valid_dataloader, loss_function, True, TinyGPTConfig.device)\n",
        "\n",
        "  print(f'Epoch : {epoch + 1} / {num_epochs}')\n",
        "  print(f'Train Loss : {train_loss:.4f} | Train_Accuracy : {train_acc:.4f} | Train Perplexity : {train_ppl:.4f}')\n",
        "  print(f'Valid Loss : {valid_loss:.4f} | Valid_Accuracy : {valid_acc:.4f} | Valid Perplexity : {valid_ppl:.4f}')\n",
        "\n",
        "  if valid_loss < best_val_loss:\n",
        "    print(f'Valid Loss improved from {best_val_loss:.4f} to {valid_loss:.4f}')\n",
        "    print('Save the loss Checkpoint')\n",
        "    best_val_loss = valid_loss\n",
        "    best_loss_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  if valid_ppl < best_ppl:\n",
        "    print(f'Valid Perplexity improved from {best_ppl:.4f} to {valid_ppl:.4f}')\n",
        "    print('Save the Perplexity Checkpoint')\n",
        "    best_ppl = valid_ppl\n",
        "    best_ppl_epoch = epoch + 1\n",
        "    cnt_to_stop = 0\n",
        "    save_path = os.path.join(save_dir, f'best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth')\n",
        "    torch.save(student_model.state_dict(), save_path)\n",
        "    print(f'Model saved to: {save_path}')\n",
        "  elif valid_loss > best_val_loss and valid_ppl > best_ppl:\n",
        "    cnt_to_stop += 1\n",
        "    if cnt_to_stop >= 6:\n",
        "      break\n",
        "\n",
        "print(f'best_loss_epoch : {best_loss_epoch}')\n",
        "print(f'best_ppl_epoch : {best_ppl_epoch}')"
      ],
      "metadata": {
        "id": "Vv6IBTOYSJOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8733daa-8f46-4459-84f9-e2d514ece55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 / 50\n",
            "Train Loss : 4.4311 | Train_Accuracy : 0.0507 | Train Perplexity : 1968.9255\n",
            "Valid Loss : 4.4148 | Valid_Accuracy : 0.0400 | Valid Perplexity : 1880.5830\n",
            "Valid Loss improved from inf to 4.4148\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from inf to 1880.5830\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [04:51<3:58:02, 291.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 2 / 50\n",
            "Train Loss : 4.2714 | Train_Accuracy : 0.0941 | Train Perplexity : 1418.8669\n",
            "Valid Loss : 4.2734 | Valid_Accuracy : 0.0873 | Valid Perplexity : 1410.2018\n",
            "Valid Loss improved from 4.4148 to 4.2734\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1880.5830 to 1410.2018\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [09:08<3:36:55, 271.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 3 / 50\n",
            "Train Loss : 4.1343 | Train_Accuracy : 0.1081 | Train Perplexity : 1070.0286\n",
            "Valid Loss : 4.1430 | Valid_Accuracy : 0.0975 | Valid Perplexity : 1076.5267\n",
            "Valid Loss improved from 4.2734 to 4.1430\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1410.2018 to 1076.5267\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [13:25<3:27:15, 264.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 4 / 50\n",
            "Train Loss : 4.0549 | Train_Accuracy : 0.1218 | Train Perplexity : 901.6639\n",
            "Valid Loss : 4.0567 | Valid_Accuracy : 0.1145 | Valid Perplexity : 897.4061\n",
            "Valid Loss improved from 4.1430 to 4.0567\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 1076.5267 to 897.4061\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [17:42<3:20:33, 261.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 5 / 50\n",
            "Train Loss : 3.8772 | Train_Accuracy : 0.1386 | Train Perplexity : 629.5192\n",
            "Valid Loss : 3.9188 | Valid_Accuracy : 0.1259 | Valid Perplexity : 681.8701\n",
            "Valid Loss improved from 4.0567 to 3.9188\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 897.4061 to 681.8701\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [21:59<3:14:56, 259.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 6 / 50\n",
            "Train Loss : 3.8009 | Train_Accuracy : 0.1486 | Train Perplexity : 535.4345\n",
            "Valid Loss : 3.8305 | Valid_Accuracy : 0.1397 | Valid Perplexity : 569.7532\n",
            "Valid Loss improved from 3.9188 to 3.8305\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 681.8701 to 569.7532\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [26:16<3:09:53, 258.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 7 / 50\n",
            "Train Loss : 3.7263 | Train_Accuracy : 0.1546 | Train Perplexity : 459.8372\n",
            "Valid Loss : 3.7889 | Valid_Accuracy : 0.1437 | Valid Perplexity : 525.9170\n",
            "Valid Loss improved from 3.8305 to 3.7889\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 569.7532 to 525.9170\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [30:33<3:05:09, 258.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 8 / 50\n",
            "Train Loss : 3.6651 | Train_Accuracy : 0.1628 | Train Perplexity : 402.0879\n",
            "Valid Loss : 3.7329 | Valid_Accuracy : 0.1505 | Valid Perplexity : 465.0290\n",
            "Valid Loss improved from 3.7889 to 3.7329\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 525.9170 to 465.0290\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [34:50<3:00:33, 257.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 9 / 50\n",
            "Train Loss : 3.5770 | Train_Accuracy : 0.1699 | Train Perplexity : 334.8802\n",
            "Valid Loss : 3.6826 | Valid_Accuracy : 0.1550 | Valid Perplexity : 419.7651\n",
            "Valid Loss improved from 3.7329 to 3.6826\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 465.0290 to 419.7651\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [39:07<2:55:59, 257.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 10 / 50\n",
            "Train Loss : 3.5208 | Train_Accuracy : 0.1772 | Train Perplexity : 296.5031\n",
            "Valid Loss : 3.6492 | Valid_Accuracy : 0.1627 | Valid Perplexity : 391.2998\n",
            "Valid Loss improved from 3.6826 to 3.6492\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 419.7651 to 391.2998\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [43:23<2:51:31, 257.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 11 / 50\n",
            "Train Loss : 3.4714 | Train_Accuracy : 0.1826 | Train Perplexity : 265.3861\n",
            "Valid Loss : 3.6159 | Valid_Accuracy : 0.1721 | Valid Perplexity : 363.8595\n",
            "Valid Loss improved from 3.6492 to 3.6159\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 391.2998 to 363.8595\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [47:40<2:47:09, 257.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 12 / 50\n",
            "Train Loss : 3.4002 | Train_Accuracy : 0.1886 | Train Perplexity : 229.0851\n",
            "Valid Loss : 3.5929 | Valid_Accuracy : 0.1746 | Valid Perplexity : 347.6089\n",
            "Valid Loss improved from 3.6159 to 3.5929\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 363.8595 to 347.6089\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [51:57<2:42:48, 257.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 13 / 50\n",
            "Train Loss : 3.3599 | Train_Accuracy : 0.1945 | Train Perplexity : 210.3758\n",
            "Valid Loss : 3.5804 | Valid_Accuracy : 0.1763 | Valid Perplexity : 338.3646\n",
            "Valid Loss improved from 3.5929 to 3.5804\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 347.6089 to 338.3646\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [56:15<2:38:36, 257.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 14 / 50\n",
            "Train Loss : 3.3141 | Train_Accuracy : 0.1997 | Train Perplexity : 188.9751\n",
            "Valid Loss : 3.5668 | Valid_Accuracy : 0.1817 | Valid Perplexity : 328.1157\n",
            "Valid Loss improved from 3.5804 to 3.5668\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 338.3646 to 328.1157\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [1:00:32<2:34:18, 257.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 15 / 50\n",
            "Train Loss : 3.2756 | Train_Accuracy : 0.2042 | Train Perplexity : 173.3372\n",
            "Valid Loss : 3.5578 | Valid_Accuracy : 0.1871 | Valid Perplexity : 320.4205\n",
            "Valid Loss improved from 3.5668 to 3.5578\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 328.1157 to 320.4205\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [1:04:48<2:29:56, 257.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 16 / 50\n",
            "Train Loss : 3.2186 | Train_Accuracy : 0.2121 | Train Perplexity : 152.5777\n",
            "Valid Loss : 3.5351 | Valid_Accuracy : 0.1905 | Valid Perplexity : 304.4640\n",
            "Valid Loss improved from 3.5578 to 3.5351\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 320.4205 to 304.4640\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [1:09:05<2:25:37, 256.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 17 / 50\n",
            "Train Loss : 3.1931 | Train_Accuracy : 0.2167 | Train Perplexity : 142.5711\n",
            "Valid Loss : 3.5276 | Valid_Accuracy : 0.1927 | Valid Perplexity : 295.4206\n",
            "Valid Loss improved from 3.5351 to 3.5276\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 304.4640 to 295.4206\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [1:13:22<2:21:18, 256.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 18 / 50\n",
            "Train Loss : 3.1380 | Train_Accuracy : 0.2244 | Train Perplexity : 126.6130\n",
            "Valid Loss : 3.5189 | Valid_Accuracy : 0.1919 | Valid Perplexity : 291.2321\n",
            "Valid Loss improved from 3.5276 to 3.5189\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 295.4206 to 291.2321\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [1:17:40<2:17:08, 257.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [1:21:55<2:12:38, 256.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 19 / 50\n",
            "Train Loss : 3.0952 | Train_Accuracy : 0.2305 | Train Perplexity : 115.4095\n",
            "Valid Loss : 3.5281 | Valid_Accuracy : 0.1885 | Valid Perplexity : 296.7999\n",
            "Epoch : 20 / 50\n",
            "Train Loss : 3.0452 | Train_Accuracy : 0.2394 | Train Perplexity : 102.3860\n",
            "Valid Loss : 3.5110 | Valid_Accuracy : 0.1944 | Valid Perplexity : 284.4696\n",
            "Valid Loss improved from 3.5189 to 3.5110\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 291.2321 to 284.4696\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [1:26:12<2:08:20, 256.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 21 / 50\n",
            "Train Loss : 3.0003 | Train_Accuracy : 0.2483 | Train Perplexity : 92.5427\n",
            "Valid Loss : 3.5125 | Valid_Accuracy : 0.1893 | Valid Perplexity : 284.4148\n",
            "Valid Perplexity improved from 284.4696 to 284.4148\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [1:30:28<2:04:02, 256.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 22 / 50\n",
            "Train Loss : 2.9595 | Train_Accuracy : 0.2563 | Train Perplexity : 84.3477\n",
            "Valid Loss : 3.5063 | Valid_Accuracy : 0.2001 | Valid Perplexity : 280.3032\n",
            "Valid Loss improved from 3.5110 to 3.5063\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 284.4148 to 280.3032\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [1:34:45<1:59:48, 256.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Epoch : 23 / 50\n",
            "Train Loss : 2.8994 | Train_Accuracy : 0.2686 | Train Perplexity : 73.5770\n",
            "Valid Loss : 3.4908 | Valid_Accuracy : 0.1959 | Valid Perplexity : 269.9587\n",
            "Valid Loss improved from 3.5063 to 3.4908\n",
            "Save the loss Checkpoint\n",
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_loss_KD_with_last_attn_TinyGPT_checkpoint.pth\n",
            "Valid Perplexity improved from 280.3032 to 269.9587\n",
            "Save the Perplexity Checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [1:39:02<1:55:31, 256.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/TinyGPT_checkpoints/best_ppl_KD_with_last_attn_TinyGPT_checkpoint.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [1:43:18<1:51:09, 256.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 24 / 50\n",
            "Train Loss : 2.8710 | Train_Accuracy : 0.2752 | Train Perplexity : 69.1748\n",
            "Valid Loss : 3.5100 | Valid_Accuracy : 0.1970 | Valid Perplexity : 281.3409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [1:47:34<1:46:50, 256.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 25 / 50\n",
            "Train Loss : 2.8236 | Train_Accuracy : 0.2855 | Train Perplexity : 61.5829\n",
            "Valid Loss : 3.5042 | Valid_Accuracy : 0.1984 | Valid Perplexity : 274.8941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [1:51:50<1:42:29, 256.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 26 / 50\n",
            "Train Loss : 2.8045 | Train_Accuracy : 0.2899 | Train Perplexity : 58.9447\n",
            "Valid Loss : 3.5181 | Valid_Accuracy : 0.1956 | Valid Perplexity : 283.8684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [1:56:06<1:38:07, 255.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 27 / 50\n",
            "Train Loss : 2.7651 | Train_Accuracy : 0.3009 | Train Perplexity : 53.7295\n",
            "Valid Loss : 3.5225 | Valid_Accuracy : 0.1970 | Valid Perplexity : 284.6574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [2:00:22<1:33:52, 256.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 28 / 50\n",
            "Train Loss : 2.7213 | Train_Accuracy : 0.3124 | Train Perplexity : 48.6627\n",
            "Valid Loss : 3.5180 | Valid_Accuracy : 0.1961 | Valid Perplexity : 281.3833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 28/50 [2:04:36<1:37:54, 267.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 29 / 50\n",
            "Train Loss : 2.6988 | Train_Accuracy : 0.3190 | Train Perplexity : 45.9824\n",
            "Valid Loss : 3.5320 | Valid_Accuracy : 0.2029 | Valid Perplexity : 288.1983\n",
            "best_loss_epoch : 23\n",
            "best_ppl_epoch : 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 16\n",
        "\n",
        "Graphs in Report"
      ],
      "metadata": {
        "id": "xhbL1yOb9Z3o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGSLQsR9heiB"
      },
      "outputs": [],
      "source": [
        "# Save each method's valid PPL\n",
        "No_KD = [1846.9351, 1809.1408, 1428.8737, 1040.5593, 979.976, 839.0429, 734.6417, 649.9261, 550.433, 534.417, 477.3394, 478.3222, 457.3042, 434.3887, 418.9305, 416.3426, 395.8133, 377.081, 376.5928, 376.1736, 367.0832, 367.9825, 368.9868, 386.0777, 388.5007, 374.5141, 376.8965]\n",
        "KL_Logits = [1926.4015, 1908.421, 1270.0845, 1139.3703, 1092.7038, 764.6118, 675.0579, 597.8781, 530.9361, 509.9682, 446.5117, 427.2878, 395.0213, 376.4525, 361.0871, 341.5499, 315.6868, 307.3681, 310.7553, 292.0945, 275.6696, 275.8296, 275.952, 252.6243, 272.6068, 241.6565, 245.4407, 240.4312, 240.8302, 229.7992, 223.8889, 220.3744, 221.4886, 214.8608, 214.6524, 212.1157, 209.7125, 205.6901, 208.6089, 203.2323, 203.0633, 201.2229, 203.1634, 198.581, 200.8778, 199.7862, 200.5692, 199.7538, 198.291, 197.1689]\n",
        "MSE_layerwise_KL_Logits = [1926.4015, 1908.6492, 1362.2171, 1081.6924, 1000.9227, 832.1236, 690.3789, 641.4207, 508.466, 506.8253, 429.2709, 434.2401, 388.61, 391.7067, 384.1965, 331.3598, 338.633, 311.2886, 326.9259, 296.2925, 282.314, 275.1564, 272.5435, 264.7332, 265.9631, 247.7954, 250.5443, 251.8607, 239.3243, 234.5951, 228.2604, 223.4226, 226.6707, 224.7556, 220.5823, 216.8481, 215.1179, 210.9752, 214.0383, 209.9312, 209.3263, 208.9846, 208.1813, 207.2896, 207.4454, 207.8969, 204.8032, 206.6954, 205.9966, 203.926]\n",
        "MSE_layerwise_JS_Logits = [1860.7965, 1815.4988, 1300.1115, 1006.4397, 831.9306, 883.2403, 764.5043, 658.6157, 542.5471, 494.1632, 460.7113, 419.6659, 418.7339, 397.1988, 367.3493, 366.6966, 353.9623, 342.5308, 334.6102, 324.6677, 323.2294, 318.9544, 305.9313, 313.9549, 310.6054, 301.0149, 302.9045, 293.6137, 297.9061, 296.4089, 302.9911, 303.2334, 299.849, 295.5693]\n",
        "MSE_last_layer_KL_Logits = [1926.4025, 1909.6343, 1237.7357, 1068.6466, 950.2782, 828.3974, 693.689, 601.9332, 524.1274, 522.9229, 464.0212, 430.072, 405.5191, 398.61, 382.0399, 335.0932, 325.2384, 311.2183, 308.5512, 294.0489, 295.5911, 288.0384, 276.2717, 258.303, 258.7487, 246.3162, 249.5611, 236.7571, 244.8268, 232.05, 226.5675, 228.7008, 222.8709, 216.8825, 216.6973, 215.5134, 212.7557, 209.1679, 208.2021, 206.598, 203.6278, 203.9338, 205.0751, 201.4424, 203.1642, 202.5138, 201.0778, 202.4422, 203.0005, 201.1704]\n",
        "MSE_last_layer_JS_Logits = [1860.7985, 1816.6137, 1312.2568, 991.3378, 914.6034, 890.8628, 738.2634, 590.4467, 549.2635, 496.4534, 462.4102, 454.99, 435.8627, 396.2553, 392.5474, 353.8389, 373.16, 337.8325, 343.5947, 326.3017, 309.6472, 316.2348, 310.5438, 309.5366, 303.5959, 302.6084, 305.5382, 296.9705, 291.6763, 298.613, 306.0963, 298.2791, 301.2456, 298.7617, 291.8446]\n",
        "MSE_last_layer_custom_KL_Logits = [1926.4079, 1909.9462, 1268.2956, 1194.842, 1022.2628, 869.6076, 698.5033, 596.2657, 514.8932, 509.8474, 467.6934, 439.6152, 422.3111, 407.4298, 414.8476, 342.8715, 357.0297, 325.8708, 305.453, 303.9985, 292.0655, 294.8488, 286.9917, 270.3822, 260.4896, 253.5633, 260.6296, 249.4783, 251.2411, 255.0734, 234.2559, 235.5979, 233.758, 221.753, 225.0391, 219.1607, 219.7281, 214.2318, 215.1196, 212.8977, 209.2359, 210.1908, 210.3716, 208.1439, 207.2093, 207.247, 208.75, 208.6674, 206.406, 204.5668]\n",
        "MSE_last_layer_custom_JS_Logits = [1880.8474, 1381.7139, 1006.3383, 845.8413, 677.3722, 599.6227, 568.0191, 479.7109, 441.1084, 410.0151, 367.8697, 363.1274, 350.6801, 326.4922, 313.6293, 302.8589, 297.8982, 302.6015, 288.5363, 281.7413, 279.5396, 272.1792, 275.4059, 274.4773, 280.9874, 284.3473, 286.6892, 283.1749]\n",
        "MSE_layerwise_KL_Cos_Logits = [1944.3027, 1902.698, 1279.0895, 1110.2924, 891.6808, 845.1608, 660.7738, 581.1533, 532.0038, 484.1135, 420.1173, 417.5582, 444.3626, 387.8292, 365.9777, 347.1828, 341.1788, 312.0896, 292.6566, 272.8808, 286.6798, 269.2365, 269.2299, 258.7557, 252.2816, 244.1539, 237.7785, 230.9574, 226.991, 231.9208, 223.4398, 217.0776, 213.2599, 215.7379, 213.1103, 208.213, 207.3096, 204.6468, 207.2546, 203.2435, 203.0898, 201.7978, 201.561, 201.7063, 200.7486, 199.9349, 199.8334, 199.2545, 198.7038, 199.2251]\n",
        "MSE_layerwise_JS_Cos_Logits = [1880.5205, 1398.3865, 1160.7957, 855.4391, 692.7315, 559.546, 559.6696, 466.8189, 428.8381, 410.5471, 359.7132, 353.6693, 340.8322, 322.2102, 325.2333, 308.2635, 307.3423, 296.9025, 295.2977, 281.8508, 282.6724, 279.3387, 281.4202, 280.6039, 281.0288, 277.9291, 277.3673, 276.6832, 282.6368, 283.1758, 287.5803, 286.0246, 289.982, 293.9117]\n",
        "MSE_last_layer_KL_Cos_Logits = [1925.7958, 1897.5121, 1274.6221, 1072.9651, 1029.7297, 790.0454, 657.355, 574.8038, 555.6623, 527.6358, 465.8652, 422.284, 444.0011, 415.5489, 384.415, 340.3393, 327.9896, 323.0529, 334.7443, 300.6608, 298.6793, 287.2646, 281.1385, 282.6656, 263.8861, 258.5416, 261.7279, 249.0883, 254.1738, 256.044, 236.5394, 231.8118, 228.9942, 223.9289, 222.3976, 217.7282, 217.5376, 212.8999, 212.8657, 211.6936, 209.7972, 208.5972, 208.187, 207.0197, 206.67, 204.8114, 205.3616, 205.0783, 203.8968, 203.5941]\n",
        "MSE_last_layer_JS_Cos_Logits = [1880.5205, 1399.5374, 1149.646, 946.488, 707.1026, 623.1356, 617.6869, 493.2935, 464.0551, 407.1443, 373.9239, 368.2544, 340.4444, 332.1273, 339.9201, 305.0002, 304.937, 290.6184, 298.1645, 282.1827, 275.9998, 276.0351, 264.7178, 270.8691, 276.4807, 285.4101, 275.8194, 277.5678, 283.7224]\n",
        "MSE_last_layer_custom_KL_Cos_Logits = [1925.8022, 1902.8581, 1407.0178, 1187.5958, 947.6026, 907.6231, 716.2929, 635.7608, 547.0343, 511.225, 456.5251, 438.3726, 396.1048, 407.0159, 383.7595, 343.3878, 355.0657, 326.2833, 324.6911, 305.2834, 303.3588, 286.5525, 293.4584, 274.1807, 270.3307, 257.3668, 252.9873, 240.275, 251.7149, 238.412, 231.5258, 232.7357, 226.3781, 221.6278, 217.2685, 214.6385, 211.545, 209.868, 211.4696, 207.6154, 205.5347, 206.8956, 205.3242, 203.7075, 204.0037, 203.0788, 202.4999, 203.6748, 201.6053, 199.9793]\n",
        "MSE_last_layer_custom_JS_Cos_Logits = [1880.583, 1410.2018, 1076.5267, 897.4061, 681.8701, 569.7532, 525.917, 465.029, 419.7651, 391.2998, 363.8595, 347.6089, 338.3646, 328.1157, 320.4205, 304.464, 295.4206, 291.2321, 296.7999, 284.4696, 284.4148, 280.3032, 269.9587, 281.3409, 274.8941, 283.8684, 284.6574, 281.3833, 288.1983]\n",
        "\n",
        "KD_results = [\n",
        "    No_KD,\n",
        "    KL_Logits,\n",
        "    MSE_layerwise_KL_Logits,\n",
        "    MSE_layerwise_JS_Logits,\n",
        "    MSE_last_layer_KL_Logits,\n",
        "    MSE_last_layer_JS_Logits,\n",
        "    MSE_last_layer_custom_KL_Logits,\n",
        "    MSE_last_layer_custom_JS_Logits,\n",
        "    MSE_layerwise_KL_Cos_Logits,\n",
        "    MSE_layerwise_JS_Cos_Logits,\n",
        "    MSE_last_layer_KL_Cos_Logits,\n",
        "    MSE_last_layer_JS_Cos_Logits,\n",
        "    MSE_last_layer_custom_KL_Cos_Logits,\n",
        "    MSE_last_layer_custom_JS_Cos_Logits\n",
        "]\n",
        "\n",
        "KD_names = [\n",
        "    \"No_KD\",\n",
        "    \"KL_Logits\",\n",
        "    \"MSE_layerwise_KL_Logits\",\n",
        "    \"MSE_layerwise_JS_Logits\",\n",
        "    \"MSE_last_layer_KL_Logits\",\n",
        "    \"MSE_last_layer_JS_Logits\",\n",
        "    \"MSE_last_layer_custom_KL_Logits\",\n",
        "    \"MSE_last_layer_custom_JS_Logits\",\n",
        "    \"MSE_layerwise_KL_Cos_Logits\",\n",
        "    \"MSE_layerwise_JS_Cos_Logits\",\n",
        "    \"MSE_last_layer_KL_Cos_Logits\",\n",
        "    \"MSE_last_layer_JS_Cos_Logits\",\n",
        "    \"MSE_last_layer_custom_KL_Cos_Logits\",\n",
        "    \"MSE_last_layer_custom_JS_Cos_Logits\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Figure 4. Comparison valid perplexity between the baseline and methods which use JS-Divergence\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "valid_ppl_lists = [\n",
        "    KL_Logits,\n",
        "    MSE_layerwise_JS_Logits,\n",
        "    MSE_last_layer_JS_Logits,\n",
        "    MSE_last_layer_custom_JS_Logits\n",
        "]\n",
        "\n",
        "valid_ppl_name_lists = [\n",
        "    \"KL_Logits\",\n",
        "    \"MSE_layerwise_JS_Logits\",\n",
        "    \"MSE_last_layer_JS_Logits\",\n",
        "    \"MSE_last_layer_custom_JS_Logits\"\n",
        "]\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "for i, ppl_list in enumerate(valid_ppl_lists):\n",
        "    num_epochs = len(ppl_list)\n",
        "    x = list(range(1, num_epochs + 1))\n",
        "    plt.plot(x, ppl_list, label=f'{valid_ppl_name_lists[i]}')\n",
        "\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Valid Perplexity')\n",
        "plt.title('Validation Perplexity over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xlim(0,16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9cFTw7FyUo95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "e1922464-29e5-4fc9-b172-e9a11232de57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Figure 5. Comparison valid perplexity between the baseline and methods which use JS-Divergence and cosine similarity loss for logits\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "valid_ppl_lists = [\n",
        "    KL_Logits,\n",
        "    MSE_layerwise_JS_Cos_Logits,\n",
        "    MSE_last_layer_JS_Cos_Logits,\n",
        "    MSE_last_layer_custom_JS_Cos_Logits\n",
        "]\n",
        "\n",
        "valid_ppl_name_lists = [\n",
        "    \"KL_Logits\",\n",
        "    \"MSE_layerwise_JS_Cos_Logits\",\n",
        "    \"MSE_last_layer_JS_Cos_Logits\",\n",
        "    \"MSE_last_layer_custom_JS_Cos_Logits\"\n",
        "]\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "for i, ppl_list in enumerate(valid_ppl_lists):\n",
        "    num_epochs = len(ppl_list)\n",
        "    x = list(range(1, num_epochs + 1))\n",
        "    plt.plot(x, ppl_list, label=f'{valid_ppl_name_lists[i]}')\n",
        "\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Valid Perplexity')\n",
        "plt.title('Validation Perplexity over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xlim(0,16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Flj7Vv3zUpAZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "d2d3619d-b617-48db-f93a-d3265881497d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Figure 6. Comparison valid perplexity between the baseline and methods which use KL-Divergence\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "valid_ppl_lists = [\n",
        "    KL_Logits,\n",
        "    MSE_layerwise_KL_Logits,\n",
        "    MSE_last_layer_KL_Logits,\n",
        "    MSE_last_layer_custom_KL_Logits\n",
        "]\n",
        "\n",
        "valid_ppl_name_lists = [\n",
        "    \"KL_Logits\",\n",
        "    \"MSE_layerwise_KL_Logits\",\n",
        "    \"MSE_last_layer_KL_Logits\",\n",
        "    \"MSE_last_layer_custom_KL_Logits\"\n",
        "]\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "for i, ppl_list in enumerate(valid_ppl_lists):\n",
        "    num_epochs = len(ppl_list)\n",
        "    x = list(range(1, num_epochs + 1))\n",
        "    plt.plot(x, ppl_list, label=f'{valid_ppl_name_lists[i]}')\n",
        "\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Valid Perplexity')\n",
        "plt.title('Validation Perplexity over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xlim(1,10)\n",
        "plt.ylim(450, 2000)\n",
        "plt.yticks(range(450, 2000, 50))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7R59wO0mUpCz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "01ff99c2-b1f7-4bef-8376-68fe4b5ef159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Figure 7. Comparison valid perplexity between the baseline and methods which use KL-Divergence\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "valid_ppl_lists = [\n",
        "    KL_Logits,\n",
        "    MSE_layerwise_KL_Cos_Logits,\n",
        "    MSE_last_layer_KL_Cos_Logits,\n",
        "    MSE_last_layer_custom_KL_Cos_Logits\n",
        "]\n",
        "\n",
        "valid_ppl_name_lists = [\n",
        "    \"KL_Logits\",\n",
        "    \"MSE_layerwise_KL_Cos_Logits\",\n",
        "    \"MSE_last_layer_KL_Cos_Logits\",\n",
        "    \"MSE_last_layer_custom_KL_Cos_Logits\"\n",
        "]\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "for i, ppl_list in enumerate(valid_ppl_lists):\n",
        "    num_epochs = len(ppl_list)\n",
        "    x = list(range(1, num_epochs + 1))  # epoch 1부터 시작\n",
        "    plt.plot(x, ppl_list, label=f'{valid_ppl_name_lists[i]}')\n",
        "\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Valid Perplexity')\n",
        "plt.title('Validation Perplexity over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xlim(1,10)\n",
        "plt.ylim(450, 2000)\n",
        "plt.yticks(range(450, 2000, 50))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "js-8rqiYUpFb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "5e644f63-af30-4bd4-be1a-7f17e0ced9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}